{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b423049",
   "metadata": {},
   "source": [
    "## Data Importation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b858cac7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data<-read.csv(\"data_visco.csv\")\n",
    "data_lasso <- read.csv(\"data_lasso.csv\")\n",
    "data_AIC <- read.csv(\"data_AIC.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707fdcdd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>6987</li><li>30</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 6987\n",
       "\\item 30\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 6987\n",
       "2. 30\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 6987   30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>7246</li><li>20</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7246\n",
       "\\item 20\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7246\n",
       "2. 20\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 7246   20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_lasso)\n",
    "dim(data_AIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ef16e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "nettoyer = function(x){\n",
    "    x[x < 0] = 0\n",
    "    return(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa8af37",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_lasso = nettoyer(data_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21ea88c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_lasso_log = data.frame(data_lasso)\n",
    "vis_log = log(data_lasso_log[1])\n",
    "data_lasso_log[,1] = vis_log\n",
    "data[,1] = vis_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4268776",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>6987</li><li>30</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 6987\n",
       "\\item 30\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 6987\n",
       "2. 30\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 6987   30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_lasso_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ff81f",
   "metadata": {},
   "source": [
    "Pour rendre la distribution de la viscocité gaussienne, on utilise log(viscocité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11f1970",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Histogram of data_lasso_log[, 1]\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(data_lasso_log[,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073baef4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6987 × 30</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>vis</th><th scope=col>X__3</th><th scope=col>X__4</th><th scope=col>X__8</th><th scope=col>X__10</th><th scope=col>X__17</th><th scope=col>X__18</th><th scope=col>X__29</th><th scope=col>X__30</th><th scope=col>X__43</th><th scope=col>...</th><th scope=col>X__84</th><th scope=col>X__86</th><th scope=col>X__106</th><th scope=col>X__109</th><th scope=col>X__113</th><th scope=col>X__115</th><th scope=col>X__117</th><th scope=col>X__133</th><th scope=col>X__138</th><th scope=col>autres</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>7.795647</td><td>0</td><td> 9.42</td><td> 8.52</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>68.39</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.00000</td></tr>\n",
       "\t<tr><td>8.396832</td><td>0</td><td> 9.42</td><td> 8.53</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>70.32</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.00000</td></tr>\n",
       "\t<tr><td>3.218876</td><td>0</td><td> 3.58</td><td>14.25</td><td>0</td><td>0</td><td> 1.88</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>45.42</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>1.34</td><td>15.80000</td></tr>\n",
       "\t<tr><td>3.044522</td><td>0</td><td> 3.81</td><td>14.08</td><td>0</td><td>0</td><td> 3.30</td><td>0.09</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>45.55</td><td>0</td><td>0.08</td><td>0</td><td>0</td><td>1.24</td><td>16.88000</td></tr>\n",
       "\t<tr><td>4.158883</td><td>0</td><td> 0.00</td><td> 0.00</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>66.51</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.01000</td></tr>\n",
       "\t<tr><td>4.369448</td><td>0</td><td> 3.00</td><td>18.00</td><td>0</td><td>0</td><td> 2.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>56.00</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>2.00</td><td> 6.00000</td></tr>\n",
       "\t<tr><td>8.676587</td><td>0</td><td> 9.43</td><td> 8.53</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>71.50</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.00000</td></tr>\n",
       "\t<tr><td>6.852243</td><td>0</td><td> 0.00</td><td> 0.00</td><td>0</td><td>0</td><td>10.60</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>74.85</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.15000</td></tr>\n",
       "\t<tr><td>5.568345</td><td>0</td><td> 0.00</td><td> 0.00</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>70.37</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.00000</td></tr>\n",
       "\t<tr><td>4.795791</td><td>0</td><td> 0.00</td><td> 0.00</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>64.46</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.00000</td></tr>\n",
       "\t<tr><td>6.817831</td><td>0</td><td> 0.22</td><td> 0.00</td><td>0</td><td>0</td><td> 0.15</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>55.91</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td>31.55000</td></tr>\n",
       "\t<tr><td>6.287859</td><td>0</td><td> 0.00</td><td> 0.00</td><td>0</td><td>0</td><td> 2.70</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>59.75</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td>26.15000</td></tr>\n",
       "\t<tr><td>6.856462</td><td>0</td><td> 3.72</td><td> 0.00</td><td>0</td><td>0</td><td> 8.69</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>68.52</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.44000</td></tr>\n",
       "\t<tr><td>8.706159</td><td>0</td><td>22.43</td><td> 3.00</td><td>0</td><td>0</td><td> 5.90</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>58.77</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 0.18499</td></tr>\n",
       "\t<tr><td>3.737670</td><td>0</td><td> 0.00</td><td>21.70</td><td>0</td><td>0</td><td> 6.59</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>54.20</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 5.70000</td></tr>\n",
       "\t<tr><td>4.852030</td><td>0</td><td> 0.00</td><td>11.52</td><td>0</td><td>0</td><td> 9.79</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>61.41</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 6.46000</td></tr>\n",
       "\t<tr><td>3.737670</td><td>0</td><td> 0.00</td><td>18.31</td><td>0</td><td>0</td><td> 0.00</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>59.37</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>0.00</td><td> 3.41000</td></tr>\n",
       "\t<tr><td>3.295837</td><td>0</td><td> 4.05</td><td>14.56</td><td>0</td><td>0</td><td> 2.58</td><td>0.03</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>46.42</td><td>0</td><td>0.00</td><td>0</td><td>0</td><td>1.36</td><td>12.23000</td></tr>\n",
       "\t<tr><td>3.295837</td><td>0</td><td> 1.70</td><td>12.00</td><td>0</td><td>0</td><td> 4.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>52.00</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>12.20000</td></tr>\n",
       "\t<tr><td>3.295837</td><td>0</td><td> 1.70</td><td>12.00</td><td>0</td><td>0</td><td> 4.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>52.00</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>12.20000</td></tr>\n",
       "\t<tr><td>3.806662</td><td>0</td><td> 6.30</td><td>12.00</td><td>0</td><td>0</td><td> 4.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>43.32</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>15.95000</td></tr>\n",
       "\t<tr><td>3.806662</td><td>0</td><td> 6.30</td><td>12.00</td><td>0</td><td>0</td><td> 4.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>43.32</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>15.95000</td></tr>\n",
       "\t<tr><td>2.639057</td><td>0</td><td> 6.30</td><td>17.00</td><td>0</td><td>0</td><td> 4.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>43.57</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>10.45000</td></tr>\n",
       "\t<tr><td>2.772589</td><td>0</td><td> 1.70</td><td>13.69</td><td>0</td><td>0</td><td> 1.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>43.06</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>18.95000</td></tr>\n",
       "\t<tr><td>3.496508</td><td>0</td><td> 6.30</td><td>15.98</td><td>0</td><td>0</td><td> 4.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>52.17</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td> 7.45000</td></tr>\n",
       "\t<tr><td>3.091042</td><td>0</td><td> 1.70</td><td>12.20</td><td>0</td><td>0</td><td> 1.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>44.55</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>23.45000</td></tr>\n",
       "\t<tr><td>3.332205</td><td>0</td><td> 6.30</td><td>12.00</td><td>0</td><td>0</td><td> 1.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>50.24</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>10.45000</td></tr>\n",
       "\t<tr><td>3.583519</td><td>0</td><td> 6.30</td><td>12.13</td><td>0</td><td>0</td><td> 1.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>47.35</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>11.95000</td></tr>\n",
       "\t<tr><td>2.639057</td><td>0</td><td> 6.08</td><td>12.00</td><td>0</td><td>0</td><td> 1.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>43.99</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>14.95000</td></tr>\n",
       "\t<tr><td>2.639057</td><td>0</td><td> 6.08</td><td>12.00</td><td>0</td><td>0</td><td> 1.50</td><td>0.00</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>43.99</td><td>0</td><td>0.20</td><td>0</td><td>0</td><td>1.40</td><td>14.95000</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>3.4657359</td><td>0</td><td> 2.661493</td><td> 7.900911</td><td>0.0488921</td><td>0</td><td>0.6522875</td><td>0.5007826</td><td>0.00</td><td>0</td><td>...</td><td>0</td><td>0.1200227</td><td>0</td><td>41.58756</td><td>0</td><td>0.1220579</td><td> 0.00</td><td>0.00</td><td> 9.049536</td><td>22.20093</td></tr>\n",
       "\t<tr><td>3.0445224</td><td>0</td><td> 7.530000</td><td> 8.350000</td><td>1.4500000</td><td>0</td><td>2.8500000</td><td>0.2800000</td><td>0.18</td><td>0</td><td>...</td><td>0</td><td>1.1500000</td><td>0</td><td>30.86000</td><td>0</td><td>0.4600000</td><td> 0.18</td><td>0.00</td><td> 5.760000</td><td>25.61000</td></tr>\n",
       "\t<tr><td>3.1780538</td><td>0</td><td> 7.530000</td><td>13.450000</td><td>1.4500000</td><td>0</td><td>2.8500000</td><td>0.2800000</td><td>0.18</td><td>0</td><td>...</td><td>0</td><td>1.1500000</td><td>0</td><td>30.86000</td><td>0</td><td>0.4600000</td><td> 0.18</td><td>0.00</td><td> 5.760000</td><td>25.62000</td></tr>\n",
       "\t<tr><td>3.1354942</td><td>0</td><td> 7.530000</td><td> 8.350000</td><td>1.4500000</td><td>0</td><td>7.9600000</td><td>0.2800000</td><td>0.18</td><td>0</td><td>...</td><td>0</td><td>1.1500000</td><td>0</td><td>30.86000</td><td>0</td><td>0.4600000</td><td> 0.18</td><td>0.00</td><td> 5.760000</td><td>25.61000</td></tr>\n",
       "\t<tr><td>2.6390573</td><td>0</td><td> 7.530000</td><td> 8.350000</td><td>1.4500000</td><td>0</td><td>2.8500000</td><td>0.2800000</td><td>0.18</td><td>0</td><td>...</td><td>0</td><td>1.1500000</td><td>0</td><td>32.90000</td><td>0</td><td>0.4600000</td><td> 0.18</td><td>0.00</td><td> 5.760000</td><td>25.62000</td></tr>\n",
       "\t<tr><td>1.9459101</td><td>0</td><td> 3.280000</td><td> 6.790000</td><td>2.0900000</td><td>0</td><td>0.0000000</td><td>0.4100000</td><td>0.26</td><td>0</td><td>...</td><td>0</td><td>1.6500000</td><td>0</td><td>32.02000</td><td>0</td><td>0.6700000</td><td> 3.07</td><td>0.00</td><td> 0.000000</td><td>38.50000</td></tr>\n",
       "\t<tr><td>2.3025851</td><td>0</td><td> 3.200000</td><td> 9.690000</td><td>2.0400000</td><td>0</td><td>0.0000000</td><td>0.4000000</td><td>0.25</td><td>0</td><td>...</td><td>0</td><td>1.6100000</td><td>0</td><td>31.99000</td><td>0</td><td>0.6500000</td><td> 3.06</td><td>0.00</td><td> 0.000000</td><td>38.79000</td></tr>\n",
       "\t<tr><td>2.0794415</td><td>0</td><td> 3.200000</td><td> 4.850000</td><td>2.0400000</td><td>0</td><td>0.0000000</td><td>0.4000000</td><td>0.25</td><td>0</td><td>...</td><td>0</td><td>1.6100000</td><td>0</td><td>31.99000</td><td>0</td><td>0.6500000</td><td> 3.06</td><td>0.00</td><td> 0.000000</td><td>38.78000</td></tr>\n",
       "\t<tr><td>2.8332133</td><td>0</td><td>11.770000</td><td> 6.070000</td><td>0.0600000</td><td>0</td><td>1.6300000</td><td>0.1400000</td><td>0.00</td><td>0</td><td>...</td><td>0</td><td>1.0700000</td><td>0</td><td>28.45000</td><td>0</td><td>0.0500000</td><td> 2.57</td><td>0.00</td><td> 0.180000</td><td>28.99000</td></tr>\n",
       "\t<tr><td>1.7917595</td><td>0</td><td> 3.820000</td><td> 6.680000</td><td>0.0000000</td><td>0</td><td>7.6300000</td><td>0.6500000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>29.57000</td><td>0</td><td>0.0000000</td><td> 1.82</td><td>0.00</td><td> 0.000000</td><td>32.71000</td></tr>\n",
       "\t<tr><td>2.0794415</td><td>0</td><td> 3.780000</td><td>16.060000</td><td>0.0000000</td><td>0</td><td>0.0000000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>27.40000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td>12.280000</td><td>19.46000</td></tr>\n",
       "\t<tr><td>1.7917595</td><td>0</td><td> 3.780000</td><td>16.060000</td><td>0.0000000</td><td>0</td><td>0.0000000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>28.35000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td> 0.000000</td><td>35.51000</td></tr>\n",
       "\t<tr><td>3.8501476</td><td>0</td><td>16.040000</td><td>15.100000</td><td>0.0000000</td><td>0</td><td>0.0000000</td><td>0.6500000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>23.59000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td>12.270000</td><td>14.52000</td></tr>\n",
       "\t<tr><td>0.6931472</td><td>0</td><td> 3.780000</td><td> 6.610000</td><td>0.0000000</td><td>0</td><td>7.5600000</td><td>0.6500000</td><td>0.63</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>23.62000</td><td>0</td><td>1.2700000</td><td> 2.64</td><td>0.00</td><td> 0.000000</td><td>29.96000</td></tr>\n",
       "\t<tr><td>2.1972246</td><td>0</td><td> 9.970000</td><td>15.260000</td><td>0.0500000</td><td>0</td><td>0.5500000</td><td>0.1200000</td><td>0.05</td><td>0</td><td>...</td><td>0</td><td>0.7800000</td><td>0</td><td>30.71000</td><td>0</td><td>0.0400000</td><td> 2.06</td><td>0.01</td><td> 0.150000</td><td>24.64000</td></tr>\n",
       "\t<tr><td>1.6094379</td><td>0</td><td> 6.030000</td><td>15.490000</td><td>0.4400000</td><td>0</td><td>1.3200000</td><td>0.3100000</td><td>0.15</td><td>0</td><td>...</td><td>0</td><td>0.8800000</td><td>0</td><td>32.00000</td><td>0</td><td>0.4400000</td><td> 2.75</td><td>0.00</td><td> 0.090000</td><td>21.41000</td></tr>\n",
       "\t<tr><td>2.0794415</td><td>0</td><td> 6.060000</td><td>11.070000</td><td>0.4400000</td><td>0</td><td>6.3400000</td><td>0.3100000</td><td>0.15</td><td>0</td><td>...</td><td>0</td><td>0.8800000</td><td>0</td><td>33.24000</td><td>0</td><td>0.4400000</td><td> 2.76</td><td>0.00</td><td> 0.090000</td><td>21.50000</td></tr>\n",
       "\t<tr><td>2.1972246</td><td>0</td><td> 1.740000</td><td> 5.990000</td><td>1.8600000</td><td>0</td><td>0.0000000</td><td>0.7300000</td><td>0.23</td><td>0</td><td>...</td><td>0</td><td>1.4700000</td><td>0</td><td>29.96000</td><td>0</td><td>0.7400000</td><td> 3.13</td><td>0.00</td><td> 0.000000</td><td>42.98000</td></tr>\n",
       "\t<tr><td>3.2580965</td><td>0</td><td>16.060000</td><td> 6.610000</td><td>0.0000000</td><td>0</td><td>7.5600000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>27.40000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td> 0.000000</td><td>16.62000</td></tr>\n",
       "\t<tr><td>1.9459101</td><td>0</td><td> 8.500000</td><td> 6.610000</td><td>3.8600000</td><td>0</td><td>0.0000000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>3.0500000</td><td>0</td><td>23.62000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td> 0.000000</td><td>30.40000</td></tr>\n",
       "\t<tr><td>2.6390573</td><td>0</td><td> 3.780000</td><td> 6.610000</td><td>0.0000000</td><td>0</td><td>7.5600000</td><td>0.6500000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>23.62000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td>12.280000</td><td>18.23000</td></tr>\n",
       "\t<tr><td>2.8332133</td><td>0</td><td> 8.320000</td><td> 7.070000</td><td>1.0100000</td><td>0</td><td>2.0400000</td><td>0.2000000</td><td>0.13</td><td>0</td><td>...</td><td>0</td><td>1.8800000</td><td>0</td><td>30.18000</td><td>0</td><td>0.3900000</td><td> 2.49</td><td>0.00</td><td> 4.030000</td><td>19.32000</td></tr>\n",
       "\t<tr><td>3.5835189</td><td>0</td><td> 4.660000</td><td> 7.140000</td><td>1.2900000</td><td>0</td><td>0.0400000</td><td>0.2500000</td><td>0.16</td><td>0</td><td>...</td><td>0</td><td>1.9500000</td><td>0</td><td>40.04000</td><td>0</td><td>0.4700000</td><td> 1.95</td><td>0.00</td><td> 0.010000</td><td>23.90000</td></tr>\n",
       "\t<tr><td>3.0445224</td><td>0</td><td>16.220000</td><td> 7.630000</td><td>3.9000000</td><td>0</td><td>7.6300000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>3.0800000</td><td>0</td><td>29.57000</td><td>0</td><td>0.0000000</td><td> 1.82</td><td>0.00</td><td> 0.000000</td><td>17.32000</td></tr>\n",
       "\t<tr><td>1.9459101</td><td>0</td><td>16.060000</td><td>16.060000</td><td>0.0000000</td><td>0</td><td>7.5600000</td><td>0.0000000</td><td>0.63</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>23.62000</td><td>0</td><td>1.2700000</td><td> 2.28</td><td>0.00</td><td> 0.000000</td><td>18.69000</td></tr>\n",
       "\t<tr><td>1.7917595</td><td>0</td><td> 3.780000</td><td>16.060000</td><td>3.8600000</td><td>0</td><td>7.5600000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>3.0500000</td><td>0</td><td>29.29000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td>10.390000</td><td>11.50000</td></tr>\n",
       "\t<tr><td>2.6390573</td><td>0</td><td>16.060000</td><td>11.340000</td><td>0.0000000</td><td>0</td><td>0.0000000</td><td>0.0000000</td><td>0.14</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>29.29000</td><td>0</td><td>0.0000000</td><td> 1.80</td><td>0.00</td><td> 0.000000</td><td>19.35000</td></tr>\n",
       "\t<tr><td>3.8712010</td><td>0</td><td>17.080000</td><td> 8.870000</td><td>0.3200000</td><td>0</td><td>1.4700000</td><td>0.7700000</td><td>0.10</td><td>0</td><td>...</td><td>0</td><td>0.8400000</td><td>0</td><td>28.63000</td><td>0</td><td>0.3200000</td><td> 2.27</td><td>0.00</td><td> 0.160000</td><td>15.75000</td></tr>\n",
       "\t<tr><td>1.7917595</td><td>0</td><td> 5.000000</td><td>10.000000</td><td>0.0000000</td><td>0</td><td>0.0000000</td><td>0.0000000</td><td>0.00</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>30.00000</td><td>0</td><td>0.0000000</td><td>29.90</td><td>0.00</td><td> 7.000000</td><td> 0.00000</td></tr>\n",
       "\t<tr><td>3.6375862</td><td>0</td><td>13.200000</td><td>10.000000</td><td>0.0000000</td><td>0</td><td>0.0000000</td><td>0.0000000</td><td>0.00</td><td>0</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>37.60000</td><td>0</td><td>0.0000000</td><td>21.10</td><td>0.00</td><td> 4.000000</td><td> 0.00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6987 × 30\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " vis & X\\_\\_3 & X\\_\\_4 & X\\_\\_8 & X\\_\\_10 & X\\_\\_17 & X\\_\\_18 & X\\_\\_29 & X\\_\\_30 & X\\_\\_43 & ... & X\\_\\_84 & X\\_\\_86 & X\\_\\_106 & X\\_\\_109 & X\\_\\_113 & X\\_\\_115 & X\\_\\_117 & X\\_\\_133 & X\\_\\_138 & autres\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 7.795647 & 0 &  9.42 &  8.52 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 68.39 & 0 & 0.00 & 0 & 0 & 0.00 &  0.00000\\\\\n",
       "\t 8.396832 & 0 &  9.42 &  8.53 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 70.32 & 0 & 0.00 & 0 & 0 & 0.00 &  0.00000\\\\\n",
       "\t 3.218876 & 0 &  3.58 & 14.25 & 0 & 0 &  1.88 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 45.42 & 0 & 0.00 & 0 & 0 & 1.34 & 15.80000\\\\\n",
       "\t 3.044522 & 0 &  3.81 & 14.08 & 0 & 0 &  3.30 & 0.09 & 0 & 0 & ... & 0 & 0 & 0 & 45.55 & 0 & 0.08 & 0 & 0 & 1.24 & 16.88000\\\\\n",
       "\t 4.158883 & 0 &  0.00 &  0.00 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 66.51 & 0 & 0.00 & 0 & 0 & 0.00 &  0.01000\\\\\n",
       "\t 4.369448 & 0 &  3.00 & 18.00 & 0 & 0 &  2.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 56.00 & 0 & 0.00 & 0 & 0 & 2.00 &  6.00000\\\\\n",
       "\t 8.676587 & 0 &  9.43 &  8.53 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 71.50 & 0 & 0.00 & 0 & 0 & 0.00 &  0.00000\\\\\n",
       "\t 6.852243 & 0 &  0.00 &  0.00 & 0 & 0 & 10.60 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 74.85 & 0 & 0.00 & 0 & 0 & 0.00 &  0.15000\\\\\n",
       "\t 5.568345 & 0 &  0.00 &  0.00 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 70.37 & 0 & 0.00 & 0 & 0 & 0.00 &  0.00000\\\\\n",
       "\t 4.795791 & 0 &  0.00 &  0.00 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 64.46 & 0 & 0.00 & 0 & 0 & 0.00 &  0.00000\\\\\n",
       "\t 6.817831 & 0 &  0.22 &  0.00 & 0 & 0 &  0.15 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 55.91 & 0 & 0.00 & 0 & 0 & 0.00 & 31.55000\\\\\n",
       "\t 6.287859 & 0 &  0.00 &  0.00 & 0 & 0 &  2.70 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 59.75 & 0 & 0.00 & 0 & 0 & 0.00 & 26.15000\\\\\n",
       "\t 6.856462 & 0 &  3.72 &  0.00 & 0 & 0 &  8.69 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 68.52 & 0 & 0.00 & 0 & 0 & 0.00 &  0.44000\\\\\n",
       "\t 8.706159 & 0 & 22.43 &  3.00 & 0 & 0 &  5.90 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 58.77 & 0 & 0.00 & 0 & 0 & 0.00 &  0.18499\\\\\n",
       "\t 3.737670 & 0 &  0.00 & 21.70 & 0 & 0 &  6.59 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 54.20 & 0 & 0.00 & 0 & 0 & 0.00 &  5.70000\\\\\n",
       "\t 4.852030 & 0 &  0.00 & 11.52 & 0 & 0 &  9.79 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 61.41 & 0 & 0.00 & 0 & 0 & 0.00 &  6.46000\\\\\n",
       "\t 3.737670 & 0 &  0.00 & 18.31 & 0 & 0 &  0.00 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 59.37 & 0 & 0.00 & 0 & 0 & 0.00 &  3.41000\\\\\n",
       "\t 3.295837 & 0 &  4.05 & 14.56 & 0 & 0 &  2.58 & 0.03 & 0 & 0 & ... & 0 & 0 & 0 & 46.42 & 0 & 0.00 & 0 & 0 & 1.36 & 12.23000\\\\\n",
       "\t 3.295837 & 0 &  1.70 & 12.00 & 0 & 0 &  4.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 52.00 & 0 & 0.20 & 0 & 0 & 1.40 & 12.20000\\\\\n",
       "\t 3.295837 & 0 &  1.70 & 12.00 & 0 & 0 &  4.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 52.00 & 0 & 0.20 & 0 & 0 & 1.40 & 12.20000\\\\\n",
       "\t 3.806662 & 0 &  6.30 & 12.00 & 0 & 0 &  4.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 43.32 & 0 & 0.20 & 0 & 0 & 1.40 & 15.95000\\\\\n",
       "\t 3.806662 & 0 &  6.30 & 12.00 & 0 & 0 &  4.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 43.32 & 0 & 0.20 & 0 & 0 & 1.40 & 15.95000\\\\\n",
       "\t 2.639057 & 0 &  6.30 & 17.00 & 0 & 0 &  4.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 43.57 & 0 & 0.20 & 0 & 0 & 1.40 & 10.45000\\\\\n",
       "\t 2.772589 & 0 &  1.70 & 13.69 & 0 & 0 &  1.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 43.06 & 0 & 0.20 & 0 & 0 & 1.40 & 18.95000\\\\\n",
       "\t 3.496508 & 0 &  6.30 & 15.98 & 0 & 0 &  4.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 52.17 & 0 & 0.20 & 0 & 0 & 1.40 &  7.45000\\\\\n",
       "\t 3.091042 & 0 &  1.70 & 12.20 & 0 & 0 &  1.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 44.55 & 0 & 0.20 & 0 & 0 & 1.40 & 23.45000\\\\\n",
       "\t 3.332205 & 0 &  6.30 & 12.00 & 0 & 0 &  1.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 50.24 & 0 & 0.20 & 0 & 0 & 1.40 & 10.45000\\\\\n",
       "\t 3.583519 & 0 &  6.30 & 12.13 & 0 & 0 &  1.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 47.35 & 0 & 0.20 & 0 & 0 & 1.40 & 11.95000\\\\\n",
       "\t 2.639057 & 0 &  6.08 & 12.00 & 0 & 0 &  1.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 43.99 & 0 & 0.20 & 0 & 0 & 1.40 & 14.95000\\\\\n",
       "\t 2.639057 & 0 &  6.08 & 12.00 & 0 & 0 &  1.50 & 0.00 & 0 & 0 & ... & 0 & 0 & 0 & 43.99 & 0 & 0.20 & 0 & 0 & 1.40 & 14.95000\\\\\n",
       "\t ... & ... & ... & ... & ... & ... & ... & ... & ... & ... &  & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t 3.4657359 & 0 &  2.661493 &  7.900911 & 0.0488921 & 0 & 0.6522875 & 0.5007826 & 0.00 & 0 & ... & 0 & 0.1200227 & 0 & 41.58756 & 0 & 0.1220579 &  0.00 & 0.00 &  9.049536 & 22.20093\\\\\n",
       "\t 3.0445224 & 0 &  7.530000 &  8.350000 & 1.4500000 & 0 & 2.8500000 & 0.2800000 & 0.18 & 0 & ... & 0 & 1.1500000 & 0 & 30.86000 & 0 & 0.4600000 &  0.18 & 0.00 &  5.760000 & 25.61000\\\\\n",
       "\t 3.1780538 & 0 &  7.530000 & 13.450000 & 1.4500000 & 0 & 2.8500000 & 0.2800000 & 0.18 & 0 & ... & 0 & 1.1500000 & 0 & 30.86000 & 0 & 0.4600000 &  0.18 & 0.00 &  5.760000 & 25.62000\\\\\n",
       "\t 3.1354942 & 0 &  7.530000 &  8.350000 & 1.4500000 & 0 & 7.9600000 & 0.2800000 & 0.18 & 0 & ... & 0 & 1.1500000 & 0 & 30.86000 & 0 & 0.4600000 &  0.18 & 0.00 &  5.760000 & 25.61000\\\\\n",
       "\t 2.6390573 & 0 &  7.530000 &  8.350000 & 1.4500000 & 0 & 2.8500000 & 0.2800000 & 0.18 & 0 & ... & 0 & 1.1500000 & 0 & 32.90000 & 0 & 0.4600000 &  0.18 & 0.00 &  5.760000 & 25.62000\\\\\n",
       "\t 1.9459101 & 0 &  3.280000 &  6.790000 & 2.0900000 & 0 & 0.0000000 & 0.4100000 & 0.26 & 0 & ... & 0 & 1.6500000 & 0 & 32.02000 & 0 & 0.6700000 &  3.07 & 0.00 &  0.000000 & 38.50000\\\\\n",
       "\t 2.3025851 & 0 &  3.200000 &  9.690000 & 2.0400000 & 0 & 0.0000000 & 0.4000000 & 0.25 & 0 & ... & 0 & 1.6100000 & 0 & 31.99000 & 0 & 0.6500000 &  3.06 & 0.00 &  0.000000 & 38.79000\\\\\n",
       "\t 2.0794415 & 0 &  3.200000 &  4.850000 & 2.0400000 & 0 & 0.0000000 & 0.4000000 & 0.25 & 0 & ... & 0 & 1.6100000 & 0 & 31.99000 & 0 & 0.6500000 &  3.06 & 0.00 &  0.000000 & 38.78000\\\\\n",
       "\t 2.8332133 & 0 & 11.770000 &  6.070000 & 0.0600000 & 0 & 1.6300000 & 0.1400000 & 0.00 & 0 & ... & 0 & 1.0700000 & 0 & 28.45000 & 0 & 0.0500000 &  2.57 & 0.00 &  0.180000 & 28.99000\\\\\n",
       "\t 1.7917595 & 0 &  3.820000 &  6.680000 & 0.0000000 & 0 & 7.6300000 & 0.6500000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 29.57000 & 0 & 0.0000000 &  1.82 & 0.00 &  0.000000 & 32.71000\\\\\n",
       "\t 2.0794415 & 0 &  3.780000 & 16.060000 & 0.0000000 & 0 & 0.0000000 & 0.0000000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 27.40000 & 0 & 0.0000000 &  1.80 & 0.00 & 12.280000 & 19.46000\\\\\n",
       "\t 1.7917595 & 0 &  3.780000 & 16.060000 & 0.0000000 & 0 & 0.0000000 & 0.0000000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 28.35000 & 0 & 0.0000000 &  1.80 & 0.00 &  0.000000 & 35.51000\\\\\n",
       "\t 3.8501476 & 0 & 16.040000 & 15.100000 & 0.0000000 & 0 & 0.0000000 & 0.6500000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 23.59000 & 0 & 0.0000000 &  1.80 & 0.00 & 12.270000 & 14.52000\\\\\n",
       "\t 0.6931472 & 0 &  3.780000 &  6.610000 & 0.0000000 & 0 & 7.5600000 & 0.6500000 & 0.63 & 0 & ... & 0 & 0.0000000 & 0 & 23.62000 & 0 & 1.2700000 &  2.64 & 0.00 &  0.000000 & 29.96000\\\\\n",
       "\t 2.1972246 & 0 &  9.970000 & 15.260000 & 0.0500000 & 0 & 0.5500000 & 0.1200000 & 0.05 & 0 & ... & 0 & 0.7800000 & 0 & 30.71000 & 0 & 0.0400000 &  2.06 & 0.01 &  0.150000 & 24.64000\\\\\n",
       "\t 1.6094379 & 0 &  6.030000 & 15.490000 & 0.4400000 & 0 & 1.3200000 & 0.3100000 & 0.15 & 0 & ... & 0 & 0.8800000 & 0 & 32.00000 & 0 & 0.4400000 &  2.75 & 0.00 &  0.090000 & 21.41000\\\\\n",
       "\t 2.0794415 & 0 &  6.060000 & 11.070000 & 0.4400000 & 0 & 6.3400000 & 0.3100000 & 0.15 & 0 & ... & 0 & 0.8800000 & 0 & 33.24000 & 0 & 0.4400000 &  2.76 & 0.00 &  0.090000 & 21.50000\\\\\n",
       "\t 2.1972246 & 0 &  1.740000 &  5.990000 & 1.8600000 & 0 & 0.0000000 & 0.7300000 & 0.23 & 0 & ... & 0 & 1.4700000 & 0 & 29.96000 & 0 & 0.7400000 &  3.13 & 0.00 &  0.000000 & 42.98000\\\\\n",
       "\t 3.2580965 & 0 & 16.060000 &  6.610000 & 0.0000000 & 0 & 7.5600000 & 0.0000000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 27.40000 & 0 & 0.0000000 &  1.80 & 0.00 &  0.000000 & 16.62000\\\\\n",
       "\t 1.9459101 & 0 &  8.500000 &  6.610000 & 3.8600000 & 0 & 0.0000000 & 0.0000000 & 0.14 & 0 & ... & 0 & 3.0500000 & 0 & 23.62000 & 0 & 0.0000000 &  1.80 & 0.00 &  0.000000 & 30.40000\\\\\n",
       "\t 2.6390573 & 0 &  3.780000 &  6.610000 & 0.0000000 & 0 & 7.5600000 & 0.6500000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 23.62000 & 0 & 0.0000000 &  1.80 & 0.00 & 12.280000 & 18.23000\\\\\n",
       "\t 2.8332133 & 0 &  8.320000 &  7.070000 & 1.0100000 & 0 & 2.0400000 & 0.2000000 & 0.13 & 0 & ... & 0 & 1.8800000 & 0 & 30.18000 & 0 & 0.3900000 &  2.49 & 0.00 &  4.030000 & 19.32000\\\\\n",
       "\t 3.5835189 & 0 &  4.660000 &  7.140000 & 1.2900000 & 0 & 0.0400000 & 0.2500000 & 0.16 & 0 & ... & 0 & 1.9500000 & 0 & 40.04000 & 0 & 0.4700000 &  1.95 & 0.00 &  0.010000 & 23.90000\\\\\n",
       "\t 3.0445224 & 0 & 16.220000 &  7.630000 & 3.9000000 & 0 & 7.6300000 & 0.0000000 & 0.14 & 0 & ... & 0 & 3.0800000 & 0 & 29.57000 & 0 & 0.0000000 &  1.82 & 0.00 &  0.000000 & 17.32000\\\\\n",
       "\t 1.9459101 & 0 & 16.060000 & 16.060000 & 0.0000000 & 0 & 7.5600000 & 0.0000000 & 0.63 & 0 & ... & 0 & 0.0000000 & 0 & 23.62000 & 0 & 1.2700000 &  2.28 & 0.00 &  0.000000 & 18.69000\\\\\n",
       "\t 1.7917595 & 0 &  3.780000 & 16.060000 & 3.8600000 & 0 & 7.5600000 & 0.0000000 & 0.14 & 0 & ... & 0 & 3.0500000 & 0 & 29.29000 & 0 & 0.0000000 &  1.80 & 0.00 & 10.390000 & 11.50000\\\\\n",
       "\t 2.6390573 & 0 & 16.060000 & 11.340000 & 0.0000000 & 0 & 0.0000000 & 0.0000000 & 0.14 & 0 & ... & 0 & 0.0000000 & 0 & 29.29000 & 0 & 0.0000000 &  1.80 & 0.00 &  0.000000 & 19.35000\\\\\n",
       "\t 3.8712010 & 0 & 17.080000 &  8.870000 & 0.3200000 & 0 & 1.4700000 & 0.7700000 & 0.10 & 0 & ... & 0 & 0.8400000 & 0 & 28.63000 & 0 & 0.3200000 &  2.27 & 0.00 &  0.160000 & 15.75000\\\\\n",
       "\t 1.7917595 & 0 &  5.000000 & 10.000000 & 0.0000000 & 0 & 0.0000000 & 0.0000000 & 0.00 & 0 & ... & 0 & 0.0000000 & 0 & 30.00000 & 0 & 0.0000000 & 29.90 & 0.00 &  7.000000 &  0.00000\\\\\n",
       "\t 3.6375862 & 0 & 13.200000 & 10.000000 & 0.0000000 & 0 & 0.0000000 & 0.0000000 & 0.00 & 0 & ... & 0 & 0.0000000 & 0 & 37.60000 & 0 & 0.0000000 & 21.10 & 0.00 &  4.000000 &  0.00000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6987 × 30\n",
       "\n",
       "| vis &lt;dbl&gt; | X__3 &lt;dbl&gt; | X__4 &lt;dbl&gt; | X__8 &lt;dbl&gt; | X__10 &lt;dbl&gt; | X__17 &lt;dbl&gt; | X__18 &lt;dbl&gt; | X__29 &lt;dbl&gt; | X__30 &lt;dbl&gt; | X__43 &lt;dbl&gt; | ... ... | X__84 &lt;dbl&gt; | X__86 &lt;dbl&gt; | X__106 &lt;dbl&gt; | X__109 &lt;dbl&gt; | X__113 &lt;dbl&gt; | X__115 &lt;dbl&gt; | X__117 &lt;dbl&gt; | X__133 &lt;dbl&gt; | X__138 &lt;dbl&gt; | autres &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 7.795647 | 0 |  9.42 |  8.52 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 68.39 | 0 | 0.00 | 0 | 0 | 0.00 |  0.00000 |\n",
       "| 8.396832 | 0 |  9.42 |  8.53 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 70.32 | 0 | 0.00 | 0 | 0 | 0.00 |  0.00000 |\n",
       "| 3.218876 | 0 |  3.58 | 14.25 | 0 | 0 |  1.88 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 45.42 | 0 | 0.00 | 0 | 0 | 1.34 | 15.80000 |\n",
       "| 3.044522 | 0 |  3.81 | 14.08 | 0 | 0 |  3.30 | 0.09 | 0 | 0 | ... | 0 | 0 | 0 | 45.55 | 0 | 0.08 | 0 | 0 | 1.24 | 16.88000 |\n",
       "| 4.158883 | 0 |  0.00 |  0.00 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 66.51 | 0 | 0.00 | 0 | 0 | 0.00 |  0.01000 |\n",
       "| 4.369448 | 0 |  3.00 | 18.00 | 0 | 0 |  2.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 56.00 | 0 | 0.00 | 0 | 0 | 2.00 |  6.00000 |\n",
       "| 8.676587 | 0 |  9.43 |  8.53 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 71.50 | 0 | 0.00 | 0 | 0 | 0.00 |  0.00000 |\n",
       "| 6.852243 | 0 |  0.00 |  0.00 | 0 | 0 | 10.60 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 74.85 | 0 | 0.00 | 0 | 0 | 0.00 |  0.15000 |\n",
       "| 5.568345 | 0 |  0.00 |  0.00 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 70.37 | 0 | 0.00 | 0 | 0 | 0.00 |  0.00000 |\n",
       "| 4.795791 | 0 |  0.00 |  0.00 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 64.46 | 0 | 0.00 | 0 | 0 | 0.00 |  0.00000 |\n",
       "| 6.817831 | 0 |  0.22 |  0.00 | 0 | 0 |  0.15 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 55.91 | 0 | 0.00 | 0 | 0 | 0.00 | 31.55000 |\n",
       "| 6.287859 | 0 |  0.00 |  0.00 | 0 | 0 |  2.70 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 59.75 | 0 | 0.00 | 0 | 0 | 0.00 | 26.15000 |\n",
       "| 6.856462 | 0 |  3.72 |  0.00 | 0 | 0 |  8.69 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 68.52 | 0 | 0.00 | 0 | 0 | 0.00 |  0.44000 |\n",
       "| 8.706159 | 0 | 22.43 |  3.00 | 0 | 0 |  5.90 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 58.77 | 0 | 0.00 | 0 | 0 | 0.00 |  0.18499 |\n",
       "| 3.737670 | 0 |  0.00 | 21.70 | 0 | 0 |  6.59 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 54.20 | 0 | 0.00 | 0 | 0 | 0.00 |  5.70000 |\n",
       "| 4.852030 | 0 |  0.00 | 11.52 | 0 | 0 |  9.79 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 61.41 | 0 | 0.00 | 0 | 0 | 0.00 |  6.46000 |\n",
       "| 3.737670 | 0 |  0.00 | 18.31 | 0 | 0 |  0.00 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 59.37 | 0 | 0.00 | 0 | 0 | 0.00 |  3.41000 |\n",
       "| 3.295837 | 0 |  4.05 | 14.56 | 0 | 0 |  2.58 | 0.03 | 0 | 0 | ... | 0 | 0 | 0 | 46.42 | 0 | 0.00 | 0 | 0 | 1.36 | 12.23000 |\n",
       "| 3.295837 | 0 |  1.70 | 12.00 | 0 | 0 |  4.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 52.00 | 0 | 0.20 | 0 | 0 | 1.40 | 12.20000 |\n",
       "| 3.295837 | 0 |  1.70 | 12.00 | 0 | 0 |  4.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 52.00 | 0 | 0.20 | 0 | 0 | 1.40 | 12.20000 |\n",
       "| 3.806662 | 0 |  6.30 | 12.00 | 0 | 0 |  4.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 43.32 | 0 | 0.20 | 0 | 0 | 1.40 | 15.95000 |\n",
       "| 3.806662 | 0 |  6.30 | 12.00 | 0 | 0 |  4.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 43.32 | 0 | 0.20 | 0 | 0 | 1.40 | 15.95000 |\n",
       "| 2.639057 | 0 |  6.30 | 17.00 | 0 | 0 |  4.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 43.57 | 0 | 0.20 | 0 | 0 | 1.40 | 10.45000 |\n",
       "| 2.772589 | 0 |  1.70 | 13.69 | 0 | 0 |  1.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 43.06 | 0 | 0.20 | 0 | 0 | 1.40 | 18.95000 |\n",
       "| 3.496508 | 0 |  6.30 | 15.98 | 0 | 0 |  4.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 52.17 | 0 | 0.20 | 0 | 0 | 1.40 |  7.45000 |\n",
       "| 3.091042 | 0 |  1.70 | 12.20 | 0 | 0 |  1.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 44.55 | 0 | 0.20 | 0 | 0 | 1.40 | 23.45000 |\n",
       "| 3.332205 | 0 |  6.30 | 12.00 | 0 | 0 |  1.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 50.24 | 0 | 0.20 | 0 | 0 | 1.40 | 10.45000 |\n",
       "| 3.583519 | 0 |  6.30 | 12.13 | 0 | 0 |  1.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 47.35 | 0 | 0.20 | 0 | 0 | 1.40 | 11.95000 |\n",
       "| 2.639057 | 0 |  6.08 | 12.00 | 0 | 0 |  1.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 43.99 | 0 | 0.20 | 0 | 0 | 1.40 | 14.95000 |\n",
       "| 2.639057 | 0 |  6.08 | 12.00 | 0 | 0 |  1.50 | 0.00 | 0 | 0 | ... | 0 | 0 | 0 | 43.99 | 0 | 0.20 | 0 | 0 | 1.40 | 14.95000 |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | <!----> | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "| 3.4657359 | 0 |  2.661493 |  7.900911 | 0.0488921 | 0 | 0.6522875 | 0.5007826 | 0.00 | 0 | ... | 0 | 0.1200227 | 0 | 41.58756 | 0 | 0.1220579 |  0.00 | 0.00 |  9.049536 | 22.20093 |\n",
       "| 3.0445224 | 0 |  7.530000 |  8.350000 | 1.4500000 | 0 | 2.8500000 | 0.2800000 | 0.18 | 0 | ... | 0 | 1.1500000 | 0 | 30.86000 | 0 | 0.4600000 |  0.18 | 0.00 |  5.760000 | 25.61000 |\n",
       "| 3.1780538 | 0 |  7.530000 | 13.450000 | 1.4500000 | 0 | 2.8500000 | 0.2800000 | 0.18 | 0 | ... | 0 | 1.1500000 | 0 | 30.86000 | 0 | 0.4600000 |  0.18 | 0.00 |  5.760000 | 25.62000 |\n",
       "| 3.1354942 | 0 |  7.530000 |  8.350000 | 1.4500000 | 0 | 7.9600000 | 0.2800000 | 0.18 | 0 | ... | 0 | 1.1500000 | 0 | 30.86000 | 0 | 0.4600000 |  0.18 | 0.00 |  5.760000 | 25.61000 |\n",
       "| 2.6390573 | 0 |  7.530000 |  8.350000 | 1.4500000 | 0 | 2.8500000 | 0.2800000 | 0.18 | 0 | ... | 0 | 1.1500000 | 0 | 32.90000 | 0 | 0.4600000 |  0.18 | 0.00 |  5.760000 | 25.62000 |\n",
       "| 1.9459101 | 0 |  3.280000 |  6.790000 | 2.0900000 | 0 | 0.0000000 | 0.4100000 | 0.26 | 0 | ... | 0 | 1.6500000 | 0 | 32.02000 | 0 | 0.6700000 |  3.07 | 0.00 |  0.000000 | 38.50000 |\n",
       "| 2.3025851 | 0 |  3.200000 |  9.690000 | 2.0400000 | 0 | 0.0000000 | 0.4000000 | 0.25 | 0 | ... | 0 | 1.6100000 | 0 | 31.99000 | 0 | 0.6500000 |  3.06 | 0.00 |  0.000000 | 38.79000 |\n",
       "| 2.0794415 | 0 |  3.200000 |  4.850000 | 2.0400000 | 0 | 0.0000000 | 0.4000000 | 0.25 | 0 | ... | 0 | 1.6100000 | 0 | 31.99000 | 0 | 0.6500000 |  3.06 | 0.00 |  0.000000 | 38.78000 |\n",
       "| 2.8332133 | 0 | 11.770000 |  6.070000 | 0.0600000 | 0 | 1.6300000 | 0.1400000 | 0.00 | 0 | ... | 0 | 1.0700000 | 0 | 28.45000 | 0 | 0.0500000 |  2.57 | 0.00 |  0.180000 | 28.99000 |\n",
       "| 1.7917595 | 0 |  3.820000 |  6.680000 | 0.0000000 | 0 | 7.6300000 | 0.6500000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 29.57000 | 0 | 0.0000000 |  1.82 | 0.00 |  0.000000 | 32.71000 |\n",
       "| 2.0794415 | 0 |  3.780000 | 16.060000 | 0.0000000 | 0 | 0.0000000 | 0.0000000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 27.40000 | 0 | 0.0000000 |  1.80 | 0.00 | 12.280000 | 19.46000 |\n",
       "| 1.7917595 | 0 |  3.780000 | 16.060000 | 0.0000000 | 0 | 0.0000000 | 0.0000000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 28.35000 | 0 | 0.0000000 |  1.80 | 0.00 |  0.000000 | 35.51000 |\n",
       "| 3.8501476 | 0 | 16.040000 | 15.100000 | 0.0000000 | 0 | 0.0000000 | 0.6500000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 23.59000 | 0 | 0.0000000 |  1.80 | 0.00 | 12.270000 | 14.52000 |\n",
       "| 0.6931472 | 0 |  3.780000 |  6.610000 | 0.0000000 | 0 | 7.5600000 | 0.6500000 | 0.63 | 0 | ... | 0 | 0.0000000 | 0 | 23.62000 | 0 | 1.2700000 |  2.64 | 0.00 |  0.000000 | 29.96000 |\n",
       "| 2.1972246 | 0 |  9.970000 | 15.260000 | 0.0500000 | 0 | 0.5500000 | 0.1200000 | 0.05 | 0 | ... | 0 | 0.7800000 | 0 | 30.71000 | 0 | 0.0400000 |  2.06 | 0.01 |  0.150000 | 24.64000 |\n",
       "| 1.6094379 | 0 |  6.030000 | 15.490000 | 0.4400000 | 0 | 1.3200000 | 0.3100000 | 0.15 | 0 | ... | 0 | 0.8800000 | 0 | 32.00000 | 0 | 0.4400000 |  2.75 | 0.00 |  0.090000 | 21.41000 |\n",
       "| 2.0794415 | 0 |  6.060000 | 11.070000 | 0.4400000 | 0 | 6.3400000 | 0.3100000 | 0.15 | 0 | ... | 0 | 0.8800000 | 0 | 33.24000 | 0 | 0.4400000 |  2.76 | 0.00 |  0.090000 | 21.50000 |\n",
       "| 2.1972246 | 0 |  1.740000 |  5.990000 | 1.8600000 | 0 | 0.0000000 | 0.7300000 | 0.23 | 0 | ... | 0 | 1.4700000 | 0 | 29.96000 | 0 | 0.7400000 |  3.13 | 0.00 |  0.000000 | 42.98000 |\n",
       "| 3.2580965 | 0 | 16.060000 |  6.610000 | 0.0000000 | 0 | 7.5600000 | 0.0000000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 27.40000 | 0 | 0.0000000 |  1.80 | 0.00 |  0.000000 | 16.62000 |\n",
       "| 1.9459101 | 0 |  8.500000 |  6.610000 | 3.8600000 | 0 | 0.0000000 | 0.0000000 | 0.14 | 0 | ... | 0 | 3.0500000 | 0 | 23.62000 | 0 | 0.0000000 |  1.80 | 0.00 |  0.000000 | 30.40000 |\n",
       "| 2.6390573 | 0 |  3.780000 |  6.610000 | 0.0000000 | 0 | 7.5600000 | 0.6500000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 23.62000 | 0 | 0.0000000 |  1.80 | 0.00 | 12.280000 | 18.23000 |\n",
       "| 2.8332133 | 0 |  8.320000 |  7.070000 | 1.0100000 | 0 | 2.0400000 | 0.2000000 | 0.13 | 0 | ... | 0 | 1.8800000 | 0 | 30.18000 | 0 | 0.3900000 |  2.49 | 0.00 |  4.030000 | 19.32000 |\n",
       "| 3.5835189 | 0 |  4.660000 |  7.140000 | 1.2900000 | 0 | 0.0400000 | 0.2500000 | 0.16 | 0 | ... | 0 | 1.9500000 | 0 | 40.04000 | 0 | 0.4700000 |  1.95 | 0.00 |  0.010000 | 23.90000 |\n",
       "| 3.0445224 | 0 | 16.220000 |  7.630000 | 3.9000000 | 0 | 7.6300000 | 0.0000000 | 0.14 | 0 | ... | 0 | 3.0800000 | 0 | 29.57000 | 0 | 0.0000000 |  1.82 | 0.00 |  0.000000 | 17.32000 |\n",
       "| 1.9459101 | 0 | 16.060000 | 16.060000 | 0.0000000 | 0 | 7.5600000 | 0.0000000 | 0.63 | 0 | ... | 0 | 0.0000000 | 0 | 23.62000 | 0 | 1.2700000 |  2.28 | 0.00 |  0.000000 | 18.69000 |\n",
       "| 1.7917595 | 0 |  3.780000 | 16.060000 | 3.8600000 | 0 | 7.5600000 | 0.0000000 | 0.14 | 0 | ... | 0 | 3.0500000 | 0 | 29.29000 | 0 | 0.0000000 |  1.80 | 0.00 | 10.390000 | 11.50000 |\n",
       "| 2.6390573 | 0 | 16.060000 | 11.340000 | 0.0000000 | 0 | 0.0000000 | 0.0000000 | 0.14 | 0 | ... | 0 | 0.0000000 | 0 | 29.29000 | 0 | 0.0000000 |  1.80 | 0.00 |  0.000000 | 19.35000 |\n",
       "| 3.8712010 | 0 | 17.080000 |  8.870000 | 0.3200000 | 0 | 1.4700000 | 0.7700000 | 0.10 | 0 | ... | 0 | 0.8400000 | 0 | 28.63000 | 0 | 0.3200000 |  2.27 | 0.00 |  0.160000 | 15.75000 |\n",
       "| 1.7917595 | 0 |  5.000000 | 10.000000 | 0.0000000 | 0 | 0.0000000 | 0.0000000 | 0.00 | 0 | ... | 0 | 0.0000000 | 0 | 30.00000 | 0 | 0.0000000 | 29.90 | 0.00 |  7.000000 |  0.00000 |\n",
       "| 3.6375862 | 0 | 13.200000 | 10.000000 | 0.0000000 | 0 | 0.0000000 | 0.0000000 | 0.00 | 0 | ... | 0 | 0.0000000 | 0 | 37.60000 | 0 | 0.0000000 | 21.10 | 0.00 |  4.000000 |  0.00000 |\n",
       "\n"
      ],
      "text/plain": [
       "     vis       X__3 X__4      X__8      X__10     X__17 X__18     X__29    \n",
       "1    7.795647  0     9.42      8.52     0         0      0.00     0.00     \n",
       "2    8.396832  0     9.42      8.53     0         0      0.00     0.00     \n",
       "3    3.218876  0     3.58     14.25     0         0      1.88     0.00     \n",
       "4    3.044522  0     3.81     14.08     0         0      3.30     0.09     \n",
       "5    4.158883  0     0.00      0.00     0         0      0.00     0.00     \n",
       "6    4.369448  0     3.00     18.00     0         0      2.00     0.00     \n",
       "7    8.676587  0     9.43      8.53     0         0      0.00     0.00     \n",
       "8    6.852243  0     0.00      0.00     0         0     10.60     0.00     \n",
       "9    5.568345  0     0.00      0.00     0         0      0.00     0.00     \n",
       "10   4.795791  0     0.00      0.00     0         0      0.00     0.00     \n",
       "11   6.817831  0     0.22      0.00     0         0      0.15     0.00     \n",
       "12   6.287859  0     0.00      0.00     0         0      2.70     0.00     \n",
       "13   6.856462  0     3.72      0.00     0         0      8.69     0.00     \n",
       "14   8.706159  0    22.43      3.00     0         0      5.90     0.00     \n",
       "15   3.737670  0     0.00     21.70     0         0      6.59     0.00     \n",
       "16   4.852030  0     0.00     11.52     0         0      9.79     0.00     \n",
       "17   3.737670  0     0.00     18.31     0         0      0.00     0.00     \n",
       "18   3.295837  0     4.05     14.56     0         0      2.58     0.03     \n",
       "19   3.295837  0     1.70     12.00     0         0      4.50     0.00     \n",
       "20   3.295837  0     1.70     12.00     0         0      4.50     0.00     \n",
       "21   3.806662  0     6.30     12.00     0         0      4.50     0.00     \n",
       "22   3.806662  0     6.30     12.00     0         0      4.50     0.00     \n",
       "23   2.639057  0     6.30     17.00     0         0      4.50     0.00     \n",
       "24   2.772589  0     1.70     13.69     0         0      1.50     0.00     \n",
       "25   3.496508  0     6.30     15.98     0         0      4.50     0.00     \n",
       "26   3.091042  0     1.70     12.20     0         0      1.50     0.00     \n",
       "27   3.332205  0     6.30     12.00     0         0      1.50     0.00     \n",
       "28   3.583519  0     6.30     12.13     0         0      1.50     0.00     \n",
       "29   2.639057  0     6.08     12.00     0         0      1.50     0.00     \n",
       "30   2.639057  0     6.08     12.00     0         0      1.50     0.00     \n",
       "...  ...       ...  ...       ...       ...       ...   ...       ...      \n",
       "6958 3.4657359 0     2.661493  7.900911 0.0488921 0     0.6522875 0.5007826\n",
       "6959 3.0445224 0     7.530000  8.350000 1.4500000 0     2.8500000 0.2800000\n",
       "6960 3.1780538 0     7.530000 13.450000 1.4500000 0     2.8500000 0.2800000\n",
       "6961 3.1354942 0     7.530000  8.350000 1.4500000 0     7.9600000 0.2800000\n",
       "6962 2.6390573 0     7.530000  8.350000 1.4500000 0     2.8500000 0.2800000\n",
       "6963 1.9459101 0     3.280000  6.790000 2.0900000 0     0.0000000 0.4100000\n",
       "6964 2.3025851 0     3.200000  9.690000 2.0400000 0     0.0000000 0.4000000\n",
       "6965 2.0794415 0     3.200000  4.850000 2.0400000 0     0.0000000 0.4000000\n",
       "6966 2.8332133 0    11.770000  6.070000 0.0600000 0     1.6300000 0.1400000\n",
       "6967 1.7917595 0     3.820000  6.680000 0.0000000 0     7.6300000 0.6500000\n",
       "6968 2.0794415 0     3.780000 16.060000 0.0000000 0     0.0000000 0.0000000\n",
       "6969 1.7917595 0     3.780000 16.060000 0.0000000 0     0.0000000 0.0000000\n",
       "6970 3.8501476 0    16.040000 15.100000 0.0000000 0     0.0000000 0.6500000\n",
       "6971 0.6931472 0     3.780000  6.610000 0.0000000 0     7.5600000 0.6500000\n",
       "6972 2.1972246 0     9.970000 15.260000 0.0500000 0     0.5500000 0.1200000\n",
       "6973 1.6094379 0     6.030000 15.490000 0.4400000 0     1.3200000 0.3100000\n",
       "6974 2.0794415 0     6.060000 11.070000 0.4400000 0     6.3400000 0.3100000\n",
       "6975 2.1972246 0     1.740000  5.990000 1.8600000 0     0.0000000 0.7300000\n",
       "6976 3.2580965 0    16.060000  6.610000 0.0000000 0     7.5600000 0.0000000\n",
       "6977 1.9459101 0     8.500000  6.610000 3.8600000 0     0.0000000 0.0000000\n",
       "6978 2.6390573 0     3.780000  6.610000 0.0000000 0     7.5600000 0.6500000\n",
       "6979 2.8332133 0     8.320000  7.070000 1.0100000 0     2.0400000 0.2000000\n",
       "6980 3.5835189 0     4.660000  7.140000 1.2900000 0     0.0400000 0.2500000\n",
       "6981 3.0445224 0    16.220000  7.630000 3.9000000 0     7.6300000 0.0000000\n",
       "6982 1.9459101 0    16.060000 16.060000 0.0000000 0     7.5600000 0.0000000\n",
       "6983 1.7917595 0     3.780000 16.060000 3.8600000 0     7.5600000 0.0000000\n",
       "6984 2.6390573 0    16.060000 11.340000 0.0000000 0     0.0000000 0.0000000\n",
       "6985 3.8712010 0    17.080000  8.870000 0.3200000 0     1.4700000 0.7700000\n",
       "6986 1.7917595 0     5.000000 10.000000 0.0000000 0     0.0000000 0.0000000\n",
       "6987 3.6375862 0    13.200000 10.000000 0.0000000 0     0.0000000 0.0000000\n",
       "     X__30 X__43 ... X__84 X__86     X__106 X__109   X__113 X__115    X__117\n",
       "1    0     0     ... 0     0         0      68.39    0      0.00      0     \n",
       "2    0     0     ... 0     0         0      70.32    0      0.00      0     \n",
       "3    0     0     ... 0     0         0      45.42    0      0.00      0     \n",
       "4    0     0     ... 0     0         0      45.55    0      0.08      0     \n",
       "5    0     0     ... 0     0         0      66.51    0      0.00      0     \n",
       "6    0     0     ... 0     0         0      56.00    0      0.00      0     \n",
       "7    0     0     ... 0     0         0      71.50    0      0.00      0     \n",
       "8    0     0     ... 0     0         0      74.85    0      0.00      0     \n",
       "9    0     0     ... 0     0         0      70.37    0      0.00      0     \n",
       "10   0     0     ... 0     0         0      64.46    0      0.00      0     \n",
       "11   0     0     ... 0     0         0      55.91    0      0.00      0     \n",
       "12   0     0     ... 0     0         0      59.75    0      0.00      0     \n",
       "13   0     0     ... 0     0         0      68.52    0      0.00      0     \n",
       "14   0     0     ... 0     0         0      58.77    0      0.00      0     \n",
       "15   0     0     ... 0     0         0      54.20    0      0.00      0     \n",
       "16   0     0     ... 0     0         0      61.41    0      0.00      0     \n",
       "17   0     0     ... 0     0         0      59.37    0      0.00      0     \n",
       "18   0     0     ... 0     0         0      46.42    0      0.00      0     \n",
       "19   0     0     ... 0     0         0      52.00    0      0.20      0     \n",
       "20   0     0     ... 0     0         0      52.00    0      0.20      0     \n",
       "21   0     0     ... 0     0         0      43.32    0      0.20      0     \n",
       "22   0     0     ... 0     0         0      43.32    0      0.20      0     \n",
       "23   0     0     ... 0     0         0      43.57    0      0.20      0     \n",
       "24   0     0     ... 0     0         0      43.06    0      0.20      0     \n",
       "25   0     0     ... 0     0         0      52.17    0      0.20      0     \n",
       "26   0     0     ... 0     0         0      44.55    0      0.20      0     \n",
       "27   0     0     ... 0     0         0      50.24    0      0.20      0     \n",
       "28   0     0     ... 0     0         0      47.35    0      0.20      0     \n",
       "29   0     0     ... 0     0         0      43.99    0      0.20      0     \n",
       "30   0     0     ... 0     0         0      43.99    0      0.20      0     \n",
       "...  ...   ...       ...   ...       ...    ...      ...    ...       ...   \n",
       "6958 0.00  0     ... 0     0.1200227 0      41.58756 0      0.1220579  0.00 \n",
       "6959 0.18  0     ... 0     1.1500000 0      30.86000 0      0.4600000  0.18 \n",
       "6960 0.18  0     ... 0     1.1500000 0      30.86000 0      0.4600000  0.18 \n",
       "6961 0.18  0     ... 0     1.1500000 0      30.86000 0      0.4600000  0.18 \n",
       "6962 0.18  0     ... 0     1.1500000 0      32.90000 0      0.4600000  0.18 \n",
       "6963 0.26  0     ... 0     1.6500000 0      32.02000 0      0.6700000  3.07 \n",
       "6964 0.25  0     ... 0     1.6100000 0      31.99000 0      0.6500000  3.06 \n",
       "6965 0.25  0     ... 0     1.6100000 0      31.99000 0      0.6500000  3.06 \n",
       "6966 0.00  0     ... 0     1.0700000 0      28.45000 0      0.0500000  2.57 \n",
       "6967 0.14  0     ... 0     0.0000000 0      29.57000 0      0.0000000  1.82 \n",
       "6968 0.14  0     ... 0     0.0000000 0      27.40000 0      0.0000000  1.80 \n",
       "6969 0.14  0     ... 0     0.0000000 0      28.35000 0      0.0000000  1.80 \n",
       "6970 0.14  0     ... 0     0.0000000 0      23.59000 0      0.0000000  1.80 \n",
       "6971 0.63  0     ... 0     0.0000000 0      23.62000 0      1.2700000  2.64 \n",
       "6972 0.05  0     ... 0     0.7800000 0      30.71000 0      0.0400000  2.06 \n",
       "6973 0.15  0     ... 0     0.8800000 0      32.00000 0      0.4400000  2.75 \n",
       "6974 0.15  0     ... 0     0.8800000 0      33.24000 0      0.4400000  2.76 \n",
       "6975 0.23  0     ... 0     1.4700000 0      29.96000 0      0.7400000  3.13 \n",
       "6976 0.14  0     ... 0     0.0000000 0      27.40000 0      0.0000000  1.80 \n",
       "6977 0.14  0     ... 0     3.0500000 0      23.62000 0      0.0000000  1.80 \n",
       "6978 0.14  0     ... 0     0.0000000 0      23.62000 0      0.0000000  1.80 \n",
       "6979 0.13  0     ... 0     1.8800000 0      30.18000 0      0.3900000  2.49 \n",
       "6980 0.16  0     ... 0     1.9500000 0      40.04000 0      0.4700000  1.95 \n",
       "6981 0.14  0     ... 0     3.0800000 0      29.57000 0      0.0000000  1.82 \n",
       "6982 0.63  0     ... 0     0.0000000 0      23.62000 0      1.2700000  2.28 \n",
       "6983 0.14  0     ... 0     3.0500000 0      29.29000 0      0.0000000  1.80 \n",
       "6984 0.14  0     ... 0     0.0000000 0      29.29000 0      0.0000000  1.80 \n",
       "6985 0.10  0     ... 0     0.8400000 0      28.63000 0      0.3200000  2.27 \n",
       "6986 0.00  0     ... 0     0.0000000 0      30.00000 0      0.0000000 29.90 \n",
       "6987 0.00  0     ... 0     0.0000000 0      37.60000 0      0.0000000 21.10 \n",
       "     X__133 X__138    autres  \n",
       "1    0      0.00       0.00000\n",
       "2    0      0.00       0.00000\n",
       "3    0      1.34      15.80000\n",
       "4    0      1.24      16.88000\n",
       "5    0      0.00       0.01000\n",
       "6    0      2.00       6.00000\n",
       "7    0      0.00       0.00000\n",
       "8    0      0.00       0.15000\n",
       "9    0      0.00       0.00000\n",
       "10   0      0.00       0.00000\n",
       "11   0      0.00      31.55000\n",
       "12   0      0.00      26.15000\n",
       "13   0      0.00       0.44000\n",
       "14   0      0.00       0.18499\n",
       "15   0      0.00       5.70000\n",
       "16   0      0.00       6.46000\n",
       "17   0      0.00       3.41000\n",
       "18   0      1.36      12.23000\n",
       "19   0      1.40      12.20000\n",
       "20   0      1.40      12.20000\n",
       "21   0      1.40      15.95000\n",
       "22   0      1.40      15.95000\n",
       "23   0      1.40      10.45000\n",
       "24   0      1.40      18.95000\n",
       "25   0      1.40       7.45000\n",
       "26   0      1.40      23.45000\n",
       "27   0      1.40      10.45000\n",
       "28   0      1.40      11.95000\n",
       "29   0      1.40      14.95000\n",
       "30   0      1.40      14.95000\n",
       "...  ...    ...       ...     \n",
       "6958 0.00    9.049536 22.20093\n",
       "6959 0.00    5.760000 25.61000\n",
       "6960 0.00    5.760000 25.62000\n",
       "6961 0.00    5.760000 25.61000\n",
       "6962 0.00    5.760000 25.62000\n",
       "6963 0.00    0.000000 38.50000\n",
       "6964 0.00    0.000000 38.79000\n",
       "6965 0.00    0.000000 38.78000\n",
       "6966 0.00    0.180000 28.99000\n",
       "6967 0.00    0.000000 32.71000\n",
       "6968 0.00   12.280000 19.46000\n",
       "6969 0.00    0.000000 35.51000\n",
       "6970 0.00   12.270000 14.52000\n",
       "6971 0.00    0.000000 29.96000\n",
       "6972 0.01    0.150000 24.64000\n",
       "6973 0.00    0.090000 21.41000\n",
       "6974 0.00    0.090000 21.50000\n",
       "6975 0.00    0.000000 42.98000\n",
       "6976 0.00    0.000000 16.62000\n",
       "6977 0.00    0.000000 30.40000\n",
       "6978 0.00   12.280000 18.23000\n",
       "6979 0.00    4.030000 19.32000\n",
       "6980 0.00    0.010000 23.90000\n",
       "6981 0.00    0.000000 17.32000\n",
       "6982 0.00    0.000000 18.69000\n",
       "6983 0.00   10.390000 11.50000\n",
       "6984 0.00    0.000000 19.35000\n",
       "6985 0.00    0.160000 15.75000\n",
       "6986 0.00    7.000000  0.00000\n",
       "6987 0.00    4.000000  0.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lasso_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75296e",
   "metadata": {},
   "source": [
    "## t-IMSE standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b213b2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'KrigInv' was built under R version 4.0.5\"\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Warning message:\n",
      "\"package 'DiceKriging' was built under R version 4.0.5\"\n",
      "Warning message:\n",
      "\"package 'nloptr' was built under R version 4.0.4\"\n"
     ]
    }
   ],
   "source": [
    "# Charger la librairie\n",
    "library(\"KrigInv\") #Pour t-IMSE\n",
    "library(\"nloptr\") #Pour la fonction d'optimisation Cobyla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a973b60",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 \n",
      "  - parameters upper bounds :  0.78 1.966238e-08 44.86 1.985377e-08 1.933217e-08 1.990286e-08 43.4 1.942561e-08 0.92 1.960491e-08 1.985787e-08 1.968854e-08 1.906054e-08 1.983038e-08 21.2 1.922246e-08 6.5 1.941189e-08 4.88 1.960927e-08 1.14 1.963207e-08 1 1.977132e-08 0.6 1.938075e-08 1.97089e-08 1.979313e-08 1.957496e-08 1.94555e-08 1.988731e-08 6 1.982323e-08 1.901088e-08 25 1.96595e-08 1.93717e-08 1.960738e-08 1.987109e-08 4 0.8 1.982079e-08 1.972261e-08 1.960657e-08 1.938218e-08 24.16 1.997519e-08 1.957453e-08 1.997778e-08 1.949423e-08 1.918955e-08 8 16.82 1.916453e-08 1.971963e-08 3 3 1.946636e-08 11.36 1.963074e-08 1.975889e-08 1.961051e-08 110.54 1.958138e-08 4 1.982247e-08 1 1.984908e-08 1.978411e-08 1.951784e-08 2 1.941344e-08 62.98 1.991451e-08 1.970503e-08 1.979226e-08 1.97337e-08 1.965842e-08 1.992298e-08 1.966013e-08 1.95303e-08 1.2 1.978285e-08 1.963527e-08 1.957818e-08 1.983315e-08 1.965026e-08 1.950709e-08 1.978614e-08 86.38 1.991896e-08 1.938685e-08 1.932784e-08 1.971537e-08 1.983609e-08 0.48 1.915389e-08 1.981813e-08 1.975265e-08 1.942653e-08 1.943757e-08 1.956512e-08 0.08000001 1.985837e-08 1.945047e-08 1.972417e-08 1.990331e-08 1.943382e-08 1.959595e-08 1.952082e-08 1.921434e-08 1.991287e-08 1.980072e-08 7.28 10 \n",
      "  - best initial criterion value(s) :  -231.3459 \n",
      "\n",
      "N = 115, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       231.35  |proj g|=   4.6086e-07\n",
      "At iterate     1  f =       214.73  |proj g|=         1.565\n",
      "ys=-3.000e+01  -gs= 4.046e-04, BFGS update SKIPPED\n",
      "At iterate     2  f =       212.22  |proj g|=        1.1686\n",
      "At iterate     3  f =       212.21  |proj g|=         1.167\n",
      "At iterate     4  f =       208.96  |proj g|=       0.58459\n",
      "Nonpositive definiteness in Cholesky factorization in formt();\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     5  f =        207.6  |proj g|=       0.38395\n",
      "At iterate     6  f =        207.6  |proj g|=       0.38395\n",
      "\n",
      "iterations 6\n",
      "function evaluations 32\n",
      "segments explored during Cauchy searches 91\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 86\n",
      "norm of the final projected gradient 0.383945\n",
      "final function value 207.597\n",
      "\n",
      "F = 207.597\n",
      "final  value 207.596811 \n",
      "converged\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.191299510862191</li><li>0.191299510862191</li><li>0.191299510862185</li><li>0.191299510862185</li><li>0.191299510862189</li><li>0.191299510862186</li><li>0.191299510862191</li><li>0.19129951086219</li><li>0.19129951086219</li><li>0.191299510862188</li><li>0.191299510862187</li><li>0.191299510862189</li><li>0.19129951086219</li><li>0.191299510862187</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862187</li><li>0.191299510862185</li><li>0.191299510862184</li><li>0.191299510862184</li><li>0.191299510862185</li><li>0.191299510862185</li><li>0.191299510862186</li><li>0.191299510862185</li><li>0.191299510862186</li><li>0.191299510862184</li><li>0.191299510862186</li><li>0.191299510862182</li><li>0.191299510862185</li><li>0.191299510862185</li><li>0.191299510862186</li><li>0.191299510862184</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862186</li><li>0.191299510862185</li><li>0.191299510862186</li><li>0.191299510862185</li><li>0.191299510862185</li><li>0.191299510862184</li><li>0.191299510862192</li><li>0.191299510862184</li><li>0.191299510862192</li><li>0.191299510862186</li><li>0.19129951086219</li><li>0.191299510862185</li><li>0.191299510862188</li><li>0.191299510862182</li><li>0.191299510862185</li><li>0.191299510862182</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.191299510862191\n",
       "\\item 0.191299510862191\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862189\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862191\n",
       "\\item 0.19129951086219\n",
       "\\item 0.19129951086219\n",
       "\\item 0.191299510862188\n",
       "\\item 0.191299510862187\n",
       "\\item 0.191299510862189\n",
       "\\item 0.19129951086219\n",
       "\\item 0.191299510862187\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862187\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862184\n",
       "\\item 0.191299510862184\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862184\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862182\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862184\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862186\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862184\n",
       "\\item 0.191299510862192\n",
       "\\item 0.191299510862184\n",
       "\\item 0.191299510862192\n",
       "\\item 0.191299510862186\n",
       "\\item 0.19129951086219\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862188\n",
       "\\item 0.191299510862182\n",
       "\\item 0.191299510862185\n",
       "\\item 0.191299510862182\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.191299510862191\n",
       "2. 0.191299510862191\n",
       "3. 0.191299510862185\n",
       "4. 0.191299510862185\n",
       "5. 0.191299510862189\n",
       "6. 0.191299510862186\n",
       "7. 0.191299510862191\n",
       "8. 0.19129951086219\n",
       "9. 0.19129951086219\n",
       "10. 0.191299510862188\n",
       "11. 0.191299510862187\n",
       "12. 0.191299510862189\n",
       "13. 0.19129951086219\n",
       "14. 0.191299510862187\n",
       "15. 0.191299510862186\n",
       "16. 0.191299510862186\n",
       "17. 0.191299510862187\n",
       "18. 0.191299510862185\n",
       "19. 0.191299510862184\n",
       "20. 0.191299510862184\n",
       "21. 0.191299510862185\n",
       "22. 0.191299510862185\n",
       "23. 0.191299510862186\n",
       "24. 0.191299510862185\n",
       "25. 0.191299510862186\n",
       "26. 0.191299510862184\n",
       "27. 0.191299510862186\n",
       "28. 0.191299510862182\n",
       "29. 0.191299510862185\n",
       "30. 0.191299510862185\n",
       "31. 0.191299510862186\n",
       "32. 0.191299510862184\n",
       "33. 0.191299510862186\n",
       "34. 0.191299510862186\n",
       "35. 0.191299510862186\n",
       "36. 0.191299510862186\n",
       "37. 0.191299510862186\n",
       "38. 0.191299510862186\n",
       "39. 0.191299510862186\n",
       "40. 0.191299510862186\n",
       "41. 0.191299510862186\n",
       "42. 0.191299510862186\n",
       "43. 0.191299510862186\n",
       "44. 0.191299510862186\n",
       "45. 0.191299510862186\n",
       "46. 0.191299510862185\n",
       "47. 0.191299510862186\n",
       "48. 0.191299510862185\n",
       "49. 0.191299510862185\n",
       "50. 0.191299510862184\n",
       "51. 0.191299510862192\n",
       "52. 0.191299510862184\n",
       "53. 0.191299510862192\n",
       "54. 0.191299510862186\n",
       "55. 0.19129951086219\n",
       "56. 0.191299510862185\n",
       "57. 0.191299510862188\n",
       "58. 0.191299510862182\n",
       "59. 0.191299510862185\n",
       "60. 0.191299510862182\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       " [8] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[15] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[22] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[29] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[36] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[43] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[50] 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995 0.1912995\n",
       "[57] 0.1912995 0.1912995 0.1912995 0.1912995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#t-IMSE STANDARD APPLIQUEE AUX DONNEES \n",
    "\n",
    "x = data[1:60,2:116]\n",
    "data_reduced = data[1:120,1:116]\n",
    "#des = data_reduced[c(-1)]\n",
    "shape = c(dim(data_reduced[,c(-1)]))\n",
    "noise = matrix(runif(prod(shape),min = 0.00000001,max = 0.00000002), nrow = 120)\n",
    "mod = km(formula = ~1, design = data_reduced[,c(-1)] + noise, response = data_reduced[1])\n",
    "tmse_optim(x, model = mod, T = log(400))\n",
    "# lowerbound = as.vector(rep(0, dim(data_reduced[, -1])[2]))\n",
    "# upperbound = as.vector(rep(100, dim(data_reduced[, -1])[2]))\n",
    "# max_infill_criterion(lower=lowerbound, upper = upperbound, method=\"tmse\", model=mod, T=(400))$par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9797e770",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$par</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.96996140761931</li><li>1.13401109801948</li><li>0.052996944391027</li><li>-0.00057615883061321</li><li>0.040126654287666</li><li>0.0597797204327858</li><li>-0.000594671198509916</li><li>-0.000594671198509916</li><li>0.0522019977256409</li><li>-0.000604348038368576</li><li>-0.0317812703301617</li><li>-0.0338826980455356</li><li>-0.000592527851471046</li><li>-0.0250561700215328</li><li>-0.000588039918851548</li><li>0.0287349055359085</li><li>0.0574245211139501</li><li>-0.000604070716763906</li><li>0.0543744046693486</li><li>-0.000614165952175719</li><li>-0.000614165952175719</li><li>-0.000614165952175719</li><li>-0.000614165952175719</li><li>-0.0273648696952537</li><li>0.0301374183908001</li><li>0.0298302373403535</li><li>0.0433948461512983</li><li>0.0433796398269892</li><li>-0.000636687286716535</li><li>0.0417074479593183</li><li>-0.000644478321047563</li><li>0.0223598721577563</li><li>-0.0263781976923035</li><li>0.0393561990377452</li><li>-0.000651341040355964</li><li>0.0429159715551487</li><li>-0.000659365990260575</li><li>0.0440102308821769</li><li>0.0242461940953804</li><li>0.0370935424190494</li><li>0.0391446544031546</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>35.7848665671055</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>60.5310391932498</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li><li>-0.000686492199786657</li></ol>\n",
       "</dd>\n",
       "\t<dt>$value</dt>\n",
       "\t\t<dd>0.191299510862186</dd>\n",
       "\t<dt>$iter</dt>\n",
       "\t\t<dd>1000</dd>\n",
       "\t<dt>$convergence</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>$message</dt>\n",
       "\t\t<dd>'NLOPT_MAXEVAL_REACHED: Optimization stopped because maxeval (above) was reached.'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$par] \\begin{enumerate*}\n",
       "\\item 1.96996140761931\n",
       "\\item 1.13401109801948\n",
       "\\item 0.052996944391027\n",
       "\\item -0.00057615883061321\n",
       "\\item 0.040126654287666\n",
       "\\item 0.0597797204327858\n",
       "\\item -0.000594671198509916\n",
       "\\item -0.000594671198509916\n",
       "\\item 0.0522019977256409\n",
       "\\item -0.000604348038368576\n",
       "\\item -0.0317812703301617\n",
       "\\item -0.0338826980455356\n",
       "\\item -0.000592527851471046\n",
       "\\item -0.0250561700215328\n",
       "\\item -0.000588039918851548\n",
       "\\item 0.0287349055359085\n",
       "\\item 0.0574245211139501\n",
       "\\item -0.000604070716763906\n",
       "\\item 0.0543744046693486\n",
       "\\item -0.000614165952175719\n",
       "\\item -0.000614165952175719\n",
       "\\item -0.000614165952175719\n",
       "\\item -0.000614165952175719\n",
       "\\item -0.0273648696952537\n",
       "\\item 0.0301374183908001\n",
       "\\item 0.0298302373403535\n",
       "\\item 0.0433948461512983\n",
       "\\item 0.0433796398269892\n",
       "\\item -0.000636687286716535\n",
       "\\item 0.0417074479593183\n",
       "\\item -0.000644478321047563\n",
       "\\item 0.0223598721577563\n",
       "\\item -0.0263781976923035\n",
       "\\item 0.0393561990377452\n",
       "\\item -0.000651341040355964\n",
       "\\item 0.0429159715551487\n",
       "\\item -0.000659365990260575\n",
       "\\item 0.0440102308821769\n",
       "\\item 0.0242461940953804\n",
       "\\item 0.0370935424190494\n",
       "\\item 0.0391446544031546\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item 35.7848665671055\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item 60.5310391932498\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\item -0.000686492199786657\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$value] 0.191299510862186\n",
       "\\item[\\$iter] 1000\n",
       "\\item[\\$convergence] 5\n",
       "\\item[\\$message] 'NLOPT\\_MAXEVAL\\_REACHED: Optimization stopped because maxeval (above) was reached.'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$par\n",
       ":   1. 1.96996140761931\n",
       "2. 1.13401109801948\n",
       "3. 0.052996944391027\n",
       "4. -0.00057615883061321\n",
       "5. 0.040126654287666\n",
       "6. 0.0597797204327858\n",
       "7. -0.000594671198509916\n",
       "8. -0.000594671198509916\n",
       "9. 0.0522019977256409\n",
       "10. -0.000604348038368576\n",
       "11. -0.0317812703301617\n",
       "12. -0.0338826980455356\n",
       "13. -0.000592527851471046\n",
       "14. -0.0250561700215328\n",
       "15. -0.000588039918851548\n",
       "16. 0.0287349055359085\n",
       "17. 0.0574245211139501\n",
       "18. -0.000604070716763906\n",
       "19. 0.0543744046693486\n",
       "20. -0.000614165952175719\n",
       "21. -0.000614165952175719\n",
       "22. -0.000614165952175719\n",
       "23. -0.000614165952175719\n",
       "24. -0.0273648696952537\n",
       "25. 0.0301374183908001\n",
       "26. 0.0298302373403535\n",
       "27. 0.0433948461512983\n",
       "28. 0.0433796398269892\n",
       "29. -0.000636687286716535\n",
       "30. 0.0417074479593183\n",
       "31. -0.000644478321047563\n",
       "32. 0.0223598721577563\n",
       "33. -0.0263781976923035\n",
       "34. 0.0393561990377452\n",
       "35. -0.000651341040355964\n",
       "36. 0.0429159715551487\n",
       "37. -0.000659365990260575\n",
       "38. 0.0440102308821769\n",
       "39. 0.0242461940953804\n",
       "40. 0.0370935424190494\n",
       "41. 0.0391446544031546\n",
       "42. -0.000686492199786657\n",
       "43. -0.000686492199786657\n",
       "44. -0.000686492199786657\n",
       "45. -0.000686492199786657\n",
       "46. -0.000686492199786657\n",
       "47. -0.000686492199786657\n",
       "48. -0.000686492199786657\n",
       "49. -0.000686492199786657\n",
       "50. -0.000686492199786657\n",
       "51. -0.000686492199786657\n",
       "52. -0.000686492199786657\n",
       "53. -0.000686492199786657\n",
       "54. -0.000686492199786657\n",
       "55. -0.000686492199786657\n",
       "56. -0.000686492199786657\n",
       "57. -0.000686492199786657\n",
       "58. -0.000686492199786657\n",
       "59. -0.000686492199786657\n",
       "60. -0.000686492199786657\n",
       "61. -0.000686492199786657\n",
       "62. -0.000686492199786657\n",
       "63. 35.7848665671055\n",
       "64. -0.000686492199786657\n",
       "65. -0.000686492199786657\n",
       "66. -0.000686492199786657\n",
       "67. -0.000686492199786657\n",
       "68. -0.000686492199786657\n",
       "69. -0.000686492199786657\n",
       "70. -0.000686492199786657\n",
       "71. -0.000686492199786657\n",
       "72. -0.000686492199786657\n",
       "73. -0.000686492199786657\n",
       "74. -0.000686492199786657\n",
       "75. -0.000686492199786657\n",
       "76. -0.000686492199786657\n",
       "77. -0.000686492199786657\n",
       "78. -0.000686492199786657\n",
       "79. -0.000686492199786657\n",
       "80. -0.000686492199786657\n",
       "81. -0.000686492199786657\n",
       "82. -0.000686492199786657\n",
       "83. -0.000686492199786657\n",
       "84. -0.000686492199786657\n",
       "85. -0.000686492199786657\n",
       "86. -0.000686492199786657\n",
       "87. -0.000686492199786657\n",
       "88. -0.000686492199786657\n",
       "89. -0.000686492199786657\n",
       "90. 60.5310391932498\n",
       "91. -0.000686492199786657\n",
       "92. -0.000686492199786657\n",
       "93. -0.000686492199786657\n",
       "94. -0.000686492199786657\n",
       "95. -0.000686492199786657\n",
       "96. -0.000686492199786657\n",
       "97. -0.000686492199786657\n",
       "98. -0.000686492199786657\n",
       "99. -0.000686492199786657\n",
       "100. -0.000686492199786657\n",
       "101. -0.000686492199786657\n",
       "102. -0.000686492199786657\n",
       "103. -0.000686492199786657\n",
       "104. -0.000686492199786657\n",
       "105. -0.000686492199786657\n",
       "106. -0.000686492199786657\n",
       "107. -0.000686492199786657\n",
       "108. -0.000686492199786657\n",
       "109. -0.000686492199786657\n",
       "110. -0.000686492199786657\n",
       "111. -0.000686492199786657\n",
       "112. -0.000686492199786657\n",
       "113. -0.000686492199786657\n",
       "114. -0.000686492199786657\n",
       "115. -0.000686492199786657\n",
       "\n",
       "\n",
       "\n",
       "$value\n",
       ":   0.191299510862186\n",
       "$iter\n",
       ":   1000\n",
       "$convergence\n",
       ":   5\n",
       "$message\n",
       ":   'NLOPT_MAXEVAL_REACHED: Optimization stopped because maxeval (above) was reached.'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$par\n",
       "  [1]  1.9699614076  1.1340110980  0.0529969444 -0.0005761588  0.0401266543\n",
       "  [6]  0.0597797204 -0.0005946712 -0.0005946712  0.0522019977 -0.0006043480\n",
       " [11] -0.0317812703 -0.0338826980 -0.0005925279 -0.0250561700 -0.0005880399\n",
       " [16]  0.0287349055  0.0574245211 -0.0006040707  0.0543744047 -0.0006141660\n",
       " [21] -0.0006141660 -0.0006141660 -0.0006141660 -0.0273648697  0.0301374184\n",
       " [26]  0.0298302373  0.0433948462  0.0433796398 -0.0006366873  0.0417074480\n",
       " [31] -0.0006444783  0.0223598722 -0.0263781977  0.0393561990 -0.0006513410\n",
       " [36]  0.0429159716 -0.0006593660  0.0440102309  0.0242461941  0.0370935424\n",
       " [41]  0.0391446544 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [46] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [51] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [56] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [61] -0.0006864922 -0.0006864922 35.7848665671 -0.0006864922 -0.0006864922\n",
       " [66] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [71] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [76] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [81] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [86] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 60.5310391932\n",
       " [91] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       " [96] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       "[101] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       "[106] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       "[111] -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922 -0.0006864922\n",
       "\n",
       "$value\n",
       "[1] 0.1912995\n",
       "\n",
       "$iter\n",
       "[1] 1000\n",
       "\n",
       "$convergence\n",
       "[1] 5\n",
       "\n",
       "$message\n",
       "[1] \"NLOPT_MAXEVAL_REACHED: Optimization stopped because maxeval (above) was reached.\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0=as.numeric(data[116,2:116])\n",
    "fn<-function(x){\n",
    "  tmse_optim(x, model = mod, T = log(400))\n",
    "}\n",
    "contr<-function(x){\n",
    "  h<-numeric(4)\n",
    "  h[1]<-sum(x)-100 #g(x)>=0\n",
    "  h[2]<-(-sum(x))+100  # g(x) <= 0 <=> -g(x)>=0\n",
    "  h[3]<-x\n",
    "  h[4]<-(-x)+100\n",
    "  return(h)\n",
    "}\n",
    "\n",
    "options(warn=-1)\n",
    "cobyla(x0,fn,hin=contr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b1f3b",
   "metadata": {},
   "source": [
    "## Adaptation t-IMSE à nos contraintes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab395923",
   "metadata": {},
   "source": [
    "Au lieu d'utiliser la fonction **tmse_optim** standard, il nous faut considerer les contraintes du simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644c1a2d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize randomly data by index\n",
    "d = 29 #Nombre de variables gardées par Lasso\n",
    "n_init = d*10\n",
    "index = sample(1:nrow(data_lasso_log),n_init)\n",
    "data_lasso_reduced = data_lasso_log[index, ] #Prendre aleatoirement n_init observations\n",
    "\n",
    "X = data_lasso_reduced[,c(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572d2041",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#simulation de x unifome sur [0,1] et la somme egale à 1\n",
    "simul <- function(d)\n",
    "{\n",
    "  # set.seed(18)\n",
    "  u = runif(n=d-1, min=0,max=1)\n",
    "  u = c(0,u,1)\n",
    "  u = sort(u)\n",
    "  x = u[2:(d+1)] - u[1:d]  \n",
    "  return(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be225fc1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Fonction pour calculer l'integrale de t-IMSE\n",
    "\n",
    "g = function (x, model, T, method.param = NULL) \n",
    "{\n",
    "    y <- t(x)\n",
    "    if (ncol(y) == model@d) \n",
    "        z <- y\n",
    "    if (ncol(y) != model@d) \n",
    "        z <- x\n",
    "    krig <- predict_nobias_km(object = model, newdata = as.data.frame(z), \n",
    "        type = \"UK\", se.compute = TRUE)\n",
    "    mk <- krig$mean\n",
    "    sk <- krig$sd\n",
    "    if (is.null(method.param)) \n",
    "        method.param <- 0\n",
    "    epsilon <- method.param\n",
    "    if (length(T) == 1) {\n",
    "        W <- 1/sqrt(2 * pi * (sk^2 + epsilon^2)) * exp(-0.5 * \n",
    "            ((mk - T)/sqrt(sk^2 + epsilon^2))^2)\n",
    "    }\n",
    "    else {\n",
    "        W0 <- 1/sqrt(2 * pi * (sk^2 + epsilon^2))\n",
    "        W <- 0\n",
    "        for (i in 1:length(T)) {\n",
    "            Ti <- T[i]\n",
    "            W <- W + W0 * exp(-0.5 * ((mk - Ti)/sqrt(sk^2 + epsilon^2))^2)\n",
    "        }\n",
    "    }\n",
    "    g <- W * sk^2\n",
    "    return(g)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f494862d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Fonction pour calculer l'integrale de t-IMSE du modele mis à jour\n",
    "g_new = function (x, m0, model, T, method.param = NULL) \n",
    "{\n",
    "    y <- t(x)\n",
    "    if (ncol(y) == model@d) \n",
    "        z <- y\n",
    "    if (ncol(y) != model@d) \n",
    "        z <- x\n",
    "    krig0 <- predict_nobias_km(object = m0, newdata = as.data.frame(z), \n",
    "        type = \"UK\", se.compute = TRUE)\n",
    "    krig <- predict_nobias_km(object = model, newdata = as.data.frame(z), \n",
    "        type = \"UK\", se.compute = TRUE)\n",
    "    mk0 <- krig0$mean\n",
    "    sk0 <- krig0$sd\n",
    "    if (is.null(method.param)) \n",
    "        method.param <- 0\n",
    "    epsilon <- method.param\n",
    "    if (length(T) == 1) {\n",
    "        W <- 1/sqrt(2 * pi * (sk0^2 + epsilon^2)) * exp(-0.5 * \n",
    "            ((mk0 - T)/sqrt(sk0^2 + epsilon^2))^2)\n",
    "    }\n",
    "    else {\n",
    "        W0 <- 1/sqrt(2 * pi * (sk0^2 + epsilon^2))\n",
    "        W <- 0\n",
    "        for (i in 1:length(T)) {\n",
    "            Ti <- T[i]\n",
    "            W <- W + W0 * exp(-0.5 * ((mk0 - Ti)/sqrt(sk0^2 + epsilon^2))^2)\n",
    "        }\n",
    "    }\n",
    "    sk <- krig$sd\n",
    "    g <- W * sk^2\n",
    "    return(g)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a97174",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Calculer t-IMSE adapté par la methode de Monte Carlo\n",
    "tmse <- function(d,mod, T)\n",
    "{\n",
    "    s = 0\n",
    "    for(i in 1:1000){\n",
    "    x = simul(d) \n",
    "    s = s + g(x, model = mod,T)\n",
    "    }\n",
    "    tmse = s/1000\n",
    "    return(tmse)\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d85e50ef",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 \n",
      "  - parameters upper bounds :  1.98709e-06 59.68 44.58 97.82 41.86 94 21.72 0.02000277 89.62 1.989396e-06 79.86 2.080001 88.9 20.6 43.56 33.16 20 1.995482e-06 91.52 1.992148e-06 18.42 1.97895e-06 159.36 2.000001 3.12 59.82 4.000002 30.08 125.04 \n",
      "  - best initial criterion value(s) :  -574.7981 \n",
      "\n",
      "N = 29, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        574.8  |proj g|=       8.1584\n",
      "At iterate     1  f =       474.23  |proj g|=        2.2322\n",
      "At iterate     2  f =        474.2  |proj g|=        2.2298\n",
      "At iterate     3  f =       474.18  |proj g|=        2.2279\n",
      "At iterate     4  f =       472.24  |proj g|=        2.0607\n",
      "At iterate     5  f =       464.18  |proj g|=        1.0756\n",
      "At iterate     6  f =       461.99  |proj g|=       0.80347\n",
      "At iterate     7  f =       460.99  |proj g|=       0.73513\n",
      "At iterate     8  f =       460.82  |proj g|=        0.6976\n",
      "At iterate     9  f =       460.81  |proj g|=       0.68534\n",
      "At iterate    10  f =       460.81  |proj g|=       0.68367\n",
      "At iterate    11  f =       460.81  |proj g|=       0.68365\n",
      "\n",
      "iterations 11\n",
      "function evaluations 44\n",
      "segments explored during Cauchy searches 19\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 9\n",
      "norm of the final projected gradient 0.683646\n",
      "final function value 460.806\n",
      "\n",
      "F = 460.806\n",
      "final  value 460.805846 \n",
      "converged\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.14006428888078</li><li>1.26867344480136</li><li>1.27829028688675</li><li>1.22982193799783</li><li>1.11606260163177</li><li>1.21337823272884</li><li>1.35551672379729</li><li>1.35194756605709</li><li>1.24259720556503</li><li>1.2496749943321</li><li>1.1804114951366</li><li>1.01876396729451</li><li>1.24272255265747</li><li>1.25397130629104</li><li>0.984622562010086</li><li>0.90567514263788</li><li>1.06530381789624</li><li>1.11317663136801</li><li>1.11611876372356</li><li>1.32365175744062</li><li>1.03856147658422</li><li>1.2357330727721</li><li>1.11851296671706</li><li>0.961127655728864</li><li>1.0538750404981</li><li>1.14269623175825</li><li>1.11233997775611</li><li>1.04638914498464</li><li>1.09598791043018</li><li>0.976475916865322</li><li>1.0579604614182</li><li>1.34799701363132</li><li>1.19899762353575</li><li>1.27171485801897</li><li>1.05699113618212</li><li>1.13180469730654</li><li>1.10677912927435</li><li>1.0634385908919</li><li>1.11938566033568</li><li>1.3211769391864</li><li>1.13266184655957</li><li>0.94795187110649</li><li>1.07339346845227</li><li>0.955267833832056</li><li>1.33843296225037</li><li>1.26601665144164</li><li>1.26421684786365</li><li>1.08955636911983</li><li>1.12921117314449</li><li>0.37123564366995</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.14006428888078\n",
       "\\item 1.26867344480136\n",
       "\\item 1.27829028688675\n",
       "\\item 1.22982193799783\n",
       "\\item 1.11606260163177\n",
       "\\item 1.21337823272884\n",
       "\\item 1.35551672379729\n",
       "\\item 1.35194756605709\n",
       "\\item 1.24259720556503\n",
       "\\item 1.2496749943321\n",
       "\\item 1.1804114951366\n",
       "\\item 1.01876396729451\n",
       "\\item 1.24272255265747\n",
       "\\item 1.25397130629104\n",
       "\\item 0.984622562010086\n",
       "\\item 0.90567514263788\n",
       "\\item 1.06530381789624\n",
       "\\item 1.11317663136801\n",
       "\\item 1.11611876372356\n",
       "\\item 1.32365175744062\n",
       "\\item 1.03856147658422\n",
       "\\item 1.2357330727721\n",
       "\\item 1.11851296671706\n",
       "\\item 0.961127655728864\n",
       "\\item 1.0538750404981\n",
       "\\item 1.14269623175825\n",
       "\\item 1.11233997775611\n",
       "\\item 1.04638914498464\n",
       "\\item 1.09598791043018\n",
       "\\item 0.976475916865322\n",
       "\\item 1.0579604614182\n",
       "\\item 1.34799701363132\n",
       "\\item 1.19899762353575\n",
       "\\item 1.27171485801897\n",
       "\\item 1.05699113618212\n",
       "\\item 1.13180469730654\n",
       "\\item 1.10677912927435\n",
       "\\item 1.0634385908919\n",
       "\\item 1.11938566033568\n",
       "\\item 1.3211769391864\n",
       "\\item 1.13266184655957\n",
       "\\item 0.94795187110649\n",
       "\\item 1.07339346845227\n",
       "\\item 0.955267833832056\n",
       "\\item 1.33843296225037\n",
       "\\item 1.26601665144164\n",
       "\\item 1.26421684786365\n",
       "\\item 1.08955636911983\n",
       "\\item 1.12921117314449\n",
       "\\item 0.37123564366995\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.14006428888078\n",
       "2. 1.26867344480136\n",
       "3. 1.27829028688675\n",
       "4. 1.22982193799783\n",
       "5. 1.11606260163177\n",
       "6. 1.21337823272884\n",
       "7. 1.35551672379729\n",
       "8. 1.35194756605709\n",
       "9. 1.24259720556503\n",
       "10. 1.2496749943321\n",
       "11. 1.1804114951366\n",
       "12. 1.01876396729451\n",
       "13. 1.24272255265747\n",
       "14. 1.25397130629104\n",
       "15. 0.984622562010086\n",
       "16. 0.90567514263788\n",
       "17. 1.06530381789624\n",
       "18. 1.11317663136801\n",
       "19. 1.11611876372356\n",
       "20. 1.32365175744062\n",
       "21. 1.03856147658422\n",
       "22. 1.2357330727721\n",
       "23. 1.11851296671706\n",
       "24. 0.961127655728864\n",
       "25. 1.0538750404981\n",
       "26. 1.14269623175825\n",
       "27. 1.11233997775611\n",
       "28. 1.04638914498464\n",
       "29. 1.09598791043018\n",
       "30. 0.976475916865322\n",
       "31. 1.0579604614182\n",
       "32. 1.34799701363132\n",
       "33. 1.19899762353575\n",
       "34. 1.27171485801897\n",
       "35. 1.05699113618212\n",
       "36. 1.13180469730654\n",
       "37. 1.10677912927435\n",
       "38. 1.0634385908919\n",
       "39. 1.11938566033568\n",
       "40. 1.3211769391864\n",
       "41. 1.13266184655957\n",
       "42. 0.94795187110649\n",
       "43. 1.07339346845227\n",
       "44. 0.955267833832056\n",
       "45. 1.33843296225037\n",
       "46. 1.26601665144164\n",
       "47. 1.26421684786365\n",
       "48. 1.08955636911983\n",
       "49. 1.12921117314449\n",
       "50. 0.37123564366995\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 1.1400643 1.2686734 1.2782903 1.2298219 1.1160626 1.2133782 1.3555167\n",
       " [8] 1.3519476 1.2425972 1.2496750 1.1804115 1.0187640 1.2427226 1.2539713\n",
       "[15] 0.9846226 0.9056751 1.0653038 1.1131766 1.1161188 1.3236518 1.0385615\n",
       "[22] 1.2357331 1.1185130 0.9611277 1.0538750 1.1426962 1.1123400 1.0463891\n",
       "[29] 1.0959879 0.9764759 1.0579605 1.3479970 1.1989976 1.2717149 1.0569911\n",
       "[36] 1.1318047 1.1067791 1.0634386 1.1193857 1.3211769 1.1326618 0.9479519\n",
       "[43] 1.0733935 0.9552678 1.3384330 1.2660167 1.2642168 1.0895564 1.1292112\n",
       "[50] 0.3712356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pour comparer avec la methode de Monte Carlo\n",
    "\n",
    "#Calculer les resultats par t-IMSE standard\n",
    "s = 0\n",
    "\n",
    "shape = c(dim(data_lasso_reduced[,c(-1)]))\n",
    "noise = matrix(runif(prod(shape),min = 0.000001,max = 0.000002), nrow = n_init)\n",
    "mod = km(formula = ~1, design = data_lasso_reduced[,c(-1)]+noise, response = data_lasso_reduced[,1])\n",
    "x = data_lasso_reduced[1:50,c(-1)]\n",
    "tmse_optim(x, model = mod, T = log(400))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec41281d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 \n",
      "  - parameters upper bounds :  1.976771e-08 76.64 53.3 90 19.1 83 1.112876 0.51714 120.92 26.8 65.02 1.16 105.1 28 35.12 43.46 30 1.983494e-08 101.54 1.99864e-08 14.8 1.982789e-08 158.16 2 1.42 39.6 6.78 42.58 155.52 \n",
      "  - best initial criterion value(s) :  -582.3132 \n",
      "\n",
      "N = 29, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       582.31  |proj g|=       7.6017\n",
      "At iterate     1  f =        561.1  |proj g|=        8.9693\n",
      "At iterate     2  f =       552.57  |proj g|=        9.1913\n",
      "At iterate     3  f =        550.7  |proj g|=        9.6593\n",
      "At iterate     4  f =       549.89  |proj g|=        9.5577\n",
      "At iterate     5  f =       549.81  |proj g|=        9.4657\n",
      "At iterate     6  f =        549.8  |proj g|=        9.4971\n",
      "At iterate     7  f =        549.8  |proj g|=         9.494\n",
      "At iterate     8  f =        549.8  |proj g|=        9.4938\n",
      "\n",
      "iterations 8\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 3\n",
      "norm of the final projected gradient 9.49384\n",
      "final function value 549.801\n",
      "\n",
      "F = 549.801\n",
      "final  value 549.800661 \n",
      "converged\n",
      "[1] 1.757591\n"
     ]
    }
   ],
   "source": [
    "#Resultats par la methode Monte Carlo \n",
    "mod = km(formula = ~1, design = data_lasso_reduced[,c(-1)] + noise, response = data_lasso_reduced[,1])\n",
    "print(tmse(d = 29, mod, T = log(400)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa28870",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d83fade9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 \n",
      "  - parameters upper bounds :  1.976771e-08 76.64 53.3 90 19.1 83 1.112876 0.51714 120.92 26.8 65.02 1.16 105.1 28 35.12 43.46 30 1.983494e-08 101.54 1.99864e-08 14.8 1.982789e-08 158.16 2 1.42 39.6 6.78 42.58 155.52 \n",
      "  - best initial criterion value(s) :  -515.217 \n",
      "\n",
      "N = 29, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       515.22  |proj g|=      0.78842\n",
      "At iterate     1  f =       503.19  |proj g|=        1.2847\n",
      "At iterate     2  f =       499.84  |proj g|=        1.2847\n",
      "At iterate     3  f =       499.81  |proj g|=        1.2847\n",
      "At iterate     4  f =       499.19  |proj g|=        1.2847\n",
      "At iterate     5  f =       499.12  |proj g|=        1.2847\n",
      "At iterate     6  f =       499.11  |proj g|=        1.2847\n",
      "At iterate     7  f =       499.11  |proj g|=        1.2847\n",
      "At iterate     8  f =        499.1  |proj g|=        1.2847\n",
      "At iterate     9  f =        499.1  |proj g|=        1.2847\n",
      "\n",
      "iterations 9\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 2\n",
      "norm of the final projected gradient 1.28472\n",
      "final function value 499.104\n",
      "\n",
      "F = 499.104\n",
      "final  value 499.104379 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "#Modele initial\n",
    "m0 = km(formula = ~1, design = data_lasso_reduced[,c(-1)] + noise, response = data_lasso_reduced[,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ab9668",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Normal QQ-plot of standardized residuals\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae283fd2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbcdbdd2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#TROUVER LE POINT LE PLUS PROCHE D'UN NOUVEAU POINT\n",
    "\n",
    "#input: nouveau point: 'x_new' ; donnees dans lesquelles on cherche: 'data'\n",
    "#output: la valeur y du point le plus proche\n",
    "\n",
    "\n",
    "# pointProche <- function(x_new, data){\n",
    "#     X_cher = data[,c(-1)]\n",
    "#     sub = do.call(rbind, apply(X_cher, 1, function(x){return(x - x_new)}))\n",
    "#     norms = apply(sub, 1, function(x){return(norm(as.numeric(x), type = \"2\"))})\n",
    "#     argmin = which.min(norms)\n",
    "#     return (data[argmin,])\n",
    "# }\n",
    "\n",
    "pointProche <- function(x_new, data){\n",
    "    X_cher = data[,c(-1)]\n",
    "    argmin = 1\n",
    "    minvalue = norm(x_new- X_cher[1,], type = \"2\") \n",
    "    n_points = nrow(data) #longeur da la base de données\n",
    "\n",
    "    for (i in 2:n_points){\n",
    "        mse = norm(x_new- X_cher[i,], type = \"2\")\n",
    "        \n",
    "        if (mse < minvalue){\n",
    "            minvalue = mse \n",
    "            argmin = i\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return (data[argmin,])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dc73f3ea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 30</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>vis</th><th scope=col>X__3</th><th scope=col>X__4</th><th scope=col>X__8</th><th scope=col>X__10</th><th scope=col>X__17</th><th scope=col>X__18</th><th scope=col>X__29</th><th scope=col>X__30</th><th scope=col>X__43</th><th scope=col>...</th><th scope=col>X__84</th><th scope=col>X__86</th><th scope=col>X__106</th><th scope=col>X__109</th><th scope=col>X__113</th><th scope=col>X__115</th><th scope=col>X__117</th><th scope=col>X__133</th><th scope=col>X__138</th><th scope=col>autres</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3337</th><td>7.713785</td><td>0</td><td>14.7</td><td>0</td><td>0</td><td>0</td><td>15.9</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>55.5</td><td>0</td><td>0.1</td><td>0</td><td>0</td><td>0</td><td>4.8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 30\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & vis & X\\_\\_3 & X\\_\\_4 & X\\_\\_8 & X\\_\\_10 & X\\_\\_17 & X\\_\\_18 & X\\_\\_29 & X\\_\\_30 & X\\_\\_43 & ... & X\\_\\_84 & X\\_\\_86 & X\\_\\_106 & X\\_\\_109 & X\\_\\_113 & X\\_\\_115 & X\\_\\_117 & X\\_\\_133 & X\\_\\_138 & autres\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t3337 & 7.713785 & 0 & 14.7 & 0 & 0 & 0 & 15.9 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 55.5 & 0 & 0.1 & 0 & 0 & 0 & 4.8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 30\n",
       "\n",
       "| <!--/--> | vis &lt;dbl&gt; | X__3 &lt;dbl&gt; | X__4 &lt;dbl&gt; | X__8 &lt;dbl&gt; | X__10 &lt;dbl&gt; | X__17 &lt;dbl&gt; | X__18 &lt;dbl&gt; | X__29 &lt;dbl&gt; | X__30 &lt;dbl&gt; | X__43 &lt;dbl&gt; | ... ... | X__84 &lt;dbl&gt; | X__86 &lt;dbl&gt; | X__106 &lt;dbl&gt; | X__109 &lt;dbl&gt; | X__113 &lt;dbl&gt; | X__115 &lt;dbl&gt; | X__117 &lt;dbl&gt; | X__133 &lt;dbl&gt; | X__138 &lt;dbl&gt; | autres &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3337 | 7.713785 | 0 | 14.7 | 0 | 0 | 0 | 15.9 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 55.5 | 0 | 0.1 | 0 | 0 | 0 | 4.8 |\n",
       "\n"
      ],
      "text/plain": [
       "     vis      X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 ... X__84\n",
       "3337 7.713785 0    14.7 0    0     0     15.9  0     0     0     ... 0    \n",
       "     X__86 X__106 X__109 X__113 X__115 X__117 X__133 X__138 autres\n",
       "3337 0     0      55.5   0      0.1    0      0      0      4.8   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pointProche(X[1,],data_recherche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1ab03eac",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "new_tmse = function(x_new){\n",
    "    # d: dimension, d = 29\n",
    "    data = data_updated\n",
    "    d = 29\n",
    "    niter = 1000\n",
    "    s = 0\n",
    "    data_recherche = data_lasso_log[setdiff(1:nrow(data_lasso_log),index),]\n",
    "    print(dim(data_recherche))\n",
    "    \n",
    "    newpoint = pointProche(x_new, data_recherche)\n",
    "    \n",
    "    data_new = data.frame(data)\n",
    "    data_new[nrow(data_new) + 1, ] = newpoint\n",
    "    noise = matrix(runif(prod(dim(data_new[,c(-1)])),min = 0.0001,max = 0.0002), nrow = nrow(data_new))\n",
    "    #mod = km(formula = ~1, design = data_new + noise, response = data_new[1],)\n",
    "    mod = update(m0, newX = data_new[,c(-1)]+noise, newy = data_new[,1],newX.alreadyExist = FALSE, cov.reestim = FALSE, trend.reestim = FALSE)\n",
    "    for(i in 1:niter){\n",
    "        x = simul(d)\n",
    "        s = s + g_new(x, m0 = m0, model = mod, T = log(400))\n",
    "    }\n",
    "    tmse = s/niter\n",
    "    return(tmse)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "247edee3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 29</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X__3</th><th scope=col>X__4</th><th scope=col>X__8</th><th scope=col>X__10</th><th scope=col>X__17</th><th scope=col>X__18</th><th scope=col>X__29</th><th scope=col>X__30</th><th scope=col>X__43</th><th scope=col>X__46</th><th scope=col>...</th><th scope=col>X__84</th><th scope=col>X__86</th><th scope=col>X__106</th><th scope=col>X__109</th><th scope=col>X__113</th><th scope=col>X__115</th><th scope=col>X__117</th><th scope=col>X__133</th><th scope=col>X__138</th><th scope=col>autres</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0</td><td>9.42</td><td>8.52</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>68.39</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 29\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & X\\_\\_3 & X\\_\\_4 & X\\_\\_8 & X\\_\\_10 & X\\_\\_17 & X\\_\\_18 & X\\_\\_29 & X\\_\\_30 & X\\_\\_43 & X\\_\\_46 & ... & X\\_\\_84 & X\\_\\_86 & X\\_\\_106 & X\\_\\_109 & X\\_\\_113 & X\\_\\_115 & X\\_\\_117 & X\\_\\_133 & X\\_\\_138 & autres\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 0 & 9.42 & 8.52 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 68.39 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 29\n",
       "\n",
       "| <!--/--> | X__3 &lt;dbl&gt; | X__4 &lt;dbl&gt; | X__8 &lt;dbl&gt; | X__10 &lt;dbl&gt; | X__17 &lt;dbl&gt; | X__18 &lt;dbl&gt; | X__29 &lt;dbl&gt; | X__30 &lt;dbl&gt; | X__43 &lt;dbl&gt; | X__46 &lt;dbl&gt; | ... ... | X__84 &lt;dbl&gt; | X__86 &lt;dbl&gt; | X__106 &lt;dbl&gt; | X__109 &lt;dbl&gt; | X__113 &lt;dbl&gt; | X__115 &lt;dbl&gt; | X__117 &lt;dbl&gt; | X__133 &lt;dbl&gt; | X__138 &lt;dbl&gt; | autres &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0 | 9.42 | 8.52 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 68.39 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 ... X__84 X__86\n",
       "1 0    9.42 8.52 0     0     0     0     0     0     0     ... 0     0    \n",
       "  X__106 X__109 X__113 X__115 X__117 X__133 X__138 autres\n",
       "1 0      68.39  0      0      0      0      0      0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1.22248457761568"
      ],
      "text/latex": [
       "1.22248457761568"
      ],
      "text/markdown": [
       "1.22248457761568"
      ],
      "text/plain": [
       "[1] 1.222485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lasso[1,c(-1)]\n",
    "new_tmse(data_lasso[1,c(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "21e97b3f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "contraintes = function(x){\n",
    "  n = length(x)\n",
    "  h<-numeric(n+2)\n",
    "  h[1]<- 100 - sum(x) #somme = 1\n",
    "  h[2]<- sum(x) - 100\n",
    "  #h[3:n+2] = as.numeric(x)\n",
    "  for (i in range(3,n+2)){\n",
    "    h[i] = x[i-2]\n",
    "  }\n",
    "  return(h)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ae6534e7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Starting...\"\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "          vis X__3  X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "5145 8.779096    0 24.19    0  0.32     0 13.41     0     0     0     0     0\n",
      "     X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "5145     0  6.42     0     0   2.1     0     0  5.06     0  0.75      0  42.41\n",
      "     X__113 X__115 X__117 X__133 X__138 autres\n",
      "5145      0      0      0      0      0   5.34\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "          vis X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "1948 5.560682    0    0 1.02 13.14     0  1.02     0     0     0     0     0\n",
      "     X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "1948     0  7.18     0     0  1.02     0     0  0.81     0     0      0  45.17\n",
      "     X__113 X__115 X__117 X__133 X__138 autres\n",
      "1948      0      0      0      0      0  30.64\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "          vis X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "1947 4.718499    0    0    0 12.39     0  2.51     0     0     0     0     0\n",
      "     X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "1947     0  2.97     0     0     0     0     0     0     0     0      0  41.18\n",
      "     X__113 X__115 X__117 X__133 X__138 autres\n",
      "1947      0      0      0      0      0  40.95\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "         vis X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "309 5.723585    0  0.2    0     0     0     0     0     0     0     0     0\n",
      "    X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "309     0     0     0     0     0     0     0 17.31     0     0      0  66.66\n",
      "    X__113 X__115 X__117 X__133 X__138 autres\n",
      "309      0    0.2  15.61      0      0   0.02\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "         vis X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "605 7.599902    0    0    0     0     0   2.3     0     0     0     0     0\n",
      "    X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "605     0     0     0     0  1.49     0     0 14.59     0     0      0   73.5\n",
      "    X__113 X__115 X__117 X__133 X__138 autres\n",
      "605      0      0      0      0   4.99   3.13\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "          vis X__3  X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "2558 5.713733    0 11.13 8.23     0     0 22.76     0     0     0     0     0\n",
      "     X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "2558     0     0     0     0  4.07     0     0     0     0     0      0  53.78\n",
      "     X__113 X__115 X__117 X__133 X__138 autres\n",
      "2558      0      0      0      0      0   0.03\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "          vis X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "2503 1.791759    0  8.9    0     0     0  26.8     0     0  30.9     0     0\n",
      "     X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "2503     0     0     0     0     0     0     0     0     0     0      0   33.4\n",
      "     X__113 X__115 X__117 X__133 X__138 autres\n",
      "2503      0      0      0      0      0      0\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "         vis X__3 X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "771 3.367296    0    0    0     0     0 11.85  4.03     0 44.52     0     0\n",
      "    X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "771     0     0     0     0     0     0     0     0     0     0      0  39.58\n",
      "    X__113 X__115 X__117 X__133 X__138 autres\n",
      "771      0      0      0      0      0   0.02\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "[1] 6697   30\n",
      "         vis X__3  X__4 X__8 X__10 X__17 X__18 X__29 X__30 X__43 X__46 X__48\n",
      "2133 3.73767    0 11.23    0  5.94     0 13.89     0     0  23.9     0     0\n",
      "     X__49 X__53 X__57 X__59 X__64 X__67 X__71 X__74 X__84 X__86 X__106 X__109\n",
      "2133     0     0     0     0     0     0     0     0     0     0      0  44.13\n",
      "     X__113 X__115 X__117 X__133 X__138 autres\n",
      "2133      0      0      0      0      0   0.91\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTIMISATION TMSE PROCESS USING COBYLA\n",
    "\n",
    "# Some parameters\n",
    "d = 29  # data dimension\n",
    "n_init = 10*d   # initial number of data points\n",
    "n_points = nrow(data_lasso) # total number of data points\n",
    "n_adds = 10 # number of additional data points\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting...\")\n",
    "# Loop over additional data points\n",
    "for (i in 1:n_adds){\n",
    "\n",
    "    print(\"Adding point... \")\n",
    "    data_recherche = data_lasso_log[setdiff(1:nrow(data_lasso),index),]\n",
    "    x_new = cobyla(x0 = as.numeric(X[i,]), fn = new_tmse, hin = contraintes, control = list(xtol_rel = 1e-3))$par\n",
    "    newpoint = pointProche(x_new,data_recherche)\n",
    "    print(newpoint)\n",
    "    data_updated[nrow(data_updated) + 1, ] = newpoint\n",
    "    #data_updated = rbind(data_updated,newpoint)\n",
    "    X = data_updated[,c(-1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da383e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 300 × 28</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X__3</th><th scope=col>X__4</th><th scope=col>X__8</th><th scope=col>X__10</th><th scope=col>X__17</th><th scope=col>X__18</th><th scope=col>X__29</th><th scope=col>X__30</th><th scope=col>X__43</th><th scope=col>X__48</th><th scope=col>...</th><th scope=col>X__84</th><th scope=col>X__86</th><th scope=col>X__106</th><th scope=col>X__109</th><th scope=col>X__113</th><th scope=col>X__115</th><th scope=col>X__117</th><th scope=col>X__133</th><th scope=col>X__138</th><th scope=col>autres</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>4278</th><td>0</td><td> 2.300000</td><td> 0.000000</td><td> 9.50</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.1000000</td><td>0</td><td>61.10000</td><td>0.0000000</td><td>0.0000000</td><td> 8.70000</td><td>0.0000000</td><td>1.80000</td><td> 1.30000</td></tr>\n",
       "\t<tr><th scope=row>1862</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>75.25000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.02000</td></tr>\n",
       "\t<tr><th scope=row>5016</th><td>0</td><td> 9.600000</td><td> 0.000000</td><td> 3.00</td><td> 0</td><td> 7.9000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>62.11000</td><td>0.0000000</td><td>0.2000000</td><td> 2.00000</td><td>0.0000000</td><td>1.50000</td><td> 0.11000</td></tr>\n",
       "\t<tr><th scope=row>6393</th><td>0</td><td>23.600000</td><td> 5.400000</td><td> 0.00</td><td> 0</td><td> 4.3000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>55.70000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.01000</td></tr>\n",
       "\t<tr><th scope=row>3001</th><td>0</td><td>15.130000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 9.2700000</td><td>0.0000000</td><td>0.0000000</td><td> 5.15</td><td> 0.00</td><td>...</td><td>0</td><td>0.1200000</td><td>0</td><td>51.97000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 5.39000</td></tr>\n",
       "\t<tr><th scope=row>2157</th><td>0</td><td>11.020000</td><td> 0.000000</td><td> 1.97</td><td> 0</td><td>17.3100000</td><td>0.0000000</td><td>0.0000000</td><td>23.90</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>45.21000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.59000</td></tr>\n",
       "\t<tr><th scope=row>1822</th><td>0</td><td> 5.980000</td><td> 6.280000</td><td> 4.98</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>68.49000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 9.29000</td></tr>\n",
       "\t<tr><th scope=row>3993</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 1.6000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>69.00000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>4.00000</td><td> 0.00000</td></tr>\n",
       "\t<tr><th scope=row>4839</th><td>0</td><td> 2.500000</td><td> 2.800000</td><td> 0.60</td><td> 0</td><td> 6.4000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>61.16000</td><td>0.0000000</td><td>0.2000000</td><td> 3.10000</td><td>0.0000000</td><td>0.60000</td><td> 0.13000</td></tr>\n",
       "\t<tr><th scope=row>2837</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td>31.4200000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>51.47000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.01000</td></tr>\n",
       "\t<tr><th scope=row>801</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td>21.0500000</td><td>5.2500000</td><td>0.0000000</td><td>36.62</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>37.07000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.01000</td></tr>\n",
       "\t<tr><th scope=row>385</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td>32.12</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>51.49000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.02000</td></tr>\n",
       "\t<tr><th scope=row>5132</th><td>0</td><td>16.500000</td><td>10.300000</td><td> 0.50</td><td> 0</td><td> 8.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>59.62000</td><td>0.2200000</td><td>0.0000000</td><td> 4.50000</td><td>0.0000000</td><td>0.04000</td><td> 0.02000</td></tr>\n",
       "\t<tr><th scope=row>2330</th><td>0</td><td> 3.340000</td><td> 4.990000</td><td>40.04</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>36.27000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td>14.77000</td></tr>\n",
       "\t<tr><th scope=row>609</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 2.1900000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>73.60000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 9.32000</td></tr>\n",
       "\t<tr><th scope=row>2502</th><td>0</td><td> 5.000000</td><td> 0.000000</td><td> 0.00</td><td>25</td><td>50.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>20.00000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.00000</td></tr>\n",
       "\t<tr><th scope=row>800</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td>20.1100000</td><td>7.7800000</td><td>0.0000000</td><td>34.54</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>37.54000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.03000</td></tr>\n",
       "\t<tr><th scope=row>7236</th><td>0</td><td> 8.500000</td><td> 6.610000</td><td> 3.86</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.1400000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>3.0500000</td><td>0</td><td>23.62000</td><td>0.0000000</td><td>0.0000000</td><td> 1.80000</td><td>0.0000000</td><td>0.00000</td><td>30.40000</td></tr>\n",
       "\t<tr><th scope=row>1113</th><td>0</td><td> 0.000000</td><td> 2.410000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>57.58000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td>26.83000</td></tr>\n",
       "\t<tr><th scope=row>654</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>28.76000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td>71.24000</td></tr>\n",
       "\t<tr><th scope=row>3595</th><td>0</td><td>14.080000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>7.6500000</td><td>0</td><td>58.38000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.03000</td></tr>\n",
       "\t<tr><th scope=row>6800</th><td>0</td><td> 7.090000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 6.2900000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>60.53000</td><td>0.0000000</td><td>0.0000000</td><td> 1.59000</td><td>0.0000000</td><td>4.09000</td><td> 0.05000</td></tr>\n",
       "\t<tr><th scope=row>3194</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td>11.0500000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>41.32000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td>47.63000</td></tr>\n",
       "\t<tr><th scope=row>3088</th><td>0</td><td> 0.390000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td>24.8700000</td><td>0.0000000</td><td>0.0000000</td><td>34.05</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>40.37000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.32000</td></tr>\n",
       "\t<tr><th scope=row>4609</th><td>0</td><td> 6.800000</td><td> 4.510000</td><td> 0.00</td><td> 0</td><td> 4.7100000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>69.44000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.25000</td></tr>\n",
       "\t<tr><th scope=row>2302</th><td>0</td><td> 0.800000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 9.8000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>72.50000</td><td>0.0000000</td><td>0.3000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.20000</td></tr>\n",
       "\t<tr><th scope=row>4033</th><td>0</td><td> 2.350000</td><td> 0.000000</td><td> 8.85</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>62.42000</td><td>0.0000000</td><td>0.0000000</td><td> 8.97000</td><td>0.0000000</td><td>1.77000</td><td> 1.50000</td></tr>\n",
       "\t<tr><th scope=row>1918</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>46.49000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td>46.79000</td></tr>\n",
       "\t<tr><th scope=row>1450</th><td>0</td><td> 0.000000</td><td> 0.000000</td><td> 0.00</td><td> 0</td><td> 0.0000000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.0000000</td><td>0</td><td>61.86000</td><td>0.0000000</td><td>0.0000000</td><td> 0.00000</td><td>0.0000000</td><td>0.00000</td><td> 0.01000</td></tr>\n",
       "\t<tr><th scope=row>7093</th><td>0</td><td> 3.000303</td><td> 6.000606</td><td> 0.00</td><td> 0</td><td> 0.3000063</td><td>0.6000606</td><td>0.2498892</td><td> 0.00</td><td> 0.00</td><td>...</td><td>0</td><td>0.6400806</td><td>0</td><td>35.00353</td><td>0.2300512</td><td>0.3299693</td><td>10.00101</td><td>0.0800481</td><td>9.60097</td><td>19.52956</td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>649</th><td> 0</td><td> 0.000000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 0.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>43.75000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td>46.4600000</td></tr>\n",
       "\t<tr><th scope=row>4457</th><td> 0</td><td>12.430000</td><td> 8.49000</td><td> 0.0000000</td><td> 0</td><td> 5.9800000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>57.72000</td><td> 0.00</td><td> 0.0000000</td><td>11.060000</td><td> 0.00</td><td> 0.000000</td><td> 0.0200000</td></tr>\n",
       "\t<tr><th scope=row>3904</th><td> 0</td><td>13.000000</td><td> 0.00000</td><td> 7.0000000</td><td> 0</td><td> 4.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>53.00000</td><td> 0.00</td><td> 0.0000000</td><td> 4.000000</td><td> 0.00</td><td> 5.000000</td><td> 0.0000000</td></tr>\n",
       "\t<tr><th scope=row>7008</th><td> 0</td><td> 6.893067</td><td>12.99792</td><td> 0.1999686</td><td> 0</td><td> 0.4999214</td><td> 0.1329791</td><td> 0.00999843</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.4999214</td><td> 0</td><td>40.99356</td><td> 0.00</td><td> 0.0999843</td><td> 3.499407</td><td> 0.00</td><td> 1.499801</td><td>17.4399857</td></tr>\n",
       "\t<tr><th scope=row>3541</th><td> 0</td><td> 8.360000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 7.3600000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>66.06000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.0300000</td></tr>\n",
       "\t<tr><th scope=row>2357</th><td> 0</td><td> 7.210000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 8.2100000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>65.13000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 2.5300000</td></tr>\n",
       "\t<tr><th scope=row>324</th><td> 0</td><td> 0.380000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 4.5000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>73.94000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.2100000</td></tr>\n",
       "\t<tr><th scope=row>3210</th><td> 0</td><td> 4.300000</td><td> 0.00000</td><td> 5.7000000</td><td> 0</td><td> 4.8000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>58.50000</td><td> 0.00</td><td> 0.2000000</td><td> 9.700000</td><td> 0.00</td><td> 2.700000</td><td> 2.1000000</td></tr>\n",
       "\t<tr><th scope=row>2677</th><td> 0</td><td> 3.500000</td><td>10.00000</td><td> 0.0000000</td><td> 0</td><td> 3.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>73.65000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 2.500000</td><td> 1.6000000</td></tr>\n",
       "\t<tr><th scope=row>4794</th><td> 0</td><td>11.970000</td><td>14.27000</td><td> 0.9900000</td><td> 0</td><td> 4.7900000</td><td> 0.0900000</td><td> 1.09000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>38.02000</td><td> 0.00</td><td> 0.0000000</td><td> 0.290000</td><td> 0.19</td><td> 1.890000</td><td> 8.6700000</td></tr>\n",
       "\t<tr><th scope=row>2508</th><td> 0</td><td> 5.000000</td><td> 0.00000</td><td> 0.0000000</td><td>45</td><td>20.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>30.00000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.0000000</td></tr>\n",
       "\t<tr><th scope=row>4084</th><td> 0</td><td> 2.550000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 7.4500000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>71.21000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 1.1500000</td></tr>\n",
       "\t<tr><th scope=row>117</th><td> 0</td><td> 0.000000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 0.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>63.28000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.0100000</td></tr>\n",
       "\t<tr><th scope=row>6814</th><td> 0</td><td> 7.790000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td> 2.5700000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>62.48000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 3.760000</td><td> 0.0300000</td></tr>\n",
       "\t<tr><th scope=row>2074</th><td> 0</td><td> 0.000000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td>14.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>74.00000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.0000000</td></tr>\n",
       "\t<tr><th scope=row>1837</th><td> 0</td><td>14.970000</td><td> 0.00000</td><td> 3.9900000</td><td> 0</td><td>16.4600000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>61.87000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 2.490000</td><td> 0.2200000</td></tr>\n",
       "\t<tr><th scope=row>4131</th><td> 0</td><td> 8.620000</td><td> 8.32000</td><td> 0.0000000</td><td> 0</td><td> 2.7000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>71.91000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.0300000</td></tr>\n",
       "\t<tr><th scope=row>5757</th><td> 0</td><td>17.130000</td><td> 4.93000</td><td>10.9500000</td><td> 0</td><td> 4.4600000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>59.05000</td><td> 0.00</td><td> 0.0000000</td><td> 1.000000</td><td> 0.00</td><td> 0.000000</td><td> 0.7500000</td></tr>\n",
       "\t<tr><th scope=row>5538</th><td> 0</td><td>16.470000</td><td>10.10000</td><td> 0.4500000</td><td> 0</td><td> 7.9700000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.0</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>59.79000</td><td> 0.22</td><td> 0.0000000</td><td> 4.960000</td><td> 0.00</td><td> 0.000000</td><td> 0.0400000</td></tr>\n",
       "\t<tr><th scope=row>1482</th><td> 0</td><td> 5.530000</td><td> 0.00000</td><td> 0.0000000</td><td> 0</td><td>30.2800000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.4</td><td> 0</td><td>...</td><td> 0</td><td> 0.0000000</td><td> 0</td><td>34.20000</td><td> 0.00</td><td> 0.0000000</td><td> 0.000000</td><td> 0.00</td><td> 0.000000</td><td> 9.3900000</td></tr>\n",
       "\t<tr><th scope=row>291</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.0032399</td></tr>\n",
       "\t<tr><th scope=row>292</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.0459753</td></tr>\n",
       "\t<tr><th scope=row>293</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.1187486</td></tr>\n",
       "\t<tr><th scope=row>294</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.1664930</td></tr>\n",
       "\t<tr><th scope=row>295</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.3513410</td></tr>\n",
       "\t<tr><th scope=row>296</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 0.9975013</td></tr>\n",
       "\t<tr><th scope=row>297</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.0603035</td></tr>\n",
       "\t<tr><th scope=row>298</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 0.9903548</td></tr>\n",
       "\t<tr><th scope=row>299</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.0113684</td></tr>\n",
       "\t<tr><th scope=row>300.1</th><td>38</td><td>38.000000</td><td>38.00000</td><td>38.0000000</td><td>38</td><td>38.0000000</td><td>38.0000000</td><td>38.00000000</td><td>38.0</td><td>38</td><td>...</td><td>38</td><td>38.0000000</td><td>38</td><td>38.00000</td><td>38.00</td><td>38.0000000</td><td>38.000000</td><td>38.00</td><td>38.000000</td><td> 1.0167788</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 300 × 28\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & X\\_\\_3 & X\\_\\_4 & X\\_\\_8 & X\\_\\_10 & X\\_\\_17 & X\\_\\_18 & X\\_\\_29 & X\\_\\_30 & X\\_\\_43 & X\\_\\_48 & ... & X\\_\\_84 & X\\_\\_86 & X\\_\\_106 & X\\_\\_109 & X\\_\\_113 & X\\_\\_115 & X\\_\\_117 & X\\_\\_133 & X\\_\\_138 & autres\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t4278 & 0 &  2.300000 &  0.000000 &  9.50 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.1000000 & 0 & 61.10000 & 0.0000000 & 0.0000000 &  8.70000 & 0.0000000 & 1.80000 &  1.30000\\\\\n",
       "\t1862 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 75.25000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.02000\\\\\n",
       "\t5016 & 0 &  9.600000 &  0.000000 &  3.00 &  0 &  7.9000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 62.11000 & 0.0000000 & 0.2000000 &  2.00000 & 0.0000000 & 1.50000 &  0.11000\\\\\n",
       "\t6393 & 0 & 23.600000 &  5.400000 &  0.00 &  0 &  4.3000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 55.70000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.01000\\\\\n",
       "\t3001 & 0 & 15.130000 &  0.000000 &  0.00 &  0 &  9.2700000 & 0.0000000 & 0.0000000 &  5.15 &  0.00 & ... & 0 & 0.1200000 & 0 & 51.97000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  5.39000\\\\\n",
       "\t2157 & 0 & 11.020000 &  0.000000 &  1.97 &  0 & 17.3100000 & 0.0000000 & 0.0000000 & 23.90 &  0.00 & ... & 0 & 0.0000000 & 0 & 45.21000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.59000\\\\\n",
       "\t1822 & 0 &  5.980000 &  6.280000 &  4.98 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 68.49000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  9.29000\\\\\n",
       "\t3993 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  1.6000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 69.00000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 4.00000 &  0.00000\\\\\n",
       "\t4839 & 0 &  2.500000 &  2.800000 &  0.60 &  0 &  6.4000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 61.16000 & 0.0000000 & 0.2000000 &  3.10000 & 0.0000000 & 0.60000 &  0.13000\\\\\n",
       "\t2837 & 0 &  0.000000 &  0.000000 &  0.00 &  0 & 31.4200000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 51.47000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.01000\\\\\n",
       "\t801 & 0 &  0.000000 &  0.000000 &  0.00 &  0 & 21.0500000 & 5.2500000 & 0.0000000 & 36.62 &  0.00 & ... & 0 & 0.0000000 & 0 & 37.07000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.01000\\\\\n",
       "\t385 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 & 32.12 & ... & 0 & 0.0000000 & 0 & 51.49000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.02000\\\\\n",
       "\t5132 & 0 & 16.500000 & 10.300000 &  0.50 &  0 &  8.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 59.62000 & 0.2200000 & 0.0000000 &  4.50000 & 0.0000000 & 0.04000 &  0.02000\\\\\n",
       "\t2330 & 0 &  3.340000 &  4.990000 & 40.04 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 36.27000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 & 14.77000\\\\\n",
       "\t609 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  2.1900000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 73.60000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  9.32000\\\\\n",
       "\t2502 & 0 &  5.000000 &  0.000000 &  0.00 & 25 & 50.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 20.00000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.00000\\\\\n",
       "\t800 & 0 &  0.000000 &  0.000000 &  0.00 &  0 & 20.1100000 & 7.7800000 & 0.0000000 & 34.54 &  0.00 & ... & 0 & 0.0000000 & 0 & 37.54000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.03000\\\\\n",
       "\t7236 & 0 &  8.500000 &  6.610000 &  3.86 &  0 &  0.0000000 & 0.0000000 & 0.1400000 &  0.00 &  0.00 & ... & 0 & 3.0500000 & 0 & 23.62000 & 0.0000000 & 0.0000000 &  1.80000 & 0.0000000 & 0.00000 & 30.40000\\\\\n",
       "\t1113 & 0 &  0.000000 &  2.410000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 57.58000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 & 26.83000\\\\\n",
       "\t654 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 28.76000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 & 71.24000\\\\\n",
       "\t3595 & 0 & 14.080000 &  0.000000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 7.6500000 & 0 & 58.38000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.03000\\\\\n",
       "\t6800 & 0 &  7.090000 &  0.000000 &  0.00 &  0 &  6.2900000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 60.53000 & 0.0000000 & 0.0000000 &  1.59000 & 0.0000000 & 4.09000 &  0.05000\\\\\n",
       "\t3194 & 0 &  0.000000 &  0.000000 &  0.00 &  0 & 11.0500000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 41.32000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 & 47.63000\\\\\n",
       "\t3088 & 0 &  0.390000 &  0.000000 &  0.00 &  0 & 24.8700000 & 0.0000000 & 0.0000000 & 34.05 &  0.00 & ... & 0 & 0.0000000 & 0 & 40.37000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.32000\\\\\n",
       "\t4609 & 0 &  6.800000 &  4.510000 &  0.00 &  0 &  4.7100000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 69.44000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.25000\\\\\n",
       "\t2302 & 0 &  0.800000 &  0.000000 &  0.00 &  0 &  9.8000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 72.50000 & 0.0000000 & 0.3000000 &  0.00000 & 0.0000000 & 0.00000 &  0.20000\\\\\n",
       "\t4033 & 0 &  2.350000 &  0.000000 &  8.85 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 62.42000 & 0.0000000 & 0.0000000 &  8.97000 & 0.0000000 & 1.77000 &  1.50000\\\\\n",
       "\t1918 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 46.49000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 & 46.79000\\\\\n",
       "\t1450 & 0 &  0.000000 &  0.000000 &  0.00 &  0 &  0.0000000 & 0.0000000 & 0.0000000 &  0.00 &  0.00 & ... & 0 & 0.0000000 & 0 & 61.86000 & 0.0000000 & 0.0000000 &  0.00000 & 0.0000000 & 0.00000 &  0.01000\\\\\n",
       "\t7093 & 0 &  3.000303 &  6.000606 &  0.00 &  0 &  0.3000063 & 0.6000606 & 0.2498892 &  0.00 &  0.00 & ... & 0 & 0.6400806 & 0 & 35.00353 & 0.2300512 & 0.3299693 & 10.00101 & 0.0800481 & 9.60097 & 19.52956\\\\\n",
       "\t... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... &  & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t649 &  0 &  0.000000 &  0.00000 &  0.0000000 &  0 &  0.0000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 43.75000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 & 46.4600000\\\\\n",
       "\t4457 &  0 & 12.430000 &  8.49000 &  0.0000000 &  0 &  5.9800000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 57.72000 &  0.00 &  0.0000000 & 11.060000 &  0.00 &  0.000000 &  0.0200000\\\\\n",
       "\t3904 &  0 & 13.000000 &  0.00000 &  7.0000000 &  0 &  4.0000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 53.00000 &  0.00 &  0.0000000 &  4.000000 &  0.00 &  5.000000 &  0.0000000\\\\\n",
       "\t7008 &  0 &  6.893067 & 12.99792 &  0.1999686 &  0 &  0.4999214 &  0.1329791 &  0.00999843 &  0.0 &  0 & ... &  0 &  0.4999214 &  0 & 40.99356 &  0.00 &  0.0999843 &  3.499407 &  0.00 &  1.499801 & 17.4399857\\\\\n",
       "\t3541 &  0 &  8.360000 &  0.00000 &  0.0000000 &  0 &  7.3600000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 66.06000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  0.0300000\\\\\n",
       "\t2357 &  0 &  7.210000 &  0.00000 &  0.0000000 &  0 &  8.2100000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 65.13000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  2.5300000\\\\\n",
       "\t324 &  0 &  0.380000 &  0.00000 &  0.0000000 &  0 &  4.5000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 73.94000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  0.2100000\\\\\n",
       "\t3210 &  0 &  4.300000 &  0.00000 &  5.7000000 &  0 &  4.8000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 58.50000 &  0.00 &  0.2000000 &  9.700000 &  0.00 &  2.700000 &  2.1000000\\\\\n",
       "\t2677 &  0 &  3.500000 & 10.00000 &  0.0000000 &  0 &  3.0000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 73.65000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  2.500000 &  1.6000000\\\\\n",
       "\t4794 &  0 & 11.970000 & 14.27000 &  0.9900000 &  0 &  4.7900000 &  0.0900000 &  1.09000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 38.02000 &  0.00 &  0.0000000 &  0.290000 &  0.19 &  1.890000 &  8.6700000\\\\\n",
       "\t2508 &  0 &  5.000000 &  0.00000 &  0.0000000 & 45 & 20.0000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 30.00000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  0.0000000\\\\\n",
       "\t4084 &  0 &  2.550000 &  0.00000 &  0.0000000 &  0 &  7.4500000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 71.21000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  1.1500000\\\\\n",
       "\t117 &  0 &  0.000000 &  0.00000 &  0.0000000 &  0 &  0.0000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 63.28000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  0.0100000\\\\\n",
       "\t6814 &  0 &  7.790000 &  0.00000 &  0.0000000 &  0 &  2.5700000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 62.48000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  3.760000 &  0.0300000\\\\\n",
       "\t2074 &  0 &  0.000000 &  0.00000 &  0.0000000 &  0 & 14.0000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 74.00000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  0.0000000\\\\\n",
       "\t1837 &  0 & 14.970000 &  0.00000 &  3.9900000 &  0 & 16.4600000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 61.87000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  2.490000 &  0.2200000\\\\\n",
       "\t4131 &  0 &  8.620000 &  8.32000 &  0.0000000 &  0 &  2.7000000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 71.91000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  0.0300000\\\\\n",
       "\t5757 &  0 & 17.130000 &  4.93000 & 10.9500000 &  0 &  4.4600000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 59.05000 &  0.00 &  0.0000000 &  1.000000 &  0.00 &  0.000000 &  0.7500000\\\\\n",
       "\t5538 &  0 & 16.470000 & 10.10000 &  0.4500000 &  0 &  7.9700000 &  0.0000000 &  0.00000000 &  0.0 &  0 & ... &  0 &  0.0000000 &  0 & 59.79000 &  0.22 &  0.0000000 &  4.960000 &  0.00 &  0.000000 &  0.0400000\\\\\n",
       "\t1482 &  0 &  5.530000 &  0.00000 &  0.0000000 &  0 & 30.2800000 &  0.0000000 &  0.00000000 &  0.4 &  0 & ... &  0 &  0.0000000 &  0 & 34.20000 &  0.00 &  0.0000000 &  0.000000 &  0.00 &  0.000000 &  9.3900000\\\\\n",
       "\t291 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.0032399\\\\\n",
       "\t292 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.0459753\\\\\n",
       "\t293 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.1187486\\\\\n",
       "\t294 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.1664930\\\\\n",
       "\t295 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.3513410\\\\\n",
       "\t296 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  0.9975013\\\\\n",
       "\t297 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.0603035\\\\\n",
       "\t298 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  0.9903548\\\\\n",
       "\t299 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.0113684\\\\\n",
       "\t300.1 & 38 & 38.000000 & 38.00000 & 38.0000000 & 38 & 38.0000000 & 38.0000000 & 38.00000000 & 38.0 & 38 & ... & 38 & 38.0000000 & 38 & 38.00000 & 38.00 & 38.0000000 & 38.000000 & 38.00 & 38.000000 &  1.0167788\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 300 × 28\n",
       "\n",
       "| <!--/--> | X__3 &lt;dbl&gt; | X__4 &lt;dbl&gt; | X__8 &lt;dbl&gt; | X__10 &lt;dbl&gt; | X__17 &lt;dbl&gt; | X__18 &lt;dbl&gt; | X__29 &lt;dbl&gt; | X__30 &lt;dbl&gt; | X__43 &lt;dbl&gt; | X__48 &lt;dbl&gt; | ... ... | X__84 &lt;dbl&gt; | X__86 &lt;dbl&gt; | X__106 &lt;dbl&gt; | X__109 &lt;dbl&gt; | X__113 &lt;dbl&gt; | X__115 &lt;dbl&gt; | X__117 &lt;dbl&gt; | X__133 &lt;dbl&gt; | X__138 &lt;dbl&gt; | autres &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 4278 | 0 |  2.300000 |  0.000000 |  9.50 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.1000000 | 0 | 61.10000 | 0.0000000 | 0.0000000 |  8.70000 | 0.0000000 | 1.80000 |  1.30000 |\n",
       "| 1862 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 75.25000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.02000 |\n",
       "| 5016 | 0 |  9.600000 |  0.000000 |  3.00 |  0 |  7.9000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 62.11000 | 0.0000000 | 0.2000000 |  2.00000 | 0.0000000 | 1.50000 |  0.11000 |\n",
       "| 6393 | 0 | 23.600000 |  5.400000 |  0.00 |  0 |  4.3000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 55.70000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.01000 |\n",
       "| 3001 | 0 | 15.130000 |  0.000000 |  0.00 |  0 |  9.2700000 | 0.0000000 | 0.0000000 |  5.15 |  0.00 | ... | 0 | 0.1200000 | 0 | 51.97000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  5.39000 |\n",
       "| 2157 | 0 | 11.020000 |  0.000000 |  1.97 |  0 | 17.3100000 | 0.0000000 | 0.0000000 | 23.90 |  0.00 | ... | 0 | 0.0000000 | 0 | 45.21000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.59000 |\n",
       "| 1822 | 0 |  5.980000 |  6.280000 |  4.98 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 68.49000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  9.29000 |\n",
       "| 3993 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  1.6000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 69.00000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 4.00000 |  0.00000 |\n",
       "| 4839 | 0 |  2.500000 |  2.800000 |  0.60 |  0 |  6.4000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 61.16000 | 0.0000000 | 0.2000000 |  3.10000 | 0.0000000 | 0.60000 |  0.13000 |\n",
       "| 2837 | 0 |  0.000000 |  0.000000 |  0.00 |  0 | 31.4200000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 51.47000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.01000 |\n",
       "| 801 | 0 |  0.000000 |  0.000000 |  0.00 |  0 | 21.0500000 | 5.2500000 | 0.0000000 | 36.62 |  0.00 | ... | 0 | 0.0000000 | 0 | 37.07000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.01000 |\n",
       "| 385 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 | 32.12 | ... | 0 | 0.0000000 | 0 | 51.49000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.02000 |\n",
       "| 5132 | 0 | 16.500000 | 10.300000 |  0.50 |  0 |  8.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 59.62000 | 0.2200000 | 0.0000000 |  4.50000 | 0.0000000 | 0.04000 |  0.02000 |\n",
       "| 2330 | 0 |  3.340000 |  4.990000 | 40.04 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 36.27000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 | 14.77000 |\n",
       "| 609 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  2.1900000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 73.60000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  9.32000 |\n",
       "| 2502 | 0 |  5.000000 |  0.000000 |  0.00 | 25 | 50.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 20.00000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.00000 |\n",
       "| 800 | 0 |  0.000000 |  0.000000 |  0.00 |  0 | 20.1100000 | 7.7800000 | 0.0000000 | 34.54 |  0.00 | ... | 0 | 0.0000000 | 0 | 37.54000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.03000 |\n",
       "| 7236 | 0 |  8.500000 |  6.610000 |  3.86 |  0 |  0.0000000 | 0.0000000 | 0.1400000 |  0.00 |  0.00 | ... | 0 | 3.0500000 | 0 | 23.62000 | 0.0000000 | 0.0000000 |  1.80000 | 0.0000000 | 0.00000 | 30.40000 |\n",
       "| 1113 | 0 |  0.000000 |  2.410000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 57.58000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 | 26.83000 |\n",
       "| 654 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 28.76000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 | 71.24000 |\n",
       "| 3595 | 0 | 14.080000 |  0.000000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 7.6500000 | 0 | 58.38000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.03000 |\n",
       "| 6800 | 0 |  7.090000 |  0.000000 |  0.00 |  0 |  6.2900000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 60.53000 | 0.0000000 | 0.0000000 |  1.59000 | 0.0000000 | 4.09000 |  0.05000 |\n",
       "| 3194 | 0 |  0.000000 |  0.000000 |  0.00 |  0 | 11.0500000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 41.32000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 | 47.63000 |\n",
       "| 3088 | 0 |  0.390000 |  0.000000 |  0.00 |  0 | 24.8700000 | 0.0000000 | 0.0000000 | 34.05 |  0.00 | ... | 0 | 0.0000000 | 0 | 40.37000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.32000 |\n",
       "| 4609 | 0 |  6.800000 |  4.510000 |  0.00 |  0 |  4.7100000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 69.44000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.25000 |\n",
       "| 2302 | 0 |  0.800000 |  0.000000 |  0.00 |  0 |  9.8000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 72.50000 | 0.0000000 | 0.3000000 |  0.00000 | 0.0000000 | 0.00000 |  0.20000 |\n",
       "| 4033 | 0 |  2.350000 |  0.000000 |  8.85 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 62.42000 | 0.0000000 | 0.0000000 |  8.97000 | 0.0000000 | 1.77000 |  1.50000 |\n",
       "| 1918 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 46.49000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 | 46.79000 |\n",
       "| 1450 | 0 |  0.000000 |  0.000000 |  0.00 |  0 |  0.0000000 | 0.0000000 | 0.0000000 |  0.00 |  0.00 | ... | 0 | 0.0000000 | 0 | 61.86000 | 0.0000000 | 0.0000000 |  0.00000 | 0.0000000 | 0.00000 |  0.01000 |\n",
       "| 7093 | 0 |  3.000303 |  6.000606 |  0.00 |  0 |  0.3000063 | 0.6000606 | 0.2498892 |  0.00 |  0.00 | ... | 0 | 0.6400806 | 0 | 35.00353 | 0.2300512 | 0.3299693 | 10.00101 | 0.0800481 | 9.60097 | 19.52956 |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | <!----> | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "| 649 |  0 |  0.000000 |  0.00000 |  0.0000000 |  0 |  0.0000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 43.75000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 | 46.4600000 |\n",
       "| 4457 |  0 | 12.430000 |  8.49000 |  0.0000000 |  0 |  5.9800000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 57.72000 |  0.00 |  0.0000000 | 11.060000 |  0.00 |  0.000000 |  0.0200000 |\n",
       "| 3904 |  0 | 13.000000 |  0.00000 |  7.0000000 |  0 |  4.0000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 53.00000 |  0.00 |  0.0000000 |  4.000000 |  0.00 |  5.000000 |  0.0000000 |\n",
       "| 7008 |  0 |  6.893067 | 12.99792 |  0.1999686 |  0 |  0.4999214 |  0.1329791 |  0.00999843 |  0.0 |  0 | ... |  0 |  0.4999214 |  0 | 40.99356 |  0.00 |  0.0999843 |  3.499407 |  0.00 |  1.499801 | 17.4399857 |\n",
       "| 3541 |  0 |  8.360000 |  0.00000 |  0.0000000 |  0 |  7.3600000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 66.06000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  0.0300000 |\n",
       "| 2357 |  0 |  7.210000 |  0.00000 |  0.0000000 |  0 |  8.2100000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 65.13000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  2.5300000 |\n",
       "| 324 |  0 |  0.380000 |  0.00000 |  0.0000000 |  0 |  4.5000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 73.94000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  0.2100000 |\n",
       "| 3210 |  0 |  4.300000 |  0.00000 |  5.7000000 |  0 |  4.8000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 58.50000 |  0.00 |  0.2000000 |  9.700000 |  0.00 |  2.700000 |  2.1000000 |\n",
       "| 2677 |  0 |  3.500000 | 10.00000 |  0.0000000 |  0 |  3.0000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 73.65000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  2.500000 |  1.6000000 |\n",
       "| 4794 |  0 | 11.970000 | 14.27000 |  0.9900000 |  0 |  4.7900000 |  0.0900000 |  1.09000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 38.02000 |  0.00 |  0.0000000 |  0.290000 |  0.19 |  1.890000 |  8.6700000 |\n",
       "| 2508 |  0 |  5.000000 |  0.00000 |  0.0000000 | 45 | 20.0000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 30.00000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  0.0000000 |\n",
       "| 4084 |  0 |  2.550000 |  0.00000 |  0.0000000 |  0 |  7.4500000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 71.21000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  1.1500000 |\n",
       "| 117 |  0 |  0.000000 |  0.00000 |  0.0000000 |  0 |  0.0000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 63.28000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  0.0100000 |\n",
       "| 6814 |  0 |  7.790000 |  0.00000 |  0.0000000 |  0 |  2.5700000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 62.48000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  3.760000 |  0.0300000 |\n",
       "| 2074 |  0 |  0.000000 |  0.00000 |  0.0000000 |  0 | 14.0000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 74.00000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  0.0000000 |\n",
       "| 1837 |  0 | 14.970000 |  0.00000 |  3.9900000 |  0 | 16.4600000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 61.87000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  2.490000 |  0.2200000 |\n",
       "| 4131 |  0 |  8.620000 |  8.32000 |  0.0000000 |  0 |  2.7000000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 71.91000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  0.0300000 |\n",
       "| 5757 |  0 | 17.130000 |  4.93000 | 10.9500000 |  0 |  4.4600000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 59.05000 |  0.00 |  0.0000000 |  1.000000 |  0.00 |  0.000000 |  0.7500000 |\n",
       "| 5538 |  0 | 16.470000 | 10.10000 |  0.4500000 |  0 |  7.9700000 |  0.0000000 |  0.00000000 |  0.0 |  0 | ... |  0 |  0.0000000 |  0 | 59.79000 |  0.22 |  0.0000000 |  4.960000 |  0.00 |  0.000000 |  0.0400000 |\n",
       "| 1482 |  0 |  5.530000 |  0.00000 |  0.0000000 |  0 | 30.2800000 |  0.0000000 |  0.00000000 |  0.4 |  0 | ... |  0 |  0.0000000 |  0 | 34.20000 |  0.00 |  0.0000000 |  0.000000 |  0.00 |  0.000000 |  9.3900000 |\n",
       "| 291 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.0032399 |\n",
       "| 292 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.0459753 |\n",
       "| 293 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.1187486 |\n",
       "| 294 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.1664930 |\n",
       "| 295 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.3513410 |\n",
       "| 296 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  0.9975013 |\n",
       "| 297 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.0603035 |\n",
       "| 298 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  0.9903548 |\n",
       "| 299 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.0113684 |\n",
       "| 300.1 | 38 | 38.000000 | 38.00000 | 38.0000000 | 38 | 38.0000000 | 38.0000000 | 38.00000000 | 38.0 | 38 | ... | 38 | 38.0000000 | 38 | 38.00000 | 38.00 | 38.0000000 | 38.000000 | 38.00 | 38.000000 |  1.0167788 |\n",
       "\n"
      ],
      "text/plain": [
       "      X__3 X__4      X__8      X__10      X__17 X__18      X__29     \n",
       "4278  0     2.300000  0.000000  9.50       0     0.0000000 0.0000000 \n",
       "1862  0     0.000000  0.000000  0.00       0     0.0000000 0.0000000 \n",
       "5016  0     9.600000  0.000000  3.00       0     7.9000000 0.0000000 \n",
       "6393  0    23.600000  5.400000  0.00       0     4.3000000 0.0000000 \n",
       "3001  0    15.130000  0.000000  0.00       0     9.2700000 0.0000000 \n",
       "2157  0    11.020000  0.000000  1.97       0    17.3100000 0.0000000 \n",
       "1822  0     5.980000  6.280000  4.98       0     0.0000000 0.0000000 \n",
       "3993  0     0.000000  0.000000  0.00       0     1.6000000 0.0000000 \n",
       "4839  0     2.500000  2.800000  0.60       0     6.4000000 0.0000000 \n",
       "2837  0     0.000000  0.000000  0.00       0    31.4200000 0.0000000 \n",
       "801   0     0.000000  0.000000  0.00       0    21.0500000 5.2500000 \n",
       "385   0     0.000000  0.000000  0.00       0     0.0000000 0.0000000 \n",
       "5132  0    16.500000 10.300000  0.50       0     8.0000000 0.0000000 \n",
       "2330  0     3.340000  4.990000 40.04       0     0.0000000 0.0000000 \n",
       "609   0     0.000000  0.000000  0.00       0     2.1900000 0.0000000 \n",
       "2502  0     5.000000  0.000000  0.00      25    50.0000000 0.0000000 \n",
       "800   0     0.000000  0.000000  0.00       0    20.1100000 7.7800000 \n",
       "7236  0     8.500000  6.610000  3.86       0     0.0000000 0.0000000 \n",
       "1113  0     0.000000  2.410000  0.00       0     0.0000000 0.0000000 \n",
       "654   0     0.000000  0.000000  0.00       0     0.0000000 0.0000000 \n",
       "3595  0    14.080000  0.000000  0.00       0     0.0000000 0.0000000 \n",
       "6800  0     7.090000  0.000000  0.00       0     6.2900000 0.0000000 \n",
       "3194  0     0.000000  0.000000  0.00       0    11.0500000 0.0000000 \n",
       "3088  0     0.390000  0.000000  0.00       0    24.8700000 0.0000000 \n",
       "4609  0     6.800000  4.510000  0.00       0     4.7100000 0.0000000 \n",
       "2302  0     0.800000  0.000000  0.00       0     9.8000000 0.0000000 \n",
       "4033  0     2.350000  0.000000  8.85       0     0.0000000 0.0000000 \n",
       "1918  0     0.000000  0.000000  0.00       0     0.0000000 0.0000000 \n",
       "1450  0     0.000000  0.000000  0.00       0     0.0000000 0.0000000 \n",
       "7093  0     3.000303  6.000606  0.00       0     0.3000063 0.6000606 \n",
       "...   ...  ...       ...       ...        ...   ...        ...       \n",
       "649    0    0.000000  0.00000   0.0000000  0     0.0000000  0.0000000\n",
       "4457   0   12.430000  8.49000   0.0000000  0     5.9800000  0.0000000\n",
       "3904   0   13.000000  0.00000   7.0000000  0     4.0000000  0.0000000\n",
       "7008   0    6.893067 12.99792   0.1999686  0     0.4999214  0.1329791\n",
       "3541   0    8.360000  0.00000   0.0000000  0     7.3600000  0.0000000\n",
       "2357   0    7.210000  0.00000   0.0000000  0     8.2100000  0.0000000\n",
       "324    0    0.380000  0.00000   0.0000000  0     4.5000000  0.0000000\n",
       "3210   0    4.300000  0.00000   5.7000000  0     4.8000000  0.0000000\n",
       "2677   0    3.500000 10.00000   0.0000000  0     3.0000000  0.0000000\n",
       "4794   0   11.970000 14.27000   0.9900000  0     4.7900000  0.0900000\n",
       "2508   0    5.000000  0.00000   0.0000000 45    20.0000000  0.0000000\n",
       "4084   0    2.550000  0.00000   0.0000000  0     7.4500000  0.0000000\n",
       "117    0    0.000000  0.00000   0.0000000  0     0.0000000  0.0000000\n",
       "6814   0    7.790000  0.00000   0.0000000  0     2.5700000  0.0000000\n",
       "2074   0    0.000000  0.00000   0.0000000  0    14.0000000  0.0000000\n",
       "1837   0   14.970000  0.00000   3.9900000  0    16.4600000  0.0000000\n",
       "4131   0    8.620000  8.32000   0.0000000  0     2.7000000  0.0000000\n",
       "5757   0   17.130000  4.93000  10.9500000  0     4.4600000  0.0000000\n",
       "5538   0   16.470000 10.10000   0.4500000  0     7.9700000  0.0000000\n",
       "1482   0    5.530000  0.00000   0.0000000  0    30.2800000  0.0000000\n",
       "291   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "292   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "293   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "294   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "295   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "296   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "297   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "298   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "299   38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "300.1 38   38.000000 38.00000  38.0000000 38    38.0000000 38.0000000\n",
       "      X__30       X__43 X__48 ... X__84 X__86      X__106 X__109   X__113   \n",
       "4278  0.0000000    0.00  0.00 ... 0     0.1000000  0      61.10000 0.0000000\n",
       "1862  0.0000000    0.00  0.00 ... 0     0.0000000  0      75.25000 0.0000000\n",
       "5016  0.0000000    0.00  0.00 ... 0     0.0000000  0      62.11000 0.0000000\n",
       "6393  0.0000000    0.00  0.00 ... 0     0.0000000  0      55.70000 0.0000000\n",
       "3001  0.0000000    5.15  0.00 ... 0     0.1200000  0      51.97000 0.0000000\n",
       "2157  0.0000000   23.90  0.00 ... 0     0.0000000  0      45.21000 0.0000000\n",
       "1822  0.0000000    0.00  0.00 ... 0     0.0000000  0      68.49000 0.0000000\n",
       "3993  0.0000000    0.00  0.00 ... 0     0.0000000  0      69.00000 0.0000000\n",
       "4839  0.0000000    0.00  0.00 ... 0     0.0000000  0      61.16000 0.0000000\n",
       "2837  0.0000000    0.00  0.00 ... 0     0.0000000  0      51.47000 0.0000000\n",
       "801   0.0000000   36.62  0.00 ... 0     0.0000000  0      37.07000 0.0000000\n",
       "385   0.0000000    0.00 32.12 ... 0     0.0000000  0      51.49000 0.0000000\n",
       "5132  0.0000000    0.00  0.00 ... 0     0.0000000  0      59.62000 0.2200000\n",
       "2330  0.0000000    0.00  0.00 ... 0     0.0000000  0      36.27000 0.0000000\n",
       "609   0.0000000    0.00  0.00 ... 0     0.0000000  0      73.60000 0.0000000\n",
       "2502  0.0000000    0.00  0.00 ... 0     0.0000000  0      20.00000 0.0000000\n",
       "800   0.0000000   34.54  0.00 ... 0     0.0000000  0      37.54000 0.0000000\n",
       "7236  0.1400000    0.00  0.00 ... 0     3.0500000  0      23.62000 0.0000000\n",
       "1113  0.0000000    0.00  0.00 ... 0     0.0000000  0      57.58000 0.0000000\n",
       "654   0.0000000    0.00  0.00 ... 0     0.0000000  0      28.76000 0.0000000\n",
       "3595  0.0000000    0.00  0.00 ... 0     7.6500000  0      58.38000 0.0000000\n",
       "6800  0.0000000    0.00  0.00 ... 0     0.0000000  0      60.53000 0.0000000\n",
       "3194  0.0000000    0.00  0.00 ... 0     0.0000000  0      41.32000 0.0000000\n",
       "3088  0.0000000   34.05  0.00 ... 0     0.0000000  0      40.37000 0.0000000\n",
       "4609  0.0000000    0.00  0.00 ... 0     0.0000000  0      69.44000 0.0000000\n",
       "2302  0.0000000    0.00  0.00 ... 0     0.0000000  0      72.50000 0.0000000\n",
       "4033  0.0000000    0.00  0.00 ... 0     0.0000000  0      62.42000 0.0000000\n",
       "1918  0.0000000    0.00  0.00 ... 0     0.0000000  0      46.49000 0.0000000\n",
       "1450  0.0000000    0.00  0.00 ... 0     0.0000000  0      61.86000 0.0000000\n",
       "7093  0.2498892    0.00  0.00 ... 0     0.6400806  0      35.00353 0.2300512\n",
       "...   ...         ...   ...       ...   ...        ...    ...      ...      \n",
       "649    0.00000000  0.0   0    ...  0     0.0000000  0     43.75000  0.00    \n",
       "4457   0.00000000  0.0   0    ...  0     0.0000000  0     57.72000  0.00    \n",
       "3904   0.00000000  0.0   0    ...  0     0.0000000  0     53.00000  0.00    \n",
       "7008   0.00999843  0.0   0    ...  0     0.4999214  0     40.99356  0.00    \n",
       "3541   0.00000000  0.0   0    ...  0     0.0000000  0     66.06000  0.00    \n",
       "2357   0.00000000  0.0   0    ...  0     0.0000000  0     65.13000  0.00    \n",
       "324    0.00000000  0.0   0    ...  0     0.0000000  0     73.94000  0.00    \n",
       "3210   0.00000000  0.0   0    ...  0     0.0000000  0     58.50000  0.00    \n",
       "2677   0.00000000  0.0   0    ...  0     0.0000000  0     73.65000  0.00    \n",
       "4794   1.09000000  0.0   0    ...  0     0.0000000  0     38.02000  0.00    \n",
       "2508   0.00000000  0.0   0    ...  0     0.0000000  0     30.00000  0.00    \n",
       "4084   0.00000000  0.0   0    ...  0     0.0000000  0     71.21000  0.00    \n",
       "117    0.00000000  0.0   0    ...  0     0.0000000  0     63.28000  0.00    \n",
       "6814   0.00000000  0.0   0    ...  0     0.0000000  0     62.48000  0.00    \n",
       "2074   0.00000000  0.0   0    ...  0     0.0000000  0     74.00000  0.00    \n",
       "1837   0.00000000  0.0   0    ...  0     0.0000000  0     61.87000  0.00    \n",
       "4131   0.00000000  0.0   0    ...  0     0.0000000  0     71.91000  0.00    \n",
       "5757   0.00000000  0.0   0    ...  0     0.0000000  0     59.05000  0.00    \n",
       "5538   0.00000000  0.0   0    ...  0     0.0000000  0     59.79000  0.22    \n",
       "1482   0.00000000  0.4   0    ...  0     0.0000000  0     34.20000  0.00    \n",
       "291   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "292   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "293   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "294   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "295   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "296   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "297   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "298   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "299   38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "300.1 38.00000000 38.0  38    ... 38    38.0000000 38     38.00000 38.00    \n",
       "      X__115     X__117    X__133    X__138    autres    \n",
       "4278  0.0000000   8.70000  0.0000000 1.80000    1.30000  \n",
       "1862  0.0000000   0.00000  0.0000000 0.00000    0.02000  \n",
       "5016  0.2000000   2.00000  0.0000000 1.50000    0.11000  \n",
       "6393  0.0000000   0.00000  0.0000000 0.00000    0.01000  \n",
       "3001  0.0000000   0.00000  0.0000000 0.00000    5.39000  \n",
       "2157  0.0000000   0.00000  0.0000000 0.00000    0.59000  \n",
       "1822  0.0000000   0.00000  0.0000000 0.00000    9.29000  \n",
       "3993  0.0000000   0.00000  0.0000000 4.00000    0.00000  \n",
       "4839  0.2000000   3.10000  0.0000000 0.60000    0.13000  \n",
       "2837  0.0000000   0.00000  0.0000000 0.00000    0.01000  \n",
       "801   0.0000000   0.00000  0.0000000 0.00000    0.01000  \n",
       "385   0.0000000   0.00000  0.0000000 0.00000    0.02000  \n",
       "5132  0.0000000   4.50000  0.0000000 0.04000    0.02000  \n",
       "2330  0.0000000   0.00000  0.0000000 0.00000   14.77000  \n",
       "609   0.0000000   0.00000  0.0000000 0.00000    9.32000  \n",
       "2502  0.0000000   0.00000  0.0000000 0.00000    0.00000  \n",
       "800   0.0000000   0.00000  0.0000000 0.00000    0.03000  \n",
       "7236  0.0000000   1.80000  0.0000000 0.00000   30.40000  \n",
       "1113  0.0000000   0.00000  0.0000000 0.00000   26.83000  \n",
       "654   0.0000000   0.00000  0.0000000 0.00000   71.24000  \n",
       "3595  0.0000000   0.00000  0.0000000 0.00000    0.03000  \n",
       "6800  0.0000000   1.59000  0.0000000 4.09000    0.05000  \n",
       "3194  0.0000000   0.00000  0.0000000 0.00000   47.63000  \n",
       "3088  0.0000000   0.00000  0.0000000 0.00000    0.32000  \n",
       "4609  0.0000000   0.00000  0.0000000 0.00000    0.25000  \n",
       "2302  0.3000000   0.00000  0.0000000 0.00000    0.20000  \n",
       "4033  0.0000000   8.97000  0.0000000 1.77000    1.50000  \n",
       "1918  0.0000000   0.00000  0.0000000 0.00000   46.79000  \n",
       "1450  0.0000000   0.00000  0.0000000 0.00000    0.01000  \n",
       "7093  0.3299693  10.00101  0.0800481 9.60097   19.52956  \n",
       "...   ...        ...       ...       ...       ...       \n",
       "649    0.0000000  0.000000  0.00      0.000000 46.4600000\n",
       "4457   0.0000000 11.060000  0.00      0.000000  0.0200000\n",
       "3904   0.0000000  4.000000  0.00      5.000000  0.0000000\n",
       "7008   0.0999843  3.499407  0.00      1.499801 17.4399857\n",
       "3541   0.0000000  0.000000  0.00      0.000000  0.0300000\n",
       "2357   0.0000000  0.000000  0.00      0.000000  2.5300000\n",
       "324    0.0000000  0.000000  0.00      0.000000  0.2100000\n",
       "3210   0.2000000  9.700000  0.00      2.700000  2.1000000\n",
       "2677   0.0000000  0.000000  0.00      2.500000  1.6000000\n",
       "4794   0.0000000  0.290000  0.19      1.890000  8.6700000\n",
       "2508   0.0000000  0.000000  0.00      0.000000  0.0000000\n",
       "4084   0.0000000  0.000000  0.00      0.000000  1.1500000\n",
       "117    0.0000000  0.000000  0.00      0.000000  0.0100000\n",
       "6814   0.0000000  0.000000  0.00      3.760000  0.0300000\n",
       "2074   0.0000000  0.000000  0.00      0.000000  0.0000000\n",
       "1837   0.0000000  0.000000  0.00      2.490000  0.2200000\n",
       "4131   0.0000000  0.000000  0.00      0.000000  0.0300000\n",
       "5757   0.0000000  1.000000  0.00      0.000000  0.7500000\n",
       "5538   0.0000000  4.960000  0.00      0.000000  0.0400000\n",
       "1482   0.0000000  0.000000  0.00      0.000000  9.3900000\n",
       "291   38.0000000 38.000000 38.00     38.000000  1.0032399\n",
       "292   38.0000000 38.000000 38.00     38.000000  1.0459753\n",
       "293   38.0000000 38.000000 38.00     38.000000  1.1187486\n",
       "294   38.0000000 38.000000 38.00     38.000000  1.1664930\n",
       "295   38.0000000 38.000000 38.00     38.000000  1.3513410\n",
       "296   38.0000000 38.000000 38.00     38.000000  0.9975013\n",
       "297   38.0000000 38.000000 38.00     38.000000  1.0603035\n",
       "298   38.0000000 38.000000 38.00     38.000000  0.9903548\n",
       "299   38.0000000 38.000000 38.00     38.000000  1.0113684\n",
       "300.1 38.0000000 38.000000 38.00     38.000000  1.0167788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb468c1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1027.01677881005"
      ],
      "text/latex": [
       "1027.01677881005"
      ],
      "text/markdown": [
       "1027.01677881005"
      ],
      "text/plain": [
       "[1] 1027.017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(X[300,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f8db9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a109eb8",
   "metadata": {},
   "source": [
    "### Tester la fonction jouet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac35069d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fjouet<-function(x1, x2){\n",
    "    return((x1-50)**2+(x2-50)**2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc176f36",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 100 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>resp</th><th scope=col>x</th><th scope=col>y</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1868.177874</td><td>80.56287</td><td>19.437131</td></tr>\n",
       "\t<tr><td> 390.943609</td><td>63.98112</td><td>36.018877</td></tr>\n",
       "\t<tr><td> 188.328631</td><td>59.70383</td><td>40.296170</td></tr>\n",
       "\t<tr><td>4139.973329</td><td>95.49711</td><td> 4.502894</td></tr>\n",
       "\t<tr><td> 145.912158</td><td>58.54143</td><td>41.458567</td></tr>\n",
       "\t<tr><td>1276.091801</td><td>75.25957</td><td>24.740430</td></tr>\n",
       "\t<tr><td> 496.443593</td><td>34.24494</td><td>65.755056</td></tr>\n",
       "\t<tr><td>3695.500355</td><td>92.98546</td><td> 7.014535</td></tr>\n",
       "\t<tr><td>2021.265020</td><td>18.20955</td><td>81.790447</td></tr>\n",
       "\t<tr><td> 129.009901</td><td>41.96850</td><td>58.031497</td></tr>\n",
       "\t<tr><td> 917.333298</td><td>28.58350</td><td>71.416504</td></tr>\n",
       "\t<tr><td> 770.221604</td><td>30.37576</td><td>69.624240</td></tr>\n",
       "\t<tr><td>   1.306652</td><td>49.19171</td><td>50.808286</td></tr>\n",
       "\t<tr><td>1956.067693</td><td>81.27353</td><td>18.726467</td></tr>\n",
       "\t<tr><td> 319.702130</td><td>37.35678</td><td>62.643222</td></tr>\n",
       "\t<tr><td> 688.060004</td><td>68.54805</td><td>31.451954</td></tr>\n",
       "\t<tr><td>1590.116459</td><td>21.80322</td><td>78.196777</td></tr>\n",
       "\t<tr><td> 651.846155</td><td>68.05334</td><td>31.946660</td></tr>\n",
       "\t<tr><td>1332.630116</td><td>75.81308</td><td>24.186921</td></tr>\n",
       "\t<tr><td>2835.168579</td><td>12.34918</td><td>87.650821</td></tr>\n",
       "\t<tr><td> 693.153822</td><td>68.61658</td><td>31.383424</td></tr>\n",
       "\t<tr><td> 417.138544</td><td>64.44193</td><td>35.558072</td></tr>\n",
       "\t<tr><td> 695.900401</td><td>31.34658</td><td>68.653423</td></tr>\n",
       "\t<tr><td>2138.333761</td><td>82.69812</td><td>17.301883</td></tr>\n",
       "\t<tr><td>1112.470062</td><td>73.58464</td><td>26.415365</td></tr>\n",
       "\t<tr><td>  83.304107</td><td>43.54616</td><td>56.453840</td></tr>\n",
       "\t<tr><td>2835.800472</td><td>12.34498</td><td>87.655016</td></tr>\n",
       "\t<tr><td>2678.385368</td><td>86.59498</td><td>13.405018</td></tr>\n",
       "\t<tr><td>3055.588762</td><td>89.08701</td><td>10.912990</td></tr>\n",
       "\t<tr><td>  38.467708</td><td>54.38564</td><td>45.614358</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>  19.2432666</td><td>53.101876</td><td>46.898124</td></tr>\n",
       "\t<tr><td>1028.3538800</td><td>72.675470</td><td>27.324530</td></tr>\n",
       "\t<tr><td> 920.7120708</td><td>71.455909</td><td>28.544091</td></tr>\n",
       "\t<tr><td> 199.0232903</td><td>59.975552</td><td>40.024448</td></tr>\n",
       "\t<tr><td>3597.1123375</td><td> 7.590612</td><td>92.409388</td></tr>\n",
       "\t<tr><td>   0.9333910</td><td>50.683151</td><td>49.316849</td></tr>\n",
       "\t<tr><td>1718.1930436</td><td>79.310348</td><td>20.689652</td></tr>\n",
       "\t<tr><td>3089.6430281</td><td>89.304218</td><td>10.695782</td></tr>\n",
       "\t<tr><td> 299.3283956</td><td>37.766268</td><td>62.233732</td></tr>\n",
       "\t<tr><td>1209.5271715</td><td>74.591941</td><td>25.408059</td></tr>\n",
       "\t<tr><td>1575.4438976</td><td>78.066385</td><td>21.933615</td></tr>\n",
       "\t<tr><td> 204.9249892</td><td>60.122376</td><td>39.877624</td></tr>\n",
       "\t<tr><td>  34.5477891</td><td>45.843812</td><td>54.156188</td></tr>\n",
       "\t<tr><td> 178.6568227</td><td>59.451371</td><td>40.548629</td></tr>\n",
       "\t<tr><td>4615.7150868</td><td> 1.959834</td><td>98.040166</td></tr>\n",
       "\t<tr><td>1536.4523802</td><td>22.283106</td><td>77.716894</td></tr>\n",
       "\t<tr><td>  13.4794093</td><td>47.403906</td><td>52.596094</td></tr>\n",
       "\t<tr><td>2605.0997231</td><td>13.909144</td><td>86.090856</td></tr>\n",
       "\t<tr><td> 107.0929054</td><td>42.682456</td><td>57.317544</td></tr>\n",
       "\t<tr><td>1980.6209557</td><td>81.469199</td><td>18.530801</td></tr>\n",
       "\t<tr><td>3769.6931079</td><td> 6.585180</td><td>93.414820</td></tr>\n",
       "\t<tr><td> 110.8576557</td><td>57.445054</td><td>42.554946</td></tr>\n",
       "\t<tr><td> 139.4639729</td><td>41.649432</td><td>58.350568</td></tr>\n",
       "\t<tr><td>4372.3431025</td><td> 3.243487</td><td>96.756513</td></tr>\n",
       "\t<tr><td>4231.9038222</td><td> 4.000523</td><td>95.999477</td></tr>\n",
       "\t<tr><td>3369.7063933</td><td>91.046963</td><td> 8.953037</td></tr>\n",
       "\t<tr><td>2742.4263992</td><td>87.029896</td><td>12.970104</td></tr>\n",
       "\t<tr><td>1203.7200959</td><td>25.467164</td><td>74.532836</td></tr>\n",
       "\t<tr><td> 743.1834501</td><td>69.276715</td><td>30.723285</td></tr>\n",
       "\t<tr><td>   0.4662798</td><td>49.517154</td><td>50.482846</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 100 × 3\n",
       "\\begin{tabular}{lll}\n",
       " resp & x & y\\\\\n",
       " <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1868.177874 & 80.56287 & 19.437131\\\\\n",
       "\t  390.943609 & 63.98112 & 36.018877\\\\\n",
       "\t  188.328631 & 59.70383 & 40.296170\\\\\n",
       "\t 4139.973329 & 95.49711 &  4.502894\\\\\n",
       "\t  145.912158 & 58.54143 & 41.458567\\\\\n",
       "\t 1276.091801 & 75.25957 & 24.740430\\\\\n",
       "\t  496.443593 & 34.24494 & 65.755056\\\\\n",
       "\t 3695.500355 & 92.98546 &  7.014535\\\\\n",
       "\t 2021.265020 & 18.20955 & 81.790447\\\\\n",
       "\t  129.009901 & 41.96850 & 58.031497\\\\\n",
       "\t  917.333298 & 28.58350 & 71.416504\\\\\n",
       "\t  770.221604 & 30.37576 & 69.624240\\\\\n",
       "\t    1.306652 & 49.19171 & 50.808286\\\\\n",
       "\t 1956.067693 & 81.27353 & 18.726467\\\\\n",
       "\t  319.702130 & 37.35678 & 62.643222\\\\\n",
       "\t  688.060004 & 68.54805 & 31.451954\\\\\n",
       "\t 1590.116459 & 21.80322 & 78.196777\\\\\n",
       "\t  651.846155 & 68.05334 & 31.946660\\\\\n",
       "\t 1332.630116 & 75.81308 & 24.186921\\\\\n",
       "\t 2835.168579 & 12.34918 & 87.650821\\\\\n",
       "\t  693.153822 & 68.61658 & 31.383424\\\\\n",
       "\t  417.138544 & 64.44193 & 35.558072\\\\\n",
       "\t  695.900401 & 31.34658 & 68.653423\\\\\n",
       "\t 2138.333761 & 82.69812 & 17.301883\\\\\n",
       "\t 1112.470062 & 73.58464 & 26.415365\\\\\n",
       "\t   83.304107 & 43.54616 & 56.453840\\\\\n",
       "\t 2835.800472 & 12.34498 & 87.655016\\\\\n",
       "\t 2678.385368 & 86.59498 & 13.405018\\\\\n",
       "\t 3055.588762 & 89.08701 & 10.912990\\\\\n",
       "\t   38.467708 & 54.38564 & 45.614358\\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t   19.2432666 & 53.101876 & 46.898124\\\\\n",
       "\t 1028.3538800 & 72.675470 & 27.324530\\\\\n",
       "\t  920.7120708 & 71.455909 & 28.544091\\\\\n",
       "\t  199.0232903 & 59.975552 & 40.024448\\\\\n",
       "\t 3597.1123375 &  7.590612 & 92.409388\\\\\n",
       "\t    0.9333910 & 50.683151 & 49.316849\\\\\n",
       "\t 1718.1930436 & 79.310348 & 20.689652\\\\\n",
       "\t 3089.6430281 & 89.304218 & 10.695782\\\\\n",
       "\t  299.3283956 & 37.766268 & 62.233732\\\\\n",
       "\t 1209.5271715 & 74.591941 & 25.408059\\\\\n",
       "\t 1575.4438976 & 78.066385 & 21.933615\\\\\n",
       "\t  204.9249892 & 60.122376 & 39.877624\\\\\n",
       "\t   34.5477891 & 45.843812 & 54.156188\\\\\n",
       "\t  178.6568227 & 59.451371 & 40.548629\\\\\n",
       "\t 4615.7150868 &  1.959834 & 98.040166\\\\\n",
       "\t 1536.4523802 & 22.283106 & 77.716894\\\\\n",
       "\t   13.4794093 & 47.403906 & 52.596094\\\\\n",
       "\t 2605.0997231 & 13.909144 & 86.090856\\\\\n",
       "\t  107.0929054 & 42.682456 & 57.317544\\\\\n",
       "\t 1980.6209557 & 81.469199 & 18.530801\\\\\n",
       "\t 3769.6931079 &  6.585180 & 93.414820\\\\\n",
       "\t  110.8576557 & 57.445054 & 42.554946\\\\\n",
       "\t  139.4639729 & 41.649432 & 58.350568\\\\\n",
       "\t 4372.3431025 &  3.243487 & 96.756513\\\\\n",
       "\t 4231.9038222 &  4.000523 & 95.999477\\\\\n",
       "\t 3369.7063933 & 91.046963 &  8.953037\\\\\n",
       "\t 2742.4263992 & 87.029896 & 12.970104\\\\\n",
       "\t 1203.7200959 & 25.467164 & 74.532836\\\\\n",
       "\t  743.1834501 & 69.276715 & 30.723285\\\\\n",
       "\t    0.4662798 & 49.517154 & 50.482846\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 100 × 3\n",
       "\n",
       "| resp &lt;dbl&gt; | x &lt;dbl&gt; | y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1868.177874 | 80.56287 | 19.437131 |\n",
       "|  390.943609 | 63.98112 | 36.018877 |\n",
       "|  188.328631 | 59.70383 | 40.296170 |\n",
       "| 4139.973329 | 95.49711 |  4.502894 |\n",
       "|  145.912158 | 58.54143 | 41.458567 |\n",
       "| 1276.091801 | 75.25957 | 24.740430 |\n",
       "|  496.443593 | 34.24494 | 65.755056 |\n",
       "| 3695.500355 | 92.98546 |  7.014535 |\n",
       "| 2021.265020 | 18.20955 | 81.790447 |\n",
       "|  129.009901 | 41.96850 | 58.031497 |\n",
       "|  917.333298 | 28.58350 | 71.416504 |\n",
       "|  770.221604 | 30.37576 | 69.624240 |\n",
       "|    1.306652 | 49.19171 | 50.808286 |\n",
       "| 1956.067693 | 81.27353 | 18.726467 |\n",
       "|  319.702130 | 37.35678 | 62.643222 |\n",
       "|  688.060004 | 68.54805 | 31.451954 |\n",
       "| 1590.116459 | 21.80322 | 78.196777 |\n",
       "|  651.846155 | 68.05334 | 31.946660 |\n",
       "| 1332.630116 | 75.81308 | 24.186921 |\n",
       "| 2835.168579 | 12.34918 | 87.650821 |\n",
       "|  693.153822 | 68.61658 | 31.383424 |\n",
       "|  417.138544 | 64.44193 | 35.558072 |\n",
       "|  695.900401 | 31.34658 | 68.653423 |\n",
       "| 2138.333761 | 82.69812 | 17.301883 |\n",
       "| 1112.470062 | 73.58464 | 26.415365 |\n",
       "|   83.304107 | 43.54616 | 56.453840 |\n",
       "| 2835.800472 | 12.34498 | 87.655016 |\n",
       "| 2678.385368 | 86.59498 | 13.405018 |\n",
       "| 3055.588762 | 89.08701 | 10.912990 |\n",
       "|   38.467708 | 54.38564 | 45.614358 |\n",
       "| ... | ... | ... |\n",
       "|   19.2432666 | 53.101876 | 46.898124 |\n",
       "| 1028.3538800 | 72.675470 | 27.324530 |\n",
       "|  920.7120708 | 71.455909 | 28.544091 |\n",
       "|  199.0232903 | 59.975552 | 40.024448 |\n",
       "| 3597.1123375 |  7.590612 | 92.409388 |\n",
       "|    0.9333910 | 50.683151 | 49.316849 |\n",
       "| 1718.1930436 | 79.310348 | 20.689652 |\n",
       "| 3089.6430281 | 89.304218 | 10.695782 |\n",
       "|  299.3283956 | 37.766268 | 62.233732 |\n",
       "| 1209.5271715 | 74.591941 | 25.408059 |\n",
       "| 1575.4438976 | 78.066385 | 21.933615 |\n",
       "|  204.9249892 | 60.122376 | 39.877624 |\n",
       "|   34.5477891 | 45.843812 | 54.156188 |\n",
       "|  178.6568227 | 59.451371 | 40.548629 |\n",
       "| 4615.7150868 |  1.959834 | 98.040166 |\n",
       "| 1536.4523802 | 22.283106 | 77.716894 |\n",
       "|   13.4794093 | 47.403906 | 52.596094 |\n",
       "| 2605.0997231 | 13.909144 | 86.090856 |\n",
       "|  107.0929054 | 42.682456 | 57.317544 |\n",
       "| 1980.6209557 | 81.469199 | 18.530801 |\n",
       "| 3769.6931079 |  6.585180 | 93.414820 |\n",
       "|  110.8576557 | 57.445054 | 42.554946 |\n",
       "|  139.4639729 | 41.649432 | 58.350568 |\n",
       "| 4372.3431025 |  3.243487 | 96.756513 |\n",
       "| 4231.9038222 |  4.000523 | 95.999477 |\n",
       "| 3369.7063933 | 91.046963 |  8.953037 |\n",
       "| 2742.4263992 | 87.029896 | 12.970104 |\n",
       "| 1203.7200959 | 25.467164 | 74.532836 |\n",
       "|  743.1834501 | 69.276715 | 30.723285 |\n",
       "|    0.4662798 | 49.517154 | 50.482846 |\n",
       "\n"
      ],
      "text/plain": [
       "    resp         x         y        \n",
       "1   1868.177874  80.56287  19.437131\n",
       "2    390.943609  63.98112  36.018877\n",
       "3    188.328631  59.70383  40.296170\n",
       "4   4139.973329  95.49711   4.502894\n",
       "5    145.912158  58.54143  41.458567\n",
       "6   1276.091801  75.25957  24.740430\n",
       "7    496.443593  34.24494  65.755056\n",
       "8   3695.500355  92.98546   7.014535\n",
       "9   2021.265020  18.20955  81.790447\n",
       "10   129.009901  41.96850  58.031497\n",
       "11   917.333298  28.58350  71.416504\n",
       "12   770.221604  30.37576  69.624240\n",
       "13     1.306652  49.19171  50.808286\n",
       "14  1956.067693  81.27353  18.726467\n",
       "15   319.702130  37.35678  62.643222\n",
       "16   688.060004  68.54805  31.451954\n",
       "17  1590.116459  21.80322  78.196777\n",
       "18   651.846155  68.05334  31.946660\n",
       "19  1332.630116  75.81308  24.186921\n",
       "20  2835.168579  12.34918  87.650821\n",
       "21   693.153822  68.61658  31.383424\n",
       "22   417.138544  64.44193  35.558072\n",
       "23   695.900401  31.34658  68.653423\n",
       "24  2138.333761  82.69812  17.301883\n",
       "25  1112.470062  73.58464  26.415365\n",
       "26    83.304107  43.54616  56.453840\n",
       "27  2835.800472  12.34498  87.655016\n",
       "28  2678.385368  86.59498  13.405018\n",
       "29  3055.588762  89.08701  10.912990\n",
       "30    38.467708  54.38564  45.614358\n",
       "... ...          ...       ...      \n",
       "71    19.2432666 53.101876 46.898124\n",
       "72  1028.3538800 72.675470 27.324530\n",
       "73   920.7120708 71.455909 28.544091\n",
       "74   199.0232903 59.975552 40.024448\n",
       "75  3597.1123375  7.590612 92.409388\n",
       "76     0.9333910 50.683151 49.316849\n",
       "77  1718.1930436 79.310348 20.689652\n",
       "78  3089.6430281 89.304218 10.695782\n",
       "79   299.3283956 37.766268 62.233732\n",
       "80  1209.5271715 74.591941 25.408059\n",
       "81  1575.4438976 78.066385 21.933615\n",
       "82   204.9249892 60.122376 39.877624\n",
       "83    34.5477891 45.843812 54.156188\n",
       "84   178.6568227 59.451371 40.548629\n",
       "85  4615.7150868  1.959834 98.040166\n",
       "86  1536.4523802 22.283106 77.716894\n",
       "87    13.4794093 47.403906 52.596094\n",
       "88  2605.0997231 13.909144 86.090856\n",
       "89   107.0929054 42.682456 57.317544\n",
       "90  1980.6209557 81.469199 18.530801\n",
       "91  3769.6931079  6.585180 93.414820\n",
       "92   110.8576557 57.445054 42.554946\n",
       "93   139.4639729 41.649432 58.350568\n",
       "94  4372.3431025  3.243487 96.756513\n",
       "95  4231.9038222  4.000523 95.999477\n",
       "96  3369.7063933 91.046963  8.953037\n",
       "97  2742.4263992 87.029896 12.970104\n",
       "98  1203.7200959 25.467164 74.532836\n",
       "99   743.1834501 69.276715 30.723285\n",
       "100    0.4662798 49.517154 50.482846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = 2\n",
    "N = 10*d\n",
    "\n",
    "x <- runif(n=100, min=0, max=100)\n",
    "y <- 100-x\n",
    "\n",
    "\n",
    "donne <- cbind(x,y)\n",
    "resp<- fjouet(donne[,1], donne[,2])\n",
    "mat.donne<-as.data.frame(cbind(resp, donne))\n",
    "\n",
    "mat.donne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0cf584",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.5822 196.5428 \n",
      "  - best initial criterion value(s) :  -563.6667 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       563.67  |proj g|=       3.5484\n",
      "At iterate     1  f =       559.52  |proj g|=        1.6297\n",
      "At iterate     2  f =        559.1  |proj g|=       0.44837\n",
      "At iterate     3  f =       559.03  |proj g|=       0.44912\n",
      "At iterate     4  f =       558.61  |proj g|=        1.4077\n",
      "At iterate     5  f =       557.77  |proj g|=        3.0469\n",
      "At iterate     6  f =       556.79  |proj g|=        3.9813\n",
      "At iterate     7  f =       555.92  |proj g|=        1.6676\n",
      "At iterate     8  f =       555.62  |proj g|=       0.64384\n",
      "At iterate     9  f =       555.58  |proj g|=      0.068366\n",
      "At iterate    10  f =       555.57  |proj g|=      0.011422\n",
      "At iterate    11  f =       555.57  |proj g|=     0.0048564\n",
      "At iterate    12  f =       555.57  |proj g|=    0.00069113\n",
      "At iterate    13  f =       555.57  |proj g|=    4.2766e-07\n",
      "\n",
      "iterations 13\n",
      "function evaluations 16\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.27662e-07\n",
      "final function value 555.567\n",
      "\n",
      "F = 555.567\n",
      "final  value 555.567453 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "noise = matrix(runif(prod(dim(mat.donne[,c(-1)])),min = 0.1,max = 0.2), nrow = nrow(mat.donne))\n",
    "m0 = km(formula = ~1, design = as.data.frame(mat.donne[,-1]+noise), response = as.data.frame(mat.donne[,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e1707a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Normal QQ-plot of standardized residuals\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc36ae3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "new_tmse = function(x_new){\n",
    "    # d: dimension, d = 29\n",
    "    data = data_updated\n",
    "    d = 2\n",
    "    niter = 1000\n",
    "    s = 0\n",
    "    data_recherche = data_updated \n",
    "    \n",
    "    newpoint = pointProche(x_new, data_recherche)\n",
    "    \n",
    "    data_new = data.frame(data)\n",
    "    data_new[nrow(data_new) + 1, ] = newpoint\n",
    "    noise = matrix(runif(prod(dim(data_new[,c(-1)])),min = 0.1,max = 0.2), nrow = nrow(data_new))\n",
    "    mod = km(formula = ~1, design = data_new[,c(-1)]+noise , response = data_new[1],)\n",
    "    #mod = update(m0, newX = data_new[,c(-1)]+noise, newy = data_new[,1],newX.alreadyExist = FALSE, cov.reestim = FALSE, trend.reestim = FALSE)\n",
    "    for(i in 1:niter){\n",
    "        x = simul(d)\n",
    "        s = s + g_new(x, m0 = m0, model = mod, T =500)\n",
    "    }\n",
    "    tmse = s/niter\n",
    "    return(tmse)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260ce444",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "contraintes = function(x){\n",
    "  n = length(x)\n",
    "  h<-numeric(n+2)\n",
    "  h[1]<- 100 - sum(x) #somme = 1\n",
    "  h[2]<- sum(x) - 100\n",
    "  #h[3:n+2] = as.numeric(x)\n",
    "  for (i in range(3,n+2)){\n",
    "    h[i] = x[i-2]\n",
    "  }\n",
    "  return(h)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a9ae9c9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Starting...\"\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5214 179.5961 \n",
      "  - best initial criterion value(s) :  -128.3304 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       128.33  |proj g|=     0.070021\n",
      "At iterate     1  f =       128.33  |proj g|=      0.069804\n",
      "At iterate     2  f =       127.94  |proj g|=      0.018058\n",
      "At iterate     3  f =        127.9  |proj g|=       0.02308\n",
      "At iterate     4  f =       127.86  |proj g|=      0.011536\n",
      "At iterate     5  f =       127.84  |proj g|=     0.0017995\n",
      "At iterate     6  f =       127.84  |proj g|=    0.00029895\n",
      "At iterate     7  f =       127.84  |proj g|=    1.0379e-05\n",
      "At iterate     8  f =       127.84  |proj g|=    1.0198e-05\n",
      "\n",
      "iterations 8\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.01984e-05\n",
      "final function value 127.838\n",
      "\n",
      "F = 127.838\n",
      "final  value 127.837760 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.66 179.6552 \n",
      "  - best initial criterion value(s) :  -132.6864 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       132.69  |proj g|=      0.24237\n",
      "At iterate     1  f =       132.63  |proj g|=       0.22997\n",
      "At iterate     2  f =       132.33  |proj g|=       0.15641\n",
      "At iterate     3  f =       132.24  |proj g|=      0.042121\n",
      "At iterate     4  f =       132.23  |proj g|=     0.0068795\n",
      "At iterate     5  f =       132.23  |proj g|=     0.0068311\n",
      "At iterate     6  f =       132.23  |proj g|=     0.0080275\n",
      "At iterate     7  f =       132.22  |proj g|=      0.021123\n",
      "At iterate     8  f =       132.22  |proj g|=      0.034963\n",
      "At iterate     9  f =        132.2  |proj g|=      0.043191\n",
      "At iterate    10  f =       132.18  |proj g|=      0.028186\n",
      "At iterate    11  f =       132.17  |proj g|=     0.0051355\n",
      "At iterate    12  f =       132.16  |proj g|=     0.0017694\n",
      "At iterate    13  f =       132.16  |proj g|=    0.00041542\n",
      "At iterate    14  f =       132.16  |proj g|=    0.00030901\n",
      "At iterate    15  f =       132.16  |proj g|=    5.4999e-06\n",
      "At iterate    16  f =       132.16  |proj g|=    4.5728e-06\n",
      "\n",
      "iterations 16\n",
      "function evaluations 19\n",
      "segments explored during Cauchy searches 16\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.57278e-06\n",
      "final function value 132.165\n",
      "\n",
      "F = 132.165\n",
      "final  value 132.164557 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.7242 179.5673 \n",
      "  - best initial criterion value(s) :  -111.6357 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       111.64  |proj g|=     0.019382\n",
      "At iterate     1  f =       111.64  |proj g|=      0.019387\n",
      "At iterate     2  f =          111  |proj g|=      0.022881\n",
      "At iterate     3  f =       110.49  |proj g|=       0.01549\n",
      "At iterate     4  f =       110.45  |proj g|=      0.017389\n",
      "At iterate     5  f =       110.34  |proj g|=      0.012304\n",
      "At iterate     6  f =       110.26  |proj g|=     0.0043591\n",
      "At iterate     7  f =       110.25  |proj g|=     0.0021675\n",
      "At iterate     8  f =       110.25  |proj g|=    0.00021121\n",
      "At iterate     9  f =       110.25  |proj g|=    8.7984e-06\n",
      "At iterate    10  f =       110.25  |proj g|=    1.4826e-07\n",
      "\n",
      "iterations 10\n",
      "function evaluations 19\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.48263e-07\n",
      "final function value 110.249\n",
      "\n",
      "F = 110.249\n",
      "final  value 110.249181 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6947 179.6447 \n",
      "  - best initial criterion value(s) :  -127.091 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       127.09  |proj g|=       0.1105\n",
      "At iterate     1  f =       127.08  |proj g|=       0.10737\n",
      "At iterate     2  f =       126.82  |proj g|=       0.02521\n",
      "At iterate     3  f =       126.79  |proj g|=      0.025987\n",
      "At iterate     4  f =       126.72  |proj g|=     0.0088687\n",
      "At iterate     5  f =       126.71  |proj g|=     0.0020832\n",
      "At iterate     6  f =       126.71  |proj g|=     0.0002774\n",
      "At iterate     7  f =       126.71  |proj g|=     2.934e-05\n",
      "At iterate     8  f =       126.71  |proj g|=    1.2124e-05\n",
      "\n",
      "iterations 8\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.21244e-05\n",
      "final function value 126.705\n",
      "\n",
      "F = 126.705\n",
      "final  value 126.705169 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4236 179.6901 \n",
      "  - best initial criterion value(s) :  -115.1275 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       115.13  |proj g|=     0.013869\n",
      "At iterate     1  f =       115.13  |proj g|=       0.01384\n",
      "At iterate     2  f =       115.07  |proj g|=     0.0068681\n",
      "At iterate     3  f =       115.04  |proj g|=     0.0013743\n",
      "At iterate     4  f =       115.03  |proj g|=     0.0010551\n",
      "At iterate     5  f =       115.03  |proj g|=    0.00013785\n",
      "At iterate     6  f =       115.03  |proj g|=    3.8675e-06\n",
      "At iterate     7  f =       115.03  |proj g|=    2.2499e-07\n",
      "\n",
      "iterations 7\n",
      "function evaluations 8\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.24991e-07\n",
      "final function value 115.034\n",
      "\n",
      "F = 115.034\n",
      "final  value 115.034177 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6357 179.6968 \n",
      "  - best initial criterion value(s) :  -89.57758 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       89.578  |proj g|=     0.044573\n",
      "At iterate     1  f =       89.575  |proj g|=      0.044483\n",
      "At iterate     2  f =       88.821  |proj g|=      0.010932\n",
      "At iterate     3  f =       88.779  |proj g|=     0.0038059\n",
      "At iterate     4  f =       88.772  |proj g|=    0.00038682\n",
      "At iterate     5  f =       88.772  |proj g|=    1.5436e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     6  f =       88.772  |proj g|=    1.5436e-05\n",
      "\n",
      "iterations 6\n",
      "function evaluations 40\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 1.54359e-05\n",
      "final function value 88.7722\n",
      "\n",
      "F = 88.7722\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 88.772222 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6373 179.6167 \n",
      "  - best initial criterion value(s) :  -134.2711 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       134.27  |proj g|=     0.047563\n",
      "At iterate     1  f =       134.27  |proj g|=      0.046754\n",
      "At iterate     2  f =       134.21  |proj g|=      0.010945\n",
      "At iterate     3  f =       134.21  |proj g|=     0.0033172\n",
      "At iterate     4  f =       134.21  |proj g|=     0.0028835\n",
      "At iterate     5  f =       134.21  |proj g|=     0.0013336\n",
      "At iterate     6  f =       134.21  |proj g|=    2.5771e-05\n",
      "At iterate     7  f =       134.21  |proj g|=    8.4744e-08\n",
      "\n",
      "iterations 7\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 8.47444e-08\n",
      "final function value 134.206\n",
      "\n",
      "F = 134.206\n",
      "final  value 134.205969 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6056 179.6483 \n",
      "  - best initial criterion value(s) :  -121.3234 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       121.32  |proj g|=       0.3418\n",
      "At iterate     1  f =       121.21  |proj g|=       0.31928\n",
      "At iterate     2  f =       120.33  |proj g|=      0.063061\n",
      "At iterate     3  f =       120.28  |proj g|=      0.018647\n",
      "At iterate     4  f =       120.28  |proj g|=     0.0019955\n",
      "At iterate     5  f =       120.28  |proj g|=     0.0010235\n",
      "At iterate     6  f =       120.28  |proj g|=    0.00098609\n",
      "At iterate     7  f =       120.28  |proj g|=     0.0025965\n",
      "At iterate     8  f =       120.28  |proj g|=     0.0043822\n",
      "At iterate     9  f =       120.28  |proj g|=     0.0053385\n",
      "At iterate    10  f =       120.28  |proj g|=     0.0031414\n",
      "At iterate    11  f =       120.28  |proj g|=    0.00053564\n",
      "At iterate    12  f =       120.28  |proj g|=    1.6495e-05\n",
      "At iterate    13  f =       120.28  |proj g|=    3.2713e-07\n",
      "\n",
      "iterations 13\n",
      "function evaluations 14\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.27134e-07\n",
      "final function value 120.275\n",
      "\n",
      "F = 120.275\n",
      "final  value 120.275174 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4606 179.5777 \n",
      "  - best initial criterion value(s) :  -132.0217 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       132.02  |proj g|=     0.035311\n",
      "At iterate     1  f =       132.02  |proj g|=       0.03517\n",
      "At iterate     2  f =       131.74  |proj g|=     0.0054222\n",
      "At iterate     3  f =       131.74  |proj g|=     0.0010412\n",
      "At iterate     4  f =       131.74  |proj g|=    0.00055068\n",
      "At iterate     5  f =       131.74  |proj g|=    0.00070985\n",
      "At iterate     6  f =       131.74  |proj g|=     0.0009017\n",
      "At iterate     7  f =       131.74  |proj g|=     0.0004799\n",
      "At iterate     8  f =       131.74  |proj g|=    7.2741e-05\n",
      "At iterate     9  f =       131.74  |proj g|=    7.1298e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 131.738425 \n",
      "stopped after 9 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6364 179.4901 \n",
      "  - best initial criterion value(s) :  -112.5581 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       112.56  |proj g|=    0.0043594\n",
      "At iterate     1  f =       112.56  |proj g|=     0.0043583\n",
      "At iterate     2  f =       112.53  |proj g|=     0.0053856\n",
      "At iterate     3  f =       112.52  |proj g|=     0.0039737\n",
      "At iterate     4  f =        112.5  |proj g|=     0.0004303\n",
      "At iterate     5  f =        112.5  |proj g|=    6.6866e-05\n",
      "At iterate     6  f =        112.5  |proj g|=    3.2846e-06\n",
      "At iterate     7  f =        112.5  |proj g|=    3.0469e-06\n",
      "\n",
      "iterations 7\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.04693e-06\n",
      "final function value 112.505\n",
      "\n",
      "F = 112.505\n",
      "final  value 112.504568 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6253 179.5714 \n",
      "  - best initial criterion value(s) :  -122.8742 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       122.87  |proj g|=     0.016098\n",
      "At iterate     1  f =       122.87  |proj g|=      0.016086\n",
      "At iterate     2  f =       122.73  |proj g|=      0.010072\n",
      "At iterate     3  f =        122.7  |proj g|=     0.0047782\n",
      "At iterate     4  f =        122.7  |proj g|=     0.0013095\n",
      "At iterate     5  f =       122.69  |proj g|=      0.001197\n",
      "At iterate     6  f =       122.69  |proj g|=    0.00072089\n",
      "At iterate     7  f =       122.69  |proj g|=    4.9722e-05\n",
      "At iterate     8  f =       122.69  |proj g|=    1.2422e-06\n",
      "At iterate     9  f =       122.69  |proj g|=    9.9192e-08\n",
      "At iterate    10  f =       122.69  |proj g|=    5.9267e-09\n",
      "At iterate    11  f =       122.69  |proj g|=    5.9267e-09\n",
      "\n",
      "iterations 11\n",
      "function evaluations 26\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.92668e-09\n",
      "final function value 122.693\n",
      "\n",
      "F = 122.693\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 122.693415 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6336 179.6415 \n",
      "  - best initial criterion value(s) :  -104.5416 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       104.54  |proj g|=     0.045376\n",
      "At iterate     1  f =       104.54  |proj g|=      0.045396\n",
      "ys=-1.138e-06  -gs= 2.141e-03, BFGS update SKIPPED\n",
      "At iterate     2  f =       103.82  |proj g|=      0.037564\n",
      "At iterate     3  f =       103.58  |proj g|=      0.016567\n",
      "Nonpositive definiteness in Cholesky factorization in formk;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     4  f =       103.56  |proj g|=      0.010242\n",
      "At iterate     5  f =       103.54  |proj g|=     0.0043304\n",
      "At iterate     6  f =       103.52  |proj g|=     0.0033147\n",
      "At iterate     7  f =       103.49  |proj g|=     0.0011991\n",
      "At iterate     8  f =       103.49  |proj g|=    9.6683e-05\n",
      "At iterate     9  f =       103.49  |proj g|=    4.1544e-05\n",
      "At iterate    10  f =       103.49  |proj g|=    2.7256e-06\n",
      "At iterate    11  f =       103.49  |proj g|=     6.362e-09\n",
      "\n",
      "iterations 11\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.36202e-09\n",
      "final function value 103.491\n",
      "\n",
      "F = 103.491\n",
      "final  value 103.491357 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6316 179.5084 \n",
      "  - best initial criterion value(s) :  -129.8186 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       129.82  |proj g|=      0.30498\n",
      "At iterate     1  f =       129.73  |proj g|=       0.30549\n",
      "ys=-1.535e-04  -gs= 9.314e-02, BFGS update SKIPPED\n",
      "At iterate     2  f =       127.83  |proj g|=       0.26441\n",
      "At iterate     3  f =       126.91  |proj g|=      0.072562\n",
      "At iterate     4  f =       126.87  |proj g|=     0.0084567\n",
      "At iterate     5  f =       126.87  |proj g|=     0.0084227\n",
      "At iterate     6  f =       126.86  |proj g|=      0.012311\n",
      "At iterate     7  f =       126.85  |proj g|=      0.032288\n",
      "At iterate     8  f =       126.83  |proj g|=      0.061191\n",
      "At iterate     9  f =       126.77  |proj g|=        0.1034\n",
      "At iterate    10  f =       126.69  |proj g|=       0.10465\n",
      "At iterate    11  f =       126.63  |proj g|=    8.4312e-05\n",
      "At iterate    12  f =       126.63  |proj g|=    9.1461e-06\n",
      "\n",
      "iterations 12\n",
      "function evaluations 20\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 9.14606e-06\n",
      "final function value 126.628\n",
      "\n",
      "F = 126.628\n",
      "final  value 126.627936 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.3944 179.5248 \n",
      "  - best initial criterion value(s) :  -126.247 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       126.25  |proj g|=     0.068734\n",
      "At iterate     1  f =       126.24  |proj g|=      0.066741\n",
      "At iterate     2  f =       126.13  |proj g|=      0.013351\n",
      "At iterate     3  f =       126.12  |proj g|=       0.01113\n",
      "At iterate     4  f =        126.1  |proj g|=      0.021259\n",
      "At iterate     5  f =       126.06  |proj g|=       0.03248\n",
      "At iterate     6  f =       126.03  |proj g|=      0.028896\n",
      "At iterate     7  f =       126.01  |proj g|=     0.0024972\n",
      "At iterate     8  f =       126.01  |proj g|=    0.00034761\n",
      "At iterate     9  f =       126.01  |proj g|=    1.0773e-05\n",
      "At iterate    10  f =       126.01  |proj g|=    8.3741e-07\n",
      "\n",
      "iterations 10\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 8.37413e-07\n",
      "final function value 126.008\n",
      "\n",
      "F = 126.008\n",
      "final  value 126.007536 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6744 179.6181 \n",
      "  - best initial criterion value(s) :  -108.9126 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       108.91  |proj g|=    0.0059545\n",
      "At iterate     1  f =       108.91  |proj g|=     0.0059482\n",
      "At iterate     2  f =       108.89  |proj g|=     0.0023983\n",
      "At iterate     3  f =       108.88  |proj g|=       0.00235\n",
      "At iterate     4  f =       108.88  |proj g|=    0.00011681\n",
      "At iterate     5  f =       108.88  |proj g|=    1.0977e-05\n",
      "At iterate     6  f =       108.88  |proj g|=    2.9618e-07\n",
      "\n",
      "iterations 6\n",
      "function evaluations 7\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.96179e-07\n",
      "final function value 108.877\n",
      "\n",
      "F = 108.877\n",
      "final  value 108.877245 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6623 179.4227 \n",
      "  - best initial criterion value(s) :  -119.066 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       119.07  |proj g|=    0.0084548\n",
      "At iterate     1  f =       119.07  |proj g|=     0.0084515\n",
      "At iterate     2  f =       118.97  |proj g|=     0.0067935\n",
      "At iterate     3  f =       118.94  |proj g|=     0.0015917\n",
      "At iterate     4  f =       118.94  |proj g|=    0.00036533\n",
      "At iterate     5  f =       118.94  |proj g|=      4.02e-05\n",
      "At iterate     6  f =       118.94  |proj g|=    4.6444e-06\n",
      "At iterate     7  f =       118.94  |proj g|=    1.5788e-06\n",
      "At iterate     8  f =       118.94  |proj g|=    1.5734e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.57344e-06\n",
      "final function value 118.937\n",
      "\n",
      "F = 118.937\n",
      "final  value 118.936966 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6827 179.5912 \n",
      "  - best initial criterion value(s) :  -111.2551 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       111.26  |proj g|=     0.037663\n",
      "At iterate     1  f =       111.25  |proj g|=       0.03736\n",
      "At iterate     2  f =       111.11  |proj g|=     0.0088886\n",
      "At iterate     3  f =       111.09  |proj g|=     0.0066212\n",
      "At iterate     4  f =       111.06  |proj g|=       0.01175\n",
      "At iterate     5  f =       111.02  |proj g|=      0.015721\n",
      "At iterate     6  f =       110.99  |proj g|=     0.0097317\n",
      "At iterate     7  f =       110.98  |proj g|=    0.00041723\n",
      "At iterate     8  f =       110.98  |proj g|=    4.2549e-05\n",
      "At iterate     9  f =       110.98  |proj g|=    1.9782e-06\n",
      "At iterate    10  f =       110.98  |proj g|=     2.283e-07\n",
      "\n",
      "iterations 10\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.28296e-07\n",
      "final function value 110.979\n",
      "\n",
      "F = 110.979\n",
      "final  value 110.979370 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6927 179.4807 \n",
      "  - best initial criterion value(s) :  -128.4609 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       128.46  |proj g|=    0.0084681\n",
      "At iterate     1  f =       128.46  |proj g|=     0.0083909\n",
      "At iterate     2  f =       128.46  |proj g|=    0.00080359\n",
      "At iterate     3  f =       128.46  |proj g|=    0.00061729\n",
      "At iterate     4  f =       128.46  |proj g|=    0.00051488\n",
      "At iterate     5  f =       128.46  |proj g|=    0.00021622\n",
      "At iterate     6  f =       128.46  |proj g|=    1.3809e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     7  f =       128.46  |proj g|=    1.3802e-05\n",
      "\n",
      "iterations 7\n",
      "function evaluations 33\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.38022e-05\n",
      "final function value 128.457\n",
      "\n",
      "F = 128.457\n",
      "final  value 128.456747 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6249 179.5023 \n",
      "  - best initial criterion value(s) :  -109.9885 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       109.99  |proj g|=     0.044922\n",
      "At iterate     1  f =       109.99  |proj g|=      0.044691\n",
      "At iterate     2  f =       109.72  |proj g|=     0.0057901\n",
      "At iterate     3  f =       109.71  |proj g|=     0.0039955\n",
      "At iterate     4  f =        109.7  |proj g|=      0.005078\n",
      "At iterate     5  f =       109.68  |proj g|=     0.0060653\n",
      "At iterate     6  f =       109.67  |proj g|=     0.0019921\n",
      "At iterate     7  f =       109.67  |proj g|=     0.0001013\n",
      "At iterate     8  f =       109.67  |proj g|=    1.5517e-06\n",
      "At iterate     9  f =       109.67  |proj g|=    7.6221e-08\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    10  f =       109.67  |proj g|=    8.5992e-08\n",
      "\n",
      "iterations 10\n",
      "function evaluations 47\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 8.59919e-08\n",
      "final function value 109.674\n",
      "\n",
      "F = 109.674\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 109.674363 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5512 179.6539 \n",
      "  - best initial criterion value(s) :  -121.2683 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       121.27  |proj g|=     0.054901\n",
      "At iterate     1  f =       121.27  |proj g|=      0.054765\n",
      "At iterate     2  f =       121.14  |proj g|=      0.039968\n",
      "At iterate     3  f =       121.07  |proj g|=     0.0054093\n",
      "At iterate     4  f =       121.07  |proj g|=     0.0066392\n",
      "At iterate     5  f =       121.06  |proj g|=     0.0068529\n",
      "At iterate     6  f =       121.05  |proj g|=    0.00058427\n",
      "At iterate     7  f =       121.05  |proj g|=    4.1506e-05\n",
      "At iterate     8  f =       121.05  |proj g|=    3.5318e-07\n",
      "At iterate     9  f =       121.05  |proj g|=     1.788e-08\n",
      "\n",
      "iterations 9\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.78797e-08\n",
      "final function value 121.052\n",
      "\n",
      "F = 121.052\n",
      "final  value 121.052020 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6166 179.575 \n",
      "  - best initial criterion value(s) :  -98.63813 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       98.638  |proj g|=     0.017981\n",
      "At iterate     1  f =       98.638  |proj g|=      0.017921\n",
      "At iterate     2  f =       98.581  |proj g|=     0.0031033\n",
      "At iterate     3  f =       98.575  |proj g|=     0.0032854\n",
      "At iterate     4  f =       98.564  |proj g|=     0.0032041\n",
      "At iterate     5  f =       98.561  |proj g|=     0.0018858\n",
      "At iterate     6  f =        98.56  |proj g|=    4.5881e-05\n",
      "At iterate     7  f =        98.56  |proj g|=    1.1105e-06\n",
      "At iterate     8  f =        98.56  |proj g|=    1.1013e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 1.1013e-06\n",
      "final function value 98.5602\n",
      "\n",
      "F = 98.5602\n",
      "final  value 98.560155 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4952 179.4514 \n",
      "  - best initial criterion value(s) :  -104.9146 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       104.91  |proj g|=     0.053359\n",
      "At iterate     1  f =       104.91  |proj g|=      0.053345\n",
      "At iterate     2  f =       104.22  |proj g|=      0.027749\n",
      "Nonpositive definiteness in Cholesky factorization in formk;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     3  f =       104.17  |proj g|=      0.018279\n",
      "At iterate     4  f =       104.14  |proj g|=      0.005352\n",
      "At iterate     5  f =       104.13  |proj g|=     0.0022653\n",
      "At iterate     6  f =       104.13  |proj g|=     0.0021992\n",
      "At iterate     7  f =       104.12  |proj g|=      0.001337\n",
      "At iterate     8  f =       104.12  |proj g|=    5.4824e-05\n",
      "At iterate     9  f =       104.12  |proj g|=    3.8414e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 17\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.84137e-07\n",
      "final function value 104.122\n",
      "\n",
      "F = 104.122\n",
      "final  value 104.121598 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6141 179.4544 \n",
      "  - best initial criterion value(s) :  -114.056 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       114.06  |proj g|=     0.013831\n",
      "At iterate     1  f =       114.06  |proj g|=      0.013803\n",
      "At iterate     2  f =       114.02  |proj g|=     0.0049767\n",
      "At iterate     3  f =       114.01  |proj g|=     0.0002584\n",
      "At iterate     4  f =       114.01  |proj g|=    8.7987e-06\n",
      "At iterate     5  f =       114.01  |proj g|=    1.1189e-08\n",
      "At iterate     6  f =       114.01  |proj g|=    3.7171e-09\n",
      "\n",
      "iterations 6\n",
      "function evaluations 7\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 3.71713e-09\n",
      "final function value 114.006\n",
      "\n",
      "F = 114.006\n",
      "final  value 114.006265 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4573 179.5929 \n",
      "  - best initial criterion value(s) :  -98.48786 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       98.488  |proj g|=     0.058961\n",
      "At iterate     1  f =       98.484  |proj g|=      0.058856\n",
      "At iterate     2  f =        97.13  |proj g|=       0.02183\n",
      "At iterate     3  f =       96.745  |proj g|=     0.0024506\n",
      "At iterate     4  f =       96.744  |proj g|=    0.00084229\n",
      "At iterate     5  f =       96.744  |proj g|=    1.8497e-05\n",
      "At iterate     6  f =       96.744  |proj g|=    1.2881e-07\n",
      "\n",
      "iterations 6\n",
      "function evaluations 7\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 1.28812e-07\n",
      "final function value 96.7439\n",
      "\n",
      "F = 96.7439\n",
      "final  value 96.743949 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6498 179.5187 \n",
      "  - best initial criterion value(s) :  -118.5731 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       118.57  |proj g|=     0.040254\n",
      "At iterate     1  f =       118.57  |proj g|=      0.040299\n",
      "ys=-2.582e-06  -gs= 1.665e-03, BFGS update SKIPPED\n",
      "At iterate     2  f =       118.12  |proj g|=      0.038668\n",
      "At iterate     3  f =       117.97  |proj g|=      0.025981\n",
      "At iterate     4  f =       117.88  |proj g|=      0.025741\n",
      "At iterate     5  f =       117.84  |proj g|=     0.0031595\n",
      "At iterate     6  f =       117.84  |proj g|=    0.00054607\n",
      "At iterate     7  f =       117.84  |proj g|=    3.4374e-05\n",
      "At iterate     8  f =       117.84  |proj g|=     3.008e-07\n",
      "At iterate     9  f =       117.84  |proj g|=    1.4339e-09\n",
      "\n",
      "iterations 9\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.43389e-09\n",
      "final function value 117.839\n",
      "\n",
      "F = 117.839\n",
      "final  value 117.839353 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5628 179.6566 \n",
      "  - best initial criterion value(s) :  -112.9989 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=          113  |proj g|=     0.021043\n",
      "At iterate     1  f =          113  |proj g|=      0.020995\n",
      "At iterate     2  f =       112.84  |proj g|=     0.0072522\n",
      "At iterate     3  f =       112.83  |proj g|=     0.0018836\n",
      "At iterate     4  f =       112.83  |proj g|=    0.00043208\n",
      "At iterate     5  f =       112.83  |proj g|=    2.0253e-05\n",
      "At iterate     6  f =       112.83  |proj g|=    2.9381e-07\n",
      "At iterate     7  f =       112.83  |proj g|=    5.7372e-09\n",
      "\n",
      "iterations 7\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.7372e-09\n",
      "final function value 112.83\n",
      "\n",
      "F = 112.83\n",
      "final  value 112.829699 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6404 179.6305 \n",
      "  - best initial criterion value(s) :  -112.3595 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       112.36  |proj g|=     0.068593\n",
      "At iterate     1  f =       112.35  |proj g|=      0.068081\n",
      "At iterate     2  f =       112.22  |proj g|=       0.06019\n",
      "At iterate     3  f =       112.13  |proj g|=      0.016514\n",
      "At iterate     4  f =       112.12  |proj g|=     0.0027596\n",
      "At iterate     5  f =       112.12  |proj g|=    0.00016817\n",
      "At iterate     6  f =       112.12  |proj g|=     2.239e-05\n",
      "At iterate     7  f =       112.12  |proj g|=    1.7287e-05\n",
      "\n",
      "iterations 7\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.72872e-05\n",
      "final function value 112.123\n",
      "\n",
      "F = 112.123\n",
      "final  value 112.123277 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6131 179.7679 \n",
      "  - best initial criterion value(s) :  -106.5689 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       106.57  |proj g|=    0.0036773\n",
      "At iterate     1  f =       106.57  |proj g|=     0.0036749\n",
      "At iterate     2  f =       106.56  |proj g|=     0.0019504\n",
      "At iterate     3  f =       106.55  |proj g|=    0.00093565\n",
      "At iterate     4  f =       106.55  |proj g|=    5.1593e-05\n",
      "At iterate     5  f =       106.55  |proj g|=     3.957e-07\n",
      "At iterate     6  f =       106.55  |proj g|=    6.1533e-09\n",
      "\n",
      "iterations 6\n",
      "function evaluations 7\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.15328e-09\n",
      "final function value 106.553\n",
      "\n",
      "F = 106.553\n",
      "final  value 106.553103 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4811 179.6213 \n",
      "  - best initial criterion value(s) :  -119.9614 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       119.96  |proj g|=    0.0069504\n",
      "At iterate     1  f =       119.96  |proj g|=     0.0069424\n",
      "At iterate     2  f =       119.85  |proj g|=     0.0063304\n",
      "At iterate     3  f =       119.84  |proj g|=     0.0024439\n",
      "At iterate     4  f =       119.84  |proj g|=    0.00015659\n",
      "At iterate     5  f =       119.84  |proj g|=    5.7467e-05\n",
      "At iterate     6  f =       119.84  |proj g|=    4.4491e-07\n",
      "At iterate     7  f =       119.84  |proj g|=    1.4574e-08\n",
      "At iterate     8  f =       119.84  |proj g|=    2.6268e-09\n",
      "\n",
      "iterations 8\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.62677e-09\n",
      "final function value 119.842\n",
      "\n",
      "F = 119.842\n",
      "final  value 119.842068 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4947 179.5426 \n",
      "  - best initial criterion value(s) :  -105.8076 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       105.81  |proj g|=      0.05882\n",
      "At iterate     1  f =        105.8  |proj g|=      0.058632\n",
      "At iterate     2  f =       104.89  |proj g|=     0.0093532\n",
      "At iterate     3  f =       104.87  |proj g|=      0.002901\n",
      "At iterate     4  f =       104.86  |proj g|=     0.0027155\n",
      "At iterate     5  f =       104.85  |proj g|=      0.001807\n",
      "At iterate     6  f =       104.84  |proj g|=    8.9511e-05\n",
      "At iterate     7  f =       104.84  |proj g|=    1.5372e-05\n",
      "At iterate     8  f =       104.84  |proj g|=    1.4121e-06\n",
      "At iterate     9  f =       104.84  |proj g|=    1.4082e-06\n",
      "At iterate    10  f =       104.84  |proj g|=    1.7562e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 104.844299 \n",
      "stopped after 10 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6479 179.6285 \n",
      "  - best initial criterion value(s) :  -116.9377 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       116.94  |proj g|=     0.063309\n",
      "At iterate     1  f =       116.93  |proj g|=       0.06312\n",
      "At iterate     2  f =       116.54  |proj g|=      0.020425\n",
      "At iterate     3  f =       116.52  |proj g|=    0.00083453\n",
      "At iterate     4  f =       116.52  |proj g|=    0.00067222\n",
      "At iterate     5  f =       116.52  |proj g|=    0.00069416\n",
      "At iterate     6  f =       116.52  |proj g|=     0.0025233\n",
      "At iterate     7  f =       116.52  |proj g|=     0.0050229\n",
      "At iterate     8  f =       116.51  |proj g|=       0.01157\n",
      "At iterate     9  f =       116.51  |proj g|=      0.024923\n",
      "At iterate    10  f =        116.5  |proj g|=      0.053446\n",
      "At iterate    11  f =       116.48  |proj g|=         0.038\n",
      "At iterate    12  f =       116.45  |proj g|=     0.0058966\n",
      "At iterate    13  f =       116.44  |proj g|=    0.00082768\n",
      "At iterate    14  f =       116.44  |proj g|=    2.2569e-05\n",
      "At iterate    15  f =       116.44  |proj g|=      9.28e-08\n",
      "\n",
      "iterations 15\n",
      "function evaluations 19\n",
      "segments explored during Cauchy searches 15\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 9.27999e-08\n",
      "final function value 116.444\n",
      "\n",
      "F = 116.444\n",
      "final  value 116.444360 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6089 179.6414 \n",
      "  - best initial criterion value(s) :  -115.8988 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        115.9  |proj g|=      0.14486\n",
      "At iterate     1  f =       115.88  |proj g|=       0.14413\n",
      "At iterate     2  f =       115.02  |proj g|=      0.033324\n",
      "At iterate     3  f =       115.01  |proj g|=      0.029964\n",
      "At iterate     4  f =          115  |proj g|=     0.0048126\n",
      "At iterate     5  f =       114.99  |proj g|=     0.0043476\n",
      "At iterate     6  f =       114.99  |proj g|=      0.004715\n",
      "At iterate     7  f =       114.99  |proj g|=     9.092e-05\n",
      "At iterate     8  f =       114.99  |proj g|=    1.6371e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 114.985552 \n",
      "stopped after 8 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.652 179.5953 \n",
      "  - best initial criterion value(s) :  -100.1871 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       100.19  |proj g|=     0.014605\n",
      "At iterate     1  f =       100.19  |proj g|=      0.014537\n",
      "At iterate     2  f =       100.15  |proj g|=     0.0028947\n",
      "At iterate     3  f =       100.15  |proj g|=     0.0019552\n",
      "At iterate     4  f =       100.15  |proj g|=     0.0015717\n",
      "At iterate     5  f =       100.15  |proj g|=    0.00049269\n",
      "At iterate     6  f =       100.15  |proj g|=    5.8195e-05\n",
      "At iterate     7  f =       100.15  |proj g|=    1.5388e-06\n",
      "At iterate     8  f =       100.15  |proj g|=    4.3151e-08\n",
      "\n",
      "iterations 8\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.31515e-08\n",
      "final function value 100.146\n",
      "\n",
      "F = 100.146\n",
      "final  value 100.145630 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.584 179.6057 \n",
      "  - best initial criterion value(s) :  -112.8094 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       112.81  |proj g|=      0.07124\n",
      "At iterate     1  f =        112.8  |proj g|=      0.070306\n",
      "At iterate     2  f =        112.6  |proj g|=     0.0086994\n",
      "At iterate     3  f =        112.6  |proj g|=     0.0014132\n",
      "At iterate     4  f =        112.6  |proj g|=    0.00011667\n",
      "At iterate     5  f =        112.6  |proj g|=    0.00011853\n",
      "At iterate     6  f =        112.6  |proj g|=    0.00022728\n",
      "At iterate     7  f =        112.6  |proj g|=     0.0003334\n",
      "At iterate     8  f =        112.6  |proj g|=    0.00023007\n",
      "At iterate     9  f =        112.6  |proj g|=    5.6658e-05\n",
      "At iterate    10  f =        112.6  |proj g|=    4.5314e-06\n",
      "\n",
      "iterations 10\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.53144e-06\n",
      "final function value 112.595\n",
      "\n",
      "F = 112.595\n",
      "final  value 112.595337 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6314 179.4832 \n",
      "  - best initial criterion value(s) :  -107.0562 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       107.06  |proj g|=     0.011702\n",
      "At iterate     1  f =       107.06  |proj g|=      0.011698\n",
      "At iterate     2  f =       106.88  |proj g|=      0.002843\n",
      "At iterate     3  f =       106.87  |proj g|=    0.00081698\n",
      "At iterate     4  f =       106.87  |proj g|=    0.00033197\n",
      "At iterate     5  f =       106.87  |proj g|=    6.7703e-05\n",
      "At iterate     6  f =       106.87  |proj g|=    7.5335e-06\n",
      "At iterate     7  f =       106.87  |proj g|=    6.6748e-06\n",
      "At iterate     8  f =       106.87  |proj g|=    6.6627e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 106.868187 \n",
      "stopped after 8 iterations\n",
      "[1] 48.68034 51.31966\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5702 179.481 \n",
      "  - best initial criterion value(s) :  -146.12 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       146.12  |proj g|=     0.046039\n",
      "At iterate     1  f =       146.12  |proj g|=      0.045915\n",
      "At iterate     2  f =       145.47  |proj g|=      0.064492\n",
      "At iterate     3  f =       143.97  |proj g|=      0.041955\n",
      "At iterate     4  f =       143.85  |proj g|=     0.0079086\n",
      "At iterate     5  f =       143.85  |proj g|=      0.005671\n",
      "At iterate     6  f =       143.85  |proj g|=     0.0050487\n",
      "At iterate     7  f =       143.85  |proj g|=    3.5002e-05\n",
      "At iterate     8  f =       143.85  |proj g|=    2.3736e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     9  f =       143.85  |proj g|=     2.378e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 45\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.37795e-06\n",
      "final function value 143.848\n",
      "\n",
      "F = 143.848\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 143.847919 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5331 179.5795 \n",
      "  - best initial criterion value(s) :  -117.4284 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       117.43  |proj g|=     0.019577\n",
      "At iterate     1  f =       117.43  |proj g|=      0.019546\n",
      "At iterate     2  f =        117.2  |proj g|=      0.030007\n",
      "At iterate     3  f =       117.09  |proj g|=      0.012714\n",
      "At iterate     4  f =       117.06  |proj g|=     0.0015993\n",
      "At iterate     5  f =       117.06  |proj g|=     0.0004453\n",
      "At iterate     6  f =       117.06  |proj g|=    0.00016246\n",
      "At iterate     7  f =       117.06  |proj g|=    4.1922e-07\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     8  f =       117.06  |proj g|=      4.19e-07\n",
      "\n",
      "iterations 8\n",
      "function evaluations 32\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.19004e-07\n",
      "final function value 117.057\n",
      "\n",
      "F = 117.057\n",
      "final  value 117.057014 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6383 179.5584 \n",
      "  - best initial criterion value(s) :  -139.7219 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       139.72  |proj g|=     0.074668\n",
      "At iterate     1  f =       139.72  |proj g|=      0.073956\n",
      "At iterate     2  f =       139.49  |proj g|=      0.035758\n",
      "At iterate     3  f =       139.44  |proj g|=     0.0066975\n",
      "At iterate     4  f =       139.44  |proj g|=     0.0020867\n",
      "At iterate     5  f =       139.44  |proj g|=    0.00018919\n",
      "At iterate     6  f =       139.44  |proj g|=    4.8371e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     7  f =       139.44  |proj g|=    4.8371e-06\n",
      "\n",
      "iterations 7\n",
      "function evaluations 43\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.83711e-06\n",
      "final function value 139.436\n",
      "\n",
      "F = 139.436\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 139.436181 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5926 179.6035 \n",
      "  - best initial criterion value(s) :  -148.1739 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       148.17  |proj g|=      0.10612\n",
      "At iterate     1  f =       148.16  |proj g|=       0.10624\n",
      "ys=-1.887e-06  -gs= 1.520e-02, BFGS update SKIPPED\n",
      "At iterate     2  f =       147.49  |proj g|=      0.066652\n",
      "At iterate     3  f =       147.19  |proj g|=       0.24567\n",
      "At iterate     4  f =       144.65  |proj g|=       0.13235\n",
      "At iterate     5  f =        144.5  |proj g|=      0.012008\n",
      "At iterate     6  f =       144.49  |proj g|=     0.0032595\n",
      "At iterate     7  f =       144.49  |proj g|=    0.00075885\n",
      "At iterate     8  f =       144.49  |proj g|=    3.2797e-05\n",
      "At iterate     9  f =       144.49  |proj g|=    1.4307e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 20\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.43071e-06\n",
      "final function value 144.494\n",
      "\n",
      "F = 144.494\n",
      "final  value 144.494085 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4594 179.6176 \n",
      "  - best initial criterion value(s) :  -127.5278 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       127.53  |proj g|=       0.1357\n",
      "At iterate     1  f =        127.5  |proj g|=       0.13222\n",
      "At iterate     2  f =       126.99  |proj g|=      0.017908\n",
      "At iterate     3  f =       126.97  |proj g|=      0.004314\n",
      "At iterate     4  f =       126.97  |proj g|=     0.0025295\n",
      "At iterate     5  f =       126.97  |proj g|=     0.0024089\n",
      "At iterate     6  f =       126.97  |proj g|=    0.00057345\n",
      "At iterate     7  f =       126.97  |proj g|=    4.9493e-05\n",
      "At iterate     8  f =       126.97  |proj g|=    3.8017e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.80173e-06\n",
      "final function value 126.972\n",
      "\n",
      "F = 126.972\n",
      "final  value 126.972167 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.7041 179.5621 \n",
      "  - best initial criterion value(s) :  -135.611 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       135.61  |proj g|=      0.06104\n",
      "At iterate     1  f =       135.61  |proj g|=      0.058229\n",
      "At iterate     2  f =       135.54  |proj g|=      0.030724\n",
      "At iterate     3  f =        134.6  |proj g|=        0.2253\n",
      "At iterate     4  f =       134.15  |proj g|=       0.25231\n",
      "At iterate     5  f =       133.78  |proj g|=       0.18206\n",
      "At iterate     6  f =       133.57  |proj g|=      0.012227\n",
      "At iterate     7  f =       133.52  |proj g|=      0.027848\n",
      "At iterate     8  f =       133.52  |proj g|=      0.011309\n",
      "At iterate     9  f =       133.51  |proj g|=     0.0046095\n",
      "At iterate    10  f =       133.51  |proj g|=     0.0008239\n",
      "At iterate    11  f =       133.51  |proj g|=    5.3715e-05\n",
      "At iterate    12  f =       133.51  |proj g|=    3.3074e-07\n",
      "\n",
      "iterations 12\n",
      "function evaluations 21\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.30737e-07\n",
      "final function value 133.511\n",
      "\n",
      "F = 133.511\n",
      "final  value 133.510847 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5581 179.6636 \n",
      "  - best initial criterion value(s) :  -123.0173 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       123.02  |proj g|=      0.19865\n",
      "At iterate     1  f =       122.98  |proj g|=       0.19298\n",
      "At iterate     2  f =       122.05  |proj g|=      0.053276\n",
      "At iterate     3  f =       121.93  |proj g|=      0.022053\n",
      "At iterate     4  f =        121.9  |proj g|=       0.00614\n",
      "At iterate     5  f =        121.9  |proj g|=     0.0014983\n",
      "At iterate     6  f =        121.9  |proj g|=    5.7915e-05\n",
      "At iterate     7  f =        121.9  |proj g|=    2.0703e-06\n",
      "\n",
      "iterations 7\n",
      "function evaluations 8\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.07028e-06\n",
      "final function value 121.9\n",
      "\n",
      "F = 121.9\n",
      "final  value 121.900055 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.693 179.5334 \n",
      "  - best initial criterion value(s) :  -131.5196 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       131.52  |proj g|=      0.17691\n",
      "At iterate     1  f =       131.49  |proj g|=       0.17685\n",
      "At iterate     2  f =       130.31  |proj g|=      0.069716\n",
      "At iterate     3  f =       130.25  |proj g|=      0.014806\n",
      "At iterate     4  f =       130.24  |proj g|=       0.01351\n",
      "At iterate     5  f =        130.2  |proj g|=     0.0099363\n",
      "At iterate     6  f =        130.2  |proj g|=    0.00081053\n",
      "At iterate     7  f =        130.2  |proj g|=      0.000129\n",
      "At iterate     8  f =        130.2  |proj g|=    2.5733e-06\n",
      "At iterate     9  f =        130.2  |proj g|=    2.5755e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 24\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.57552e-06\n",
      "final function value 130.202\n",
      "\n",
      "F = 130.202\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 130.201985 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6392 179.7527 \n",
      "  - best initial criterion value(s) :  -124.4436 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       124.44  |proj g|=     0.076762\n",
      "At iterate     1  f =       124.44  |proj g|=      0.075815\n",
      "At iterate     2  f =       124.29  |proj g|=      0.064674\n",
      "At iterate     3  f =       124.23  |proj g|=      0.014774\n",
      "At iterate     4  f =       124.22  |proj g|=      0.015516\n",
      "At iterate     5  f =       124.18  |proj g|=      0.026197\n",
      "At iterate     6  f =       124.11  |proj g|=      0.054869\n",
      "At iterate     7  f =        123.9  |proj g|=       0.12622\n",
      "At iterate     8  f =       123.67  |proj g|=       0.15383\n",
      "At iterate     9  f =       123.45  |proj g|=      0.039816\n",
      "At iterate    10  f =       123.43  |proj g|=     0.0083207\n",
      "At iterate    11  f =       123.43  |proj g|=    0.00054034\n",
      "At iterate    12  f =       123.43  |proj g|=    0.00075314\n",
      "At iterate    13  f =       123.43  |proj g|=    7.8516e-05\n",
      "At iterate    14  f =       123.43  |proj g|=    2.8017e-06\n",
      "\n",
      "iterations 14\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.80174e-06\n",
      "final function value 123.431\n",
      "\n",
      "F = 123.431\n",
      "final  value 123.431143 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6847 179.6271 \n",
      "  - best initial criterion value(s) :  -158.5693 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       158.57  |proj g|=      0.03714\n",
      "At iterate     1  f =       158.57  |proj g|=      0.037031\n",
      "At iterate     2  f =       158.42  |proj g|=      0.031161\n",
      "At iterate     3  f =       158.37  |proj g|=      0.012579\n",
      "At iterate     4  f =       158.35  |proj g|=     0.0036115\n",
      "At iterate     5  f =       158.35  |proj g|=     0.0033118\n",
      "At iterate     6  f =       158.35  |proj g|=     0.0017583\n",
      "At iterate     7  f =       158.35  |proj g|=    0.00010606\n",
      "At iterate     8  f =       158.35  |proj g|=    1.8504e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 158.346557 \n",
      "stopped after 8 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5198 179.6822 \n",
      "  - best initial criterion value(s) :  -116.8569 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       116.86  |proj g|=     0.021404\n",
      "At iterate     1  f =       116.86  |proj g|=      0.021388\n",
      "At iterate     2  f =       116.69  |proj g|=       0.03484\n",
      "At iterate     3  f =       116.61  |proj g|=      0.034042\n",
      "At iterate     4  f =       116.49  |proj g|=      0.025131\n",
      "At iterate     5  f =       116.39  |proj g|=      0.011029\n",
      "At iterate     6  f =       116.38  |proj g|=      0.001915\n",
      "At iterate     7  f =       116.38  |proj g|=    0.00049347\n",
      "At iterate     8  f =       116.38  |proj g|=     1.891e-05\n",
      "At iterate     9  f =       116.38  |proj g|=    3.2161e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.21611e-07\n",
      "final function value 116.383\n",
      "\n",
      "F = 116.383\n",
      "final  value 116.383393 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6107 179.7539 \n",
      "  - best initial criterion value(s) :  -118.7511 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       118.75  |proj g|=     0.025365\n",
      "At iterate     1  f =       118.75  |proj g|=      0.025322\n",
      "At iterate     2  f =       118.53  |proj g|=       0.01051\n",
      "At iterate     3  f =        118.4  |proj g|=     0.0042633\n",
      "At iterate     4  f =       118.33  |proj g|=      0.001204\n",
      "At iterate     5  f =       118.33  |proj g|=    0.00045711\n",
      "At iterate     6  f =       118.33  |proj g|=    5.0985e-05\n",
      "At iterate     7  f =       118.33  |proj g|=     1.806e-05\n",
      "At iterate     8  f =       118.33  |proj g|=    1.7851e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 118.326634 \n",
      "stopped after 8 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6229 179.4718 \n",
      "  - best initial criterion value(s) :  -120.4788 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       120.48  |proj g|=     0.050988\n",
      "At iterate     1  f =       120.48  |proj g|=       0.05096\n",
      "At iterate     2  f =        119.7  |proj g|=      0.020959\n",
      "At iterate     3  f =       119.65  |proj g|=     0.0012669\n",
      "At iterate     4  f =       119.65  |proj g|=    0.00095734\n",
      "At iterate     5  f =       119.65  |proj g|=    0.00038233\n",
      "At iterate     6  f =       119.65  |proj g|=    6.7418e-05\n",
      "At iterate     7  f =       119.65  |proj g|=    3.5057e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 119.650268 \n",
      "stopped after 7 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.4861 179.5462 \n",
      "  - best initial criterion value(s) :  -134.2961 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        134.3  |proj g|=      0.17553\n",
      "At iterate     1  f =       134.27  |proj g|=       0.17208\n",
      "At iterate     2  f =       133.79  |proj g|=      0.025272\n",
      "At iterate     3  f =       133.77  |proj g|=       0.02962\n",
      "At iterate     4  f =       133.73  |proj g|=      0.038137\n",
      "At iterate     5  f =       133.55  |proj g|=       0.12545\n",
      "At iterate     6  f =       133.47  |proj g|=      0.032753\n",
      "At iterate     7  f =       133.45  |proj g|=      0.010982\n",
      "At iterate     8  f =       133.45  |proj g|=     0.0016335\n",
      "At iterate     9  f =       133.45  |proj g|=    0.00021407\n",
      "At iterate    10  f =       133.45  |proj g|=    1.3397e-06\n",
      "At iterate    11  f =       133.45  |proj g|=    5.3094e-09\n",
      "\n",
      "iterations 11\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.30937e-09\n",
      "final function value 133.446\n",
      "\n",
      "F = 133.446\n",
      "final  value 133.446114 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5858 179.6638 \n",
      "  - best initial criterion value(s) :  -137.8877 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       137.89  |proj g|=     0.028588\n",
      "At iterate     1  f =       137.89  |proj g|=      0.028528\n",
      "At iterate     2  f =       137.79  |proj g|=      0.047763\n",
      "At iterate     3  f =       137.72  |proj g|=      0.062862\n",
      "At iterate     4  f =       137.68  |proj g|=      0.019356\n",
      "At iterate     5  f =       137.66  |proj g|=     0.0055994\n",
      "At iterate     6  f =       137.66  |proj g|=     0.0011462\n",
      "At iterate     7  f =       137.66  |proj g|=    0.00014561\n",
      "At iterate     8  f =       137.66  |proj g|=    2.5938e-05\n",
      "At iterate     9  f =       137.66  |proj g|=    3.7683e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.7683e-07\n",
      "final function value 137.66\n",
      "\n",
      "F = 137.66\n",
      "final  value 137.659631 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5626 179.7343 \n",
      "  - best initial criterion value(s) :  -126.1677 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       126.17  |proj g|=     0.028228\n",
      "At iterate     1  f =       126.17  |proj g|=      0.027342\n",
      "At iterate     2  f =       126.13  |proj g|=      0.021167\n",
      "At iterate     3  f =       126.11  |proj g|=      0.026696\n",
      "At iterate     4  f =       125.94  |proj g|=      0.094969\n",
      "At iterate     5  f =       125.83  |proj g|=       0.07615\n",
      "At iterate     6  f =       125.78  |proj g|=     0.0039841\n",
      "At iterate     7  f =       125.78  |proj g|=    0.00046265\n",
      "At iterate     8  f =       125.78  |proj g|=    5.3706e-05\n",
      "At iterate     9  f =       125.78  |proj g|=    1.2045e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.2045e-06\n",
      "final function value 125.782\n",
      "\n",
      "F = 125.782\n",
      "final  value 125.781704 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.7372 179.7179 \n",
      "  - best initial criterion value(s) :  -140.5589 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       140.56  |proj g|=     0.065458\n",
      "At iterate     1  f =       140.56  |proj g|=      0.051223\n",
      "At iterate     2  f =       140.55  |proj g|=     0.0038679\n",
      "At iterate     3  f =       140.55  |proj g|=     0.0038393\n",
      "At iterate     4  f =       140.55  |proj g|=     0.0072984\n",
      "At iterate     5  f =       140.55  |proj g|=      0.015766\n",
      "At iterate     6  f =       140.55  |proj g|=      0.030021\n",
      "At iterate     7  f =       140.54  |proj g|=      0.049035\n",
      "At iterate     8  f =       140.53  |proj g|=      0.068876\n",
      "At iterate     9  f =       140.51  |proj g|=      0.069376\n",
      "At iterate    10  f =        140.5  |proj g|=      0.023856\n",
      "At iterate    11  f =        140.5  |proj g|=     0.0018026\n",
      "At iterate    12  f =        140.5  |proj g|=    4.3208e-05\n",
      "At iterate    13  f =        140.5  |proj g|=    1.3666e-05\n",
      "At iterate    14  f =        140.5  |proj g|=    1.3665e-05\n",
      "\n",
      "iterations 14\n",
      "function evaluations 26\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.36654e-05\n",
      "final function value 140.497\n",
      "\n",
      "F = 140.497\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 140.496753 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.5086 179.6567 \n",
      "  - best initial criterion value(s) :  -123.4341 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       123.43  |proj g|=     0.046974\n",
      "At iterate     1  f =       123.43  |proj g|=      0.046953\n",
      "At iterate     2  f =        122.9  |proj g|=      0.019429\n",
      "At iterate     3  f =       122.82  |proj g|=      0.026254\n",
      "At iterate     4  f =       122.77  |proj g|=      0.014593\n",
      "At iterate     5  f =       122.76  |proj g|=     0.0060548\n",
      "At iterate     6  f =       122.76  |proj g|=    0.00085026\n",
      "At iterate     7  f =       122.76  |proj g|=    6.0487e-05\n",
      "At iterate     8  f =       122.76  |proj g|=    4.6627e-07\n",
      "At iterate     9  f =       122.76  |proj g|=    4.6627e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.66269e-07\n",
      "final function value 122.757\n",
      "\n",
      "F = 122.757\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 122.757150 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.6475 179.6834 \n",
      "  - best initial criterion value(s) :  -150.0272 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       150.03  |proj g|=      0.10544\n",
      "At iterate     1  f =       150.02  |proj g|=       0.10484\n",
      "At iterate     2  f =       148.83  |proj g|=       0.10549\n",
      "At iterate     3  f =       144.25  |proj g|=       0.11102\n",
      "At iterate     4  f =       144.13  |proj g|=      0.010617\n",
      "At iterate     5  f =       144.12  |proj g|=      0.013177\n",
      "At iterate     6  f =       144.12  |proj g|=     0.0017829\n",
      "At iterate     7  f =       144.12  |proj g|=    5.9616e-05\n",
      "At iterate     8  f =       144.12  |proj g|=    2.1008e-07\n",
      "\n",
      "iterations 8\n",
      "function evaluations 16\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.10081e-07\n",
      "final function value 144.121\n",
      "\n",
      "F = 144.121\n",
      "final  value 144.120502 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  179.7118 179.6069 \n",
      "  - best initial criterion value(s) :  -116.6665 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       116.67  |proj g|=     0.012517\n",
      "At iterate     1  f =       116.67  |proj g|=      0.012509\n",
      "At iterate     2  f =       116.51  |proj g|=     0.0049328\n",
      "At iterate     3  f =        116.5  |proj g|=     0.0034852\n",
      "At iterate     4  f =       116.49  |proj g|=    0.00044669\n",
      "At iterate     5  f =       116.49  |proj g|=     6.527e-05\n",
      "At iterate     6  f =       116.49  |proj g|=    3.5515e-05\n",
      "At iterate     7  f =       116.49  |proj g|=    5.6481e-06\n",
      "At iterate     8  f =       116.49  |proj g|=    6.2585e-09\n",
      "\n",
      "iterations 8\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.25854e-09\n",
      "final function value 116.489\n",
      "\n",
      "F = 116.489\n",
      "final  value 116.488563 \n",
      "converged\n",
      "[1]  1.000000e+02 -5.357195e-17\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1703 196.2499 \n",
      "  - best initial criterion value(s) :  -156.4296 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       156.43  |proj g|=      0.20957\n",
      "At iterate     1  f =       156.38  |proj g|=       0.21134\n",
      "ys=-3.399e-04  -gs= 4.889e-02, BFGS update SKIPPED\n",
      "At iterate     2  f =       155.35  |proj g|=        0.1809\n",
      "At iterate     3  f =       154.75  |proj g|=      0.082811\n",
      "At iterate     4  f =       153.69  |proj g|=       0.55545\n",
      "At iterate     5  f =       153.11  |proj g|=       0.26939\n",
      "At iterate     6  f =        152.8  |proj g|=      0.041289\n",
      "At iterate     7  f =       152.77  |proj g|=      0.017795\n",
      "At iterate     8  f =       152.77  |proj g|=     0.0034985\n",
      "At iterate     9  f =       152.77  |proj g|=      0.001049\n",
      "At iterate    10  f =       152.77  |proj g|=    7.9974e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    11  f =       152.77  |proj g|=    7.9969e-06\n",
      "\n",
      "iterations 11\n",
      "function evaluations 46\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 7.99685e-06\n",
      "final function value 152.766\n",
      "\n",
      "F = 152.766\n",
      "final  value 152.765736 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3802 196.3559 \n",
      "  - best initial criterion value(s) :  -129.9619 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       129.96  |proj g|=     0.031227\n",
      "At iterate     1  f =       129.96  |proj g|=      0.031178\n",
      "At iterate     2  f =       129.48  |proj g|=      0.023444\n",
      "At iterate     3  f =       129.13  |proj g|=      0.018226\n",
      "At iterate     4  f =       129.12  |proj g|=     0.0016669\n",
      "At iterate     5  f =       129.12  |proj g|=    0.00089168\n",
      "At iterate     6  f =       129.12  |proj g|=     1.662e-05\n",
      "At iterate     7  f =       129.12  |proj g|=    1.6191e-05\n",
      "\n",
      "iterations 7\n",
      "function evaluations 17\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.61905e-05\n",
      "final function value 129.118\n",
      "\n",
      "F = 129.118\n",
      "final  value 129.117890 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3087 196.0913 \n",
      "  - best initial criterion value(s) :  -127.847 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       127.85  |proj g|=     0.034204\n",
      "At iterate     1  f =       127.85  |proj g|=      0.034153\n",
      "At iterate     2  f =        127.1  |proj g|=      0.041852\n",
      "At iterate     3  f =       126.85  |proj g|=       0.04547\n",
      "At iterate     4  f =       126.52  |proj g|=      0.031226\n",
      "At iterate     5  f =       126.43  |proj g|=      0.010961\n",
      "At iterate     6  f =       126.41  |proj g|=     0.0026987\n",
      "At iterate     7  f =       126.41  |proj g|=    0.00036576\n",
      "At iterate     8  f =       126.41  |proj g|=    1.1509e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 126.410004 \n",
      "stopped after 8 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2816 196.2511 \n",
      "  - best initial criterion value(s) :  -124.8863 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       124.89  |proj g|=     0.084545\n",
      "At iterate     1  f =       124.88  |proj g|=      0.083984\n",
      "At iterate     2  f =       123.33  |proj g|=      0.019705\n",
      "At iterate     3  f =       123.31  |proj g|=      0.018553\n",
      "At iterate     4  f =       123.28  |proj g|=     0.0088938\n",
      "At iterate     5  f =       123.26  |proj g|=     0.0039468\n",
      "At iterate     6  f =       123.26  |proj g|=    0.00054494\n",
      "At iterate     7  f =       123.26  |proj g|=    5.3685e-06\n",
      "At iterate     8  f =       123.26  |proj g|=    6.6624e-08\n",
      "At iterate     9  f =       123.26  |proj g|=    5.1216e-08\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 123.257908 \n",
      "stopped after 9 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.303 196.1859 \n",
      "  - best initial criterion value(s) :  -134.4878 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       134.49  |proj g|=     0.065697\n",
      "At iterate     1  f =       134.48  |proj g|=      0.065566\n",
      "At iterate     2  f =       133.31  |proj g|=      0.038733\n",
      "At iterate     3  f =       133.16  |proj g|=      0.013905\n",
      "At iterate     4  f =       132.74  |proj g|=      0.016564\n",
      "At iterate     5  f =       132.45  |proj g|=     0.0017246\n",
      "At iterate     6  f =       132.45  |proj g|=    3.2337e-06\n",
      "At iterate     7  f =       132.45  |proj g|=    3.2338e-06\n",
      "\n",
      "iterations 7\n",
      "function evaluations 18\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.23379e-06\n",
      "final function value 132.451\n",
      "\n",
      "F = 132.451\n",
      "final  value 132.451495 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2174 196.2115 \n",
      "  - best initial criterion value(s) :  -146.4375 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       146.44  |proj g|=      0.17975\n",
      "At iterate     1  f =       146.41  |proj g|=       0.17809\n",
      "At iterate     2  f =       145.74  |proj g|=      0.089992\n",
      "At iterate     3  f =       145.63  |proj g|=     0.0086917\n",
      "At iterate     4  f =       145.63  |proj g|=     0.0091808\n",
      "At iterate     5  f =       145.63  |proj g|=      0.011843\n",
      "At iterate     6  f =       145.62  |proj g|=      0.014703\n",
      "At iterate     7  f =       145.62  |proj g|=     0.0010824\n",
      "At iterate     8  f =       145.62  |proj g|=    4.5328e-05\n",
      "At iterate     9  f =       145.62  |proj g|=    2.7696e-08\n",
      "\n",
      "iterations 9\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.76957e-08\n",
      "final function value 145.616\n",
      "\n",
      "F = 145.616\n",
      "final  value 145.615803 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3146 196.2724 \n",
      "  - best initial criterion value(s) :  -140.5432 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       140.54  |proj g|=      0.12401\n",
      "At iterate     1  f =       140.53  |proj g|=       0.12246\n",
      "At iterate     2  f =       140.12  |proj g|=       0.02632\n",
      "At iterate     3  f =       140.11  |proj g|=     0.0071825\n",
      "At iterate     4  f =       140.11  |proj g|=      0.007125\n",
      "At iterate     5  f =       140.09  |proj g|=      0.025938\n",
      "At iterate     6  f =       140.05  |proj g|=      0.062253\n",
      "At iterate     7  f =       139.86  |proj g|=       0.20784\n",
      "At iterate     8  f =       139.78  |proj g|=       0.24654\n",
      "At iterate     9  f =       139.66  |proj g|=       0.20852\n",
      "At iterate    10  f =        139.4  |proj g|=      0.030067\n",
      "At iterate    11  f =        139.4  |proj g|=     0.0051527\n",
      "At iterate    12  f =        139.4  |proj g|=    0.00014834\n",
      "At iterate    13  f =        139.4  |proj g|=    1.9351e-05\n",
      "At iterate    14  f =        139.4  |proj g|=    1.2084e-06\n",
      "\n",
      "iterations 14\n",
      "function evaluations 21\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.20836e-06\n",
      "final function value 139.398\n",
      "\n",
      "F = 139.398\n",
      "final  value 139.397938 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2787 196.3241 \n",
      "  - best initial criterion value(s) :  -120.4409 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       120.44  |proj g|=     0.078601\n",
      "At iterate     1  f =       120.43  |proj g|=      0.077183\n",
      "At iterate     2  f =       120.22  |proj g|=      0.010784\n",
      "At iterate     3  f =       120.21  |proj g|=     0.0046534\n",
      "At iterate     4  f =       120.21  |proj g|=      0.002914\n",
      "At iterate     5  f =       120.21  |proj g|=     0.0037224\n",
      "At iterate     6  f =       120.21  |proj g|=     0.0016544\n",
      "At iterate     7  f =       120.21  |proj g|=    0.00015361\n",
      "At iterate     8  f =       120.21  |proj g|=    5.6737e-06\n",
      "At iterate     9  f =       120.21  |proj g|=     1.269e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.26895e-07\n",
      "final function value 120.208\n",
      "\n",
      "F = 120.208\n",
      "final  value 120.207697 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1924 196.2657 \n",
      "  - best initial criterion value(s) :  -124.4263 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       124.43  |proj g|=     0.018691\n",
      "At iterate     1  f =       124.43  |proj g|=      0.018384\n",
      "At iterate     2  f =       124.41  |proj g|=     0.0074031\n",
      "At iterate     3  f =        124.4  |proj g|=     0.0068941\n",
      "At iterate     4  f =       124.38  |proj g|=      0.015285\n",
      "At iterate     5  f =       124.36  |proj g|=      0.015266\n",
      "At iterate     6  f =       124.35  |proj g|=     0.0010138\n",
      "At iterate     7  f =       124.35  |proj g|=     7.077e-05\n",
      "At iterate     8  f =       124.35  |proj g|=    1.0335e-06\n",
      "At iterate     9  f =       124.35  |proj g|=    9.6028e-08\n",
      "\n",
      "iterations 9\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 9.60275e-08\n",
      "final function value 124.348\n",
      "\n",
      "F = 124.348\n",
      "final  value 124.348319 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.33 196.1962 \n",
      "  - best initial criterion value(s) :  -140.9283 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       140.93  |proj g|=      0.24757\n",
      "At iterate     1  f =       140.87  |proj g|=       0.22025\n",
      "At iterate     2  f =       140.61  |proj g|=      0.038982\n",
      "At iterate     3  f =        140.6  |proj g|=      0.019399\n",
      "At iterate     4  f =       140.59  |proj g|=      0.019081\n",
      "At iterate     5  f =       140.57  |proj g|=      0.035464\n",
      "At iterate     6  f =       140.53  |proj g|=      0.069346\n",
      "At iterate     7  f =       140.46  |proj g|=       0.10404\n",
      "At iterate     8  f =       140.38  |proj g|=      0.096061\n",
      "At iterate     9  f =       140.33  |proj g|=      0.036731\n",
      "At iterate    10  f =       140.32  |proj g|=     0.0047903\n",
      "At iterate    11  f =       140.32  |proj g|=     0.0005098\n",
      "At iterate    12  f =       140.32  |proj g|=    0.00011705\n",
      "At iterate    13  f =       140.32  |proj g|=    4.1376e-07\n",
      "\n",
      "iterations 13\n",
      "function evaluations 14\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.13764e-07\n",
      "final function value 140.319\n",
      "\n",
      "F = 140.319\n",
      "final  value 140.318717 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2646 196.2655 \n",
      "  - best initial criterion value(s) :  -122.0071 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       122.01  |proj g|=     0.005509\n",
      "At iterate     1  f =       122.01  |proj g|=     0.0055024\n",
      "At iterate     2  f =       121.99  |proj g|=    0.00097642\n",
      "At iterate     3  f =       121.99  |proj g|=     0.0009265\n",
      "At iterate     4  f =       121.99  |proj g|=    0.00036517\n",
      "At iterate     5  f =       121.99  |proj g|=    9.5724e-06\n",
      "At iterate     6  f =       121.99  |proj g|=    7.1678e-07\n",
      "\n",
      "iterations 6\n",
      "function evaluations 7\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 7.16783e-07\n",
      "final function value 121.988\n",
      "\n",
      "F = 121.988\n",
      "final  value 121.988376 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.0706 196.2979 \n",
      "  - best initial criterion value(s) :  -141.3745 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       141.37  |proj g|=       1.0404\n",
      "At iterate     1  f =       140.42  |proj g|=       0.79877\n",
      "At iterate     2  f =       138.74  |proj g|=       0.23259\n",
      "At iterate     3  f =       138.52  |proj g|=      0.088974\n",
      "At iterate     4  f =       138.48  |proj g|=      0.019722\n",
      "At iterate     5  f =       138.47  |proj g|=      0.002317\n",
      "At iterate     6  f =       138.47  |proj g|=     0.0019769\n",
      "At iterate     7  f =       138.47  |proj g|=     0.0019822\n",
      "At iterate     8  f =       138.47  |proj g|=     0.0055651\n",
      "At iterate     9  f =       138.47  |proj g|=      0.010782\n",
      "At iterate    10  f =       138.47  |proj g|=      0.019047\n",
      "At iterate    11  f =       138.46  |proj g|=       0.03003\n",
      "At iterate    12  f =       138.45  |proj g|=      0.041757\n",
      "At iterate    13  f =       138.44  |proj g|=      0.031898\n",
      "At iterate    14  f =       138.43  |proj g|=     0.0020688\n",
      "At iterate    15  f =       138.43  |proj g|=    0.00012737\n",
      "At iterate    16  f =       138.43  |proj g|=    4.6399e-07\n",
      "\n",
      "iterations 16\n",
      "function evaluations 17\n",
      "segments explored during Cauchy searches 16\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 4.63991e-07\n",
      "final function value 138.431\n",
      "\n",
      "F = 138.431\n",
      "final  value 138.431219 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.381 196.4 \n",
      "  - best initial criterion value(s) :  -139.0668 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       139.07  |proj g|=      0.13686\n",
      "At iterate     1  f =       139.03  |proj g|=       0.13603\n",
      "At iterate     2  f =       137.68  |proj g|=      0.019201\n",
      "At iterate     3  f =       137.65  |proj g|=      0.020673\n",
      "At iterate     4  f =       137.63  |proj g|=      0.022479\n",
      "At iterate     5  f =       137.58  |proj g|=      0.011979\n",
      "At iterate     6  f =       137.57  |proj g|=      0.001024\n",
      "At iterate     7  f =       137.57  |proj g|=    0.00017757\n",
      "At iterate     8  f =       137.57  |proj g|=    2.5538e-05\n",
      "At iterate     9  f =       137.57  |proj g|=    5.0785e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.07854e-06\n",
      "final function value 137.569\n",
      "\n",
      "F = 137.569\n",
      "final  value 137.569041 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.0938 196.3104 \n",
      "  - best initial criterion value(s) :  -137.6572 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       137.66  |proj g|=      0.11077\n",
      "At iterate     1  f =       137.65  |proj g|=       0.10906\n",
      "At iterate     2  f =       137.41  |proj g|=      0.040074\n",
      "At iterate     3  f =       137.39  |proj g|=      0.024102\n",
      "At iterate     4  f =       137.39  |proj g|=     0.0038384\n",
      "At iterate     5  f =       137.39  |proj g|=     0.0036694\n",
      "At iterate     6  f =       137.39  |proj g|=     0.0047586\n",
      "At iterate     7  f =       137.38  |proj g|=     0.0037808\n",
      "At iterate     8  f =       137.38  |proj g|=    0.00039783\n",
      "At iterate     9  f =       137.38  |proj g|=    1.6655e-05\n",
      "At iterate    10  f =       137.38  |proj g|=    2.3172e-07\n",
      "\n",
      "iterations 10\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.31718e-07\n",
      "final function value 137.384\n",
      "\n",
      "F = 137.384\n",
      "final  value 137.383947 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2281 196.3492 \n",
      "  - best initial criterion value(s) :  -129.4212 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       129.42  |proj g|=     0.054393\n",
      "At iterate     1  f =       129.42  |proj g|=      0.053824\n",
      "At iterate     2  f =       129.23  |proj g|=      0.012256\n",
      "At iterate     3  f =       129.19  |proj g|=      0.011015\n",
      "At iterate     4  f =       129.14  |proj g|=      0.009366\n",
      "At iterate     5  f =       129.14  |proj g|=     0.0017837\n",
      "At iterate     6  f =       129.14  |proj g|=    5.4373e-05\n",
      "At iterate     7  f =       129.14  |proj g|=    5.4298e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 129.137247 \n",
      "stopped after 7 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2573 196.233 \n",
      "  - best initial criterion value(s) :  -119.6771 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       119.68  |proj g|=     0.041214\n",
      "At iterate     1  f =       119.67  |proj g|=      0.040931\n",
      "At iterate     2  f =       119.49  |proj g|=     0.0033466\n",
      "At iterate     3  f =       119.49  |proj g|=      0.003355\n",
      "At iterate     4  f =       119.47  |proj g|=     0.0025781\n",
      "At iterate     5  f =       119.47  |proj g|=    0.00019928\n",
      "At iterate     6  f =       119.47  |proj g|=    2.6323e-05\n",
      "At iterate     7  f =       119.47  |proj g|=    5.1046e-06\n",
      "\n",
      "iterations 7\n",
      "function evaluations 8\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.10459e-06\n",
      "final function value 119.468\n",
      "\n",
      "F = 119.468\n",
      "final  value 119.468000 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2288 196.2614 \n",
      "  - best initial criterion value(s) :  -143.5568 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       143.56  |proj g|=      0.20166\n",
      "At iterate     1  f =       143.52  |proj g|=       0.19768\n",
      "At iterate     2  f =       143.03  |proj g|=      0.054006\n",
      "At iterate     3  f =       143.01  |proj g|=     0.0056389\n",
      "At iterate     4  f =       143.01  |proj g|=     0.0055648\n",
      "At iterate     5  f =       143.01  |proj g|=     0.0081536\n",
      "At iterate     6  f =       143.01  |proj g|=      0.019674\n",
      "At iterate     7  f =          143  |proj g|=      0.031653\n",
      "At iterate     8  f =       142.99  |proj g|=      0.036293\n",
      "At iterate     9  f =       142.97  |proj g|=      0.013654\n",
      "At iterate    10  f =       142.97  |proj g|=     0.0018657\n",
      "At iterate    11  f =       142.97  |proj g|=    6.1527e-05\n",
      "At iterate    12  f =       142.97  |proj g|=    3.7372e-06\n",
      "\n",
      "iterations 12\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.73721e-06\n",
      "final function value 142.971\n",
      "\n",
      "F = 142.971\n",
      "final  value 142.970901 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2055 196.1676 \n",
      "  - best initial criterion value(s) :  -111.2921 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       111.29  |proj g|=     0.014358\n",
      "At iterate     1  f =       111.29  |proj g|=      0.014312\n",
      "At iterate     2  f =       111.25  |proj g|=     0.0017254\n",
      "At iterate     3  f =       111.24  |proj g|=      0.002713\n",
      "At iterate     4  f =       111.23  |proj g|=     0.0017488\n",
      "At iterate     5  f =       111.23  |proj g|=    4.5097e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 111.231008 \n",
      "stopped after 5 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.247 196.3909 \n",
      "  - best initial criterion value(s) :  -126.4066 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       126.41  |proj g|=     0.011929\n",
      "At iterate     1  f =       126.41  |proj g|=      0.011733\n",
      "At iterate     2  f =        126.4  |proj g|=    0.00058348\n",
      "At iterate     3  f =        126.4  |proj g|=     0.0001247\n",
      "At iterate     4  f =        126.4  |proj g|=    8.3651e-05\n",
      "At iterate     5  f =        126.4  |proj g|=    1.8438e-07\n",
      "At iterate     6  f =        126.4  |proj g|=    1.8438e-07\n",
      "\n",
      "iterations 6\n",
      "function evaluations 26\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.84377e-07\n",
      "final function value 126.402\n",
      "\n",
      "F = 126.402\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 126.402313 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2278 196.3365 \n",
      "  - best initial criterion value(s) :  -120.0821 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       120.08  |proj g|=     0.034538\n",
      "At iterate     1  f =       120.08  |proj g|=      0.034524\n",
      "At iterate     2  f =        119.2  |proj g|=      0.031512\n",
      "At iterate     3  f =        118.5  |proj g|=     0.0089319\n",
      "Nonpositive definiteness in Cholesky factorization in formk;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     4  f =       118.49  |proj g|=     0.0080104\n",
      "At iterate     5  f =       118.47  |proj g|=      0.010906\n",
      "At iterate     6  f =       118.46  |proj g|=     0.0077598\n",
      "At iterate     7  f =       118.46  |proj g|=    0.00044042\n",
      "At iterate     8  f =       118.46  |proj g|=    2.4828e-05\n",
      "At iterate     9  f =       118.46  |proj g|=    2.3754e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 19\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.37537e-06\n",
      "final function value 118.461\n",
      "\n",
      "F = 118.461\n",
      "final  value 118.460566 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1573 196.3621 \n",
      "  - best initial criterion value(s) :  -115.0438 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       115.04  |proj g|=    0.0037714\n",
      "At iterate     1  f =       115.04  |proj g|=     0.0037691\n",
      "At iterate     2  f =          115  |proj g|=     0.0013964\n",
      "At iterate     3  f =          115  |proj g|=    0.00024981\n",
      "At iterate     4  f =          115  |proj g|=    5.8912e-06\n",
      "At iterate     5  f =          115  |proj g|=    2.1986e-08\n",
      "At iterate     6  f =          115  |proj g|=    9.1533e-08\n",
      "ys=-5.391e-20  -gs= 1.704e-20, BFGS update SKIPPED\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 114.995117 \n",
      "stopped after 6 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2729 196.2102 \n",
      "  - best initial criterion value(s) :  -145.1934 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       145.19  |proj g|=      0.22709\n",
      "At iterate     1  f =       145.14  |proj g|=       0.21795\n",
      "At iterate     2  f =       144.81  |proj g|=      0.034744\n",
      "At iterate     3  f =        144.8  |proj g|=      0.025169\n",
      "At iterate     4  f =        144.8  |proj g|=     0.0079678\n",
      "At iterate     5  f =        144.8  |proj g|=     0.0079196\n",
      "At iterate     6  f =       144.78  |proj g|=      0.036065\n",
      "At iterate     7  f =       144.75  |proj g|=      0.065873\n",
      "At iterate     8  f =       144.69  |proj g|=      0.083629\n",
      "At iterate     9  f =       144.61  |proj g|=      0.064129\n",
      "At iterate    10  f =       144.55  |proj g|=     0.0034537\n",
      "At iterate    11  f =       144.53  |proj g|=      0.021983\n",
      "At iterate    12  f =       144.51  |proj g|=      0.002693\n",
      "At iterate    13  f =       144.51  |proj g|=    0.00034863\n",
      "At iterate    14  f =       144.51  |proj g|=    9.6165e-07\n",
      "At iterate    15  f =       144.51  |proj g|=    7.8995e-10\n",
      "\n",
      "iterations 15\n",
      "function evaluations 18\n",
      "segments explored during Cauchy searches 15\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 7.8995e-10\n",
      "final function value 144.514\n",
      "\n",
      "F = 144.514\n",
      "final  value 144.514071 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2655 196.3671 \n",
      "  - best initial criterion value(s) :  -144.8646 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       144.86  |proj g|=      0.12676\n",
      "At iterate     1  f =       144.85  |proj g|=       0.11823\n",
      "At iterate     2  f =       144.77  |proj g|=      0.042125\n",
      "At iterate     3  f =       144.76  |proj g|=     0.0084826\n",
      "At iterate     4  f =       144.76  |proj g|=    0.00046602\n",
      "At iterate     5  f =       144.76  |proj g|=    0.00035244\n",
      "At iterate     6  f =       144.76  |proj g|=    0.00035217\n",
      "At iterate     7  f =       144.76  |proj g|=     0.0010343\n",
      "At iterate     8  f =       144.76  |proj g|=     0.0020527\n",
      "At iterate     9  f =       144.76  |proj g|=     0.0038501\n",
      "At iterate    10  f =       144.76  |proj g|=     0.0067336\n",
      "At iterate    11  f =       144.76  |proj g|=      0.011704\n",
      "At iterate    12  f =       144.76  |proj g|=      0.020968\n",
      "At iterate    13  f =       144.76  |proj g|=      0.043108\n",
      "At iterate    14  f =       144.75  |proj g|=      0.071063\n",
      "At iterate    15  f =       144.75  |proj g|=      0.081662\n",
      "At iterate    16  f =       144.74  |proj g|=      0.067171\n",
      "At iterate    17  f =       144.72  |proj g|=      0.010915\n",
      "At iterate    18  f =       144.72  |proj g|=     0.0070055\n",
      "At iterate    19  f =       144.72  |proj g|=    0.00033525\n",
      "At iterate    20  f =       144.72  |proj g|=    3.5573e-06\n",
      "At iterate    21  f =       144.72  |proj g|=    1.1443e-06\n",
      "\n",
      "iterations 21\n",
      "function evaluations 25\n",
      "segments explored during Cauchy searches 21\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.14427e-06\n",
      "final function value 144.717\n",
      "\n",
      "F = 144.717\n",
      "final  value 144.716888 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1443 196.2166 \n",
      "  - best initial criterion value(s) :  -106.7689 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       106.77  |proj g|=     0.034061\n",
      "At iterate     1  f =       106.77  |proj g|=      0.033908\n",
      "At iterate     2  f =       106.44  |proj g|=      0.011172\n",
      "At iterate     3  f =       106.38  |proj g|=     0.0058977\n",
      "At iterate     4  f =       106.35  |proj g|=     0.0074191\n",
      "At iterate     5  f =       106.33  |proj g|=     0.0044341\n",
      "At iterate     6  f =       106.33  |proj g|=    0.00055997\n",
      "At iterate     7  f =       106.33  |proj g|=    4.0528e-05\n",
      "At iterate     8  f =       106.33  |proj g|=    2.8807e-07\n",
      "At iterate     9  f =       106.33  |proj g|=    1.7379e-08\n",
      "At iterate    10  f =       106.33  |proj g|=    2.3683e-08\n",
      "ys=-2.311e-19  -gs= 3.439e-19, BFGS update SKIPPED\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 106.325338 \n",
      "stopped after 10 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.4104 196.1953 \n",
      "  - best initial criterion value(s) :  -149.2853 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       149.29  |proj g|=      0.40646\n",
      "At iterate     1  f =       149.12  |proj g|=       0.39882\n",
      "At iterate     2  f =       147.98  |proj g|=       0.13749\n",
      "At iterate     3  f =       147.92  |proj g|=     0.0058735\n",
      "At iterate     4  f =       147.92  |proj g|=     0.0021961\n",
      "At iterate     5  f =       147.63  |proj g|=        0.2811\n",
      "At iterate     6  f =       147.63  |proj g|=       0.29756\n",
      "At iterate     7  f =       147.36  |proj g|=       0.32887\n",
      "At iterate     8  f =          147  |proj g|=       0.28716\n",
      "At iterate     9  f =        145.9  |proj g|=      0.057319\n",
      "At iterate    10  f =       145.79  |proj g|=      0.030206\n",
      "At iterate    11  f =       145.73  |proj g|=      0.019048\n",
      "At iterate    12  f =       145.69  |proj g|=       0.03988\n",
      "At iterate    13  f =       145.64  |proj g|=      0.009694\n",
      "At iterate    14  f =       145.61  |proj g|=      0.065138\n",
      "At iterate    15  f =       145.58  |proj g|=     0.0035041\n",
      "At iterate    16  f =       145.57  |proj g|=     0.0020327\n",
      "At iterate    17  f =       145.56  |proj g|=     0.0095856\n",
      "At iterate    18  f =       145.55  |proj g|=     0.0039119\n",
      "At iterate    19  f =       145.55  |proj g|=     0.0010828\n",
      "At iterate    20  f =       145.55  |proj g|=    0.00033542\n",
      "At iterate    21  f =       145.55  |proj g|=    0.00056322\n",
      "At iterate    22  f =       145.55  |proj g|=    1.9872e-05\n",
      "At iterate    23  f =       145.55  |proj g|=    2.6959e-07\n",
      "\n",
      "iterations 23\n",
      "function evaluations 46\n",
      "segments explored during Cauchy searches 24\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.69595e-07\n",
      "final function value 145.553\n",
      "\n",
      "F = 145.553\n",
      "final  value 145.552588 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3597 196.1757 \n",
      "  - best initial criterion value(s) :  -131.1519 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       131.15  |proj g|=     0.010854\n",
      "At iterate     1  f =       131.15  |proj g|=      0.010843\n",
      "At iterate     2  f =       130.82  |proj g|=      0.034969\n",
      "At iterate     3  f =       130.59  |proj g|=      0.031971\n",
      "At iterate     4  f =       130.35  |proj g|=     0.0074929\n",
      "At iterate     5  f =       130.34  |proj g|=     0.0017138\n",
      "At iterate     6  f =       130.34  |proj g|=     0.0013844\n",
      "At iterate     7  f =       130.34  |proj g|=    3.2766e-05\n",
      "At iterate     8  f =       130.34  |proj g|=    3.8284e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.82845e-06\n",
      "final function value 130.344\n",
      "\n",
      "F = 130.344\n",
      "final  value 130.344036 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1954 196.359 \n",
      "  - best initial criterion value(s) :  -132.5755 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       132.58  |proj g|=     0.082578\n",
      "At iterate     1  f =       132.57  |proj g|=      0.082133\n",
      "At iterate     2  f =       131.78  |proj g|=      0.027627\n",
      "At iterate     3  f =        131.7  |proj g|=      0.031263\n",
      "At iterate     4  f =       131.56  |proj g|=      0.022045\n",
      "At iterate     5  f =       131.54  |proj g|=     0.0035152\n",
      "At iterate     6  f =       131.54  |proj g|=    0.00076322\n",
      "At iterate     7  f =       131.54  |proj g|=    0.00020282\n",
      "At iterate     8  f =       131.54  |proj g|=     3.598e-06\n",
      "At iterate     9  f =       131.54  |proj g|=    1.9305e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.93054e-07\n",
      "final function value 131.536\n",
      "\n",
      "F = 131.536\n",
      "final  value 131.535667 \n",
      "converged\n",
      "[1] 97.748362  2.251638\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2214 196.2221 \n",
      "  - best initial criterion value(s) :  -135.7509 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       135.75  |proj g|=     0.016574\n",
      "At iterate     1  f =       135.75  |proj g|=      0.016239\n",
      "At iterate     2  f =       135.74  |proj g|=     0.0022624\n",
      "At iterate     3  f =       135.74  |proj g|=     0.0023755\n",
      "At iterate     4  f =       135.74  |proj g|=    0.00047031\n",
      "At iterate     5  f =       135.74  |proj g|=    5.5669e-06\n",
      "At iterate     6  f =       135.74  |proj g|=     5.512e-06\n",
      "\n",
      "iterations 6\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.512e-06\n",
      "final function value 135.74\n",
      "\n",
      "F = 135.74\n",
      "final  value 135.740488 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3403 196.2903 \n",
      "  - best initial criterion value(s) :  -118.8849 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       118.88  |proj g|=     0.055481\n",
      "At iterate     1  f =       118.88  |proj g|=      0.054458\n",
      "At iterate     2  f =       118.75  |proj g|=      0.014457\n",
      "At iterate     3  f =       118.73  |proj g|=      0.011476\n",
      "At iterate     4  f =        118.7  |proj g|=       0.01629\n",
      "At iterate     5  f =       118.66  |proj g|=      0.016933\n",
      "At iterate     6  f =       118.65  |proj g|=     0.0034031\n",
      "At iterate     7  f =       118.65  |proj g|=    0.00043983\n",
      "At iterate     8  f =       118.65  |proj g|=    9.6802e-06\n",
      "At iterate     9  f =       118.65  |proj g|=    2.7674e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.76738e-07\n",
      "final function value 118.648\n",
      "\n",
      "F = 118.648\n",
      "final  value 118.647516 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2861 196.0921 \n",
      "  - best initial criterion value(s) :  -161.0068 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       161.01  |proj g|=      0.48221\n",
      "At iterate     1  f =       160.81  |proj g|=        0.3185\n",
      "At iterate     2  f =       160.71  |proj g|=        0.1188\n",
      "At iterate     3  f =       160.69  |proj g|=      0.016561\n",
      "At iterate     4  f =       160.69  |proj g|=    0.00068219\n",
      "At iterate     5  f =       160.69  |proj g|=    0.00029162\n",
      "At iterate     6  f =       160.69  |proj g|=    0.00029164\n",
      "\n",
      "iterations 6\n",
      "function evaluations 7\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 0.000291637\n",
      "final function value 160.693\n",
      "\n",
      "F = 160.693\n",
      "final  value 160.692568 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.4129 196.2344 \n",
      "  - best initial criterion value(s) :  -142.3134 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       142.31  |proj g|=     0.040327\n",
      "At iterate     1  f =       142.31  |proj g|=      0.040163\n",
      "At iterate     2  f =       142.06  |proj g|=     0.0071581\n",
      "At iterate     3  f =       142.03  |proj g|=      0.008493\n",
      "At iterate     4  f =       141.93  |proj g|=     0.0083721\n",
      "At iterate     5  f =       141.89  |proj g|=     0.0022655\n",
      "At iterate     6  f =       141.89  |proj g|=    0.00041589\n",
      "At iterate     7  f =       141.89  |proj g|=    3.1377e-05\n",
      "At iterate     8  f =       141.89  |proj g|=    2.0118e-06\n",
      "At iterate     9  f =       141.89  |proj g|=     2.044e-06\n",
      "ys=-8.665e-15  -gs= 1.602e-13, BFGS update SKIPPED\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    10  f =       141.89  |proj g|=     2.044e-06\n",
      "\n",
      "iterations 10\n",
      "function evaluations 65\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.04401e-06\n",
      "final function value 141.887\n",
      "\n",
      "F = 141.887\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 141.887368 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2668 196.2679 \n",
      "  - best initial criterion value(s) :  -138.1445 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       138.14  |proj g|=     0.025247\n",
      "At iterate     1  f =       138.14  |proj g|=       0.02521\n",
      "At iterate     2  f =       137.95  |proj g|=      0.011821\n",
      "At iterate     3  f =       137.93  |proj g|=     0.0028168\n",
      "At iterate     4  f =       137.92  |proj g|=     0.0014029\n",
      "At iterate     5  f =       137.92  |proj g|=    0.00015015\n",
      "At iterate     6  f =       137.92  |proj g|=    1.8735e-05\n",
      "At iterate     7  f =       137.92  |proj g|=     4.326e-07\n",
      "\n",
      "iterations 7\n",
      "function evaluations 10\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.32598e-07\n",
      "final function value 137.924\n",
      "\n",
      "F = 137.924\n",
      "final  value 137.924197 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.352 196.3903 \n",
      "  - best initial criterion value(s) :  -143.0613 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       143.06  |proj g|=     0.033644\n",
      "At iterate     1  f =       143.06  |proj g|=      0.033524\n",
      "At iterate     2  f =       142.96  |proj g|=      0.078188\n",
      "At iterate     3  f =       142.84  |proj g|=      0.033779\n",
      "At iterate     4  f =       142.83  |proj g|=     0.0038373\n",
      "At iterate     5  f =       142.83  |proj g|=    0.00049827\n",
      "At iterate     6  f =       142.83  |proj g|=    0.00057798\n",
      "At iterate     7  f =       142.83  |proj g|=    0.00010601\n",
      "At iterate     8  f =       142.83  |proj g|=      8.79e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 8.79002e-06\n",
      "final function value 142.827\n",
      "\n",
      "F = 142.827\n",
      "final  value 142.826597 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1497 196.2616 \n",
      "  - best initial criterion value(s) :  -134.1647 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       134.16  |proj g|=     0.071411\n",
      "At iterate     1  f =       134.16  |proj g|=      0.071396\n",
      "At iterate     2  f =       133.54  |proj g|=      0.035187\n",
      "At iterate     3  f =        133.4  |proj g|=      0.036192\n",
      "At iterate     4  f =       133.27  |proj g|=       0.01239\n",
      "At iterate     5  f =       133.26  |proj g|=     0.0020626\n",
      "At iterate     6  f =       133.26  |proj g|=    0.00034179\n",
      "At iterate     7  f =       133.26  |proj g|=    0.00011484\n",
      "At iterate     8  f =       133.26  |proj g|=    2.3416e-07\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     9  f =       133.26  |proj g|=    2.3349e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 51\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.33487e-07\n",
      "final function value 133.262\n",
      "\n",
      "F = 133.262\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 133.261917 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1388 196.2712 \n",
      "  - best initial criterion value(s) :  -136.9129 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       136.91  |proj g|=     0.009184\n",
      "At iterate     1  f =       136.91  |proj g|=     0.0091788\n",
      "At iterate     2  f =       136.89  |proj g|=      0.008556\n",
      "At iterate     3  f =       136.88  |proj g|=      0.017411\n",
      "At iterate     4  f =       136.82  |proj g|=      0.037155\n",
      "At iterate     5  f =       136.74  |proj g|=      0.056503\n",
      "At iterate     6  f =       136.65  |proj g|=      0.052507\n",
      "At iterate     7  f =        136.6  |proj g|=      0.037839\n",
      "At iterate     8  f =       136.58  |proj g|=     0.0062588\n",
      "At iterate     9  f =       136.57  |proj g|=     0.0011293\n",
      "At iterate    10  f =       136.57  |proj g|=    0.00018247\n",
      "At iterate    11  f =       136.57  |proj g|=    1.5979e-06\n",
      "At iterate    12  f =       136.57  |proj g|=    1.1759e-06\n",
      "\n",
      "iterations 12\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.1759e-06\n",
      "final function value 136.575\n",
      "\n",
      "F = 136.575\n",
      "final  value 136.574586 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3572 196.36 \n",
      "  - best initial criterion value(s) :  -137.9825 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       137.98  |proj g|=      0.06574\n",
      "At iterate     1  f =       137.98  |proj g|=      0.065162\n",
      "At iterate     2  f =       137.65  |proj g|=      0.024655\n",
      "At iterate     3  f =       137.54  |proj g|=      0.010613\n",
      "At iterate     4  f =       137.52  |proj g|=      0.021227\n",
      "At iterate     5  f =       137.45  |proj g|=      0.063684\n",
      "At iterate     6  f =       137.44  |proj g|=      0.069731\n",
      "At iterate     7  f =        137.3  |proj g|=      0.070218\n",
      "At iterate     8  f =       136.81  |proj g|=       0.19678\n",
      "At iterate     9  f =       135.82  |proj g|=      0.077793\n",
      "At iterate    10  f =       135.06  |proj g|=      0.041814\n",
      "At iterate    11  f =       134.52  |proj g|=      0.010282\n",
      "At iterate    12  f =       134.14  |proj g|=    0.00067236\n",
      "At iterate    13  f =       134.14  |proj g|=    8.9135e-07\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    14  f =       134.14  |proj g|=    8.8839e-07\n",
      "\n",
      "iterations 14\n",
      "function evaluations 50\n",
      "segments explored during Cauchy searches 15\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 8.88393e-07\n",
      "final function value 134.139\n",
      "\n",
      "F = 134.139\n",
      "final  value 134.138873 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3832 196.2927 \n",
      "  - best initial criterion value(s) :  -138.237 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       138.24  |proj g|=     0.073767\n",
      "At iterate     1  f =       138.23  |proj g|=      0.073416\n",
      "At iterate     2  f =       137.56  |proj g|=      0.017578\n",
      "At iterate     3  f =       137.54  |proj g|=      0.010791\n",
      "At iterate     4  f =       137.53  |proj g|=     0.0048564\n",
      "At iterate     5  f =       137.53  |proj g|=     0.0012249\n",
      "At iterate     6  f =       137.53  |proj g|=    0.00024256\n",
      "At iterate     7  f =       137.53  |proj g|=    4.7042e-05\n",
      "At iterate     8  f =       137.53  |proj g|=     9.708e-08\n",
      "\n",
      "iterations 8\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 9.70802e-08\n",
      "final function value 137.527\n",
      "\n",
      "F = 137.527\n",
      "final  value 137.527465 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.0712 196.2896 \n",
      "  - best initial criterion value(s) :  -146.5706 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       146.57  |proj g|=      0.25051\n",
      "At iterate     1  f =       146.51  |proj g|=       0.21732\n",
      "At iterate     2  f =       146.31  |proj g|=       0.03355\n",
      "At iterate     3  f =       146.31  |proj g|=     0.0057031\n",
      "At iterate     4  f =       146.31  |proj g|=     0.0044494\n",
      "At iterate     5  f =       146.31  |proj g|=     0.0044783\n",
      "At iterate     6  f =       146.31  |proj g|=      0.012315\n",
      "At iterate     7  f =        146.3  |proj g|=      0.023409\n",
      "At iterate     8  f =       146.29  |proj g|=      0.039868\n",
      "At iterate     9  f =       146.27  |proj g|=      0.057653\n",
      "At iterate    10  f =       146.24  |proj g|=      0.063078\n",
      "At iterate    11  f =       146.22  |proj g|=      0.014477\n",
      "At iterate    12  f =       146.21  |proj g|=     0.0011813\n",
      "At iterate    13  f =       146.21  |proj g|=    1.9641e-05\n",
      "At iterate    14  f =       146.21  |proj g|=    2.7138e-08\n",
      "\n",
      "iterations 14\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 2.71385e-08\n",
      "final function value 146.214\n",
      "\n",
      "F = 146.214\n",
      "final  value 146.214220 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1329 196.1804 \n",
      "  - best initial criterion value(s) :  -167.318 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       167.32  |proj g|=      0.10956\n",
      "At iterate     1  f =       167.31  |proj g|=       0.10929\n",
      "At iterate     2  f =       165.53  |proj g|=      0.081759\n",
      "At iterate     3  f =       164.79  |proj g|=       0.11212\n",
      "At iterate     4  f =       163.76  |proj g|=       0.13658\n",
      "At iterate     5  f =       162.98  |proj g|=       0.12177\n",
      "At iterate     6  f =       162.55  |proj g|=      0.030033\n",
      "At iterate     7  f =       162.54  |proj g|=      0.010652\n",
      "At iterate     8  f =       162.54  |proj g|=    0.00016601\n",
      "At iterate     9  f =       162.54  |proj g|=    8.4511e-06\n",
      "At iterate    10  f =       162.54  |proj g|=    1.5859e-07\n",
      "\n",
      "iterations 10\n",
      "function evaluations 20\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.58586e-07\n",
      "final function value 162.54\n",
      "\n",
      "F = 162.54\n",
      "final  value 162.539740 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2414 196.2077 \n",
      "  - best initial criterion value(s) :  -133.504 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        133.5  |proj g|=      0.31764\n",
      "At iterate     1  f =       133.41  |proj g|=       0.29505\n",
      "At iterate     2  f =       132.65  |proj g|=      0.081953\n",
      "At iterate     3  f =       132.54  |proj g|=      0.030875\n",
      "At iterate     4  f =        132.5  |proj g|=      0.015055\n",
      "At iterate     5  f =       132.49  |proj g|=      0.012656\n",
      "At iterate     6  f =       132.46  |proj g|=      0.019596\n",
      "At iterate     7  f =       132.43  |proj g|=      0.013921\n",
      "At iterate     8  f =       132.42  |proj g|=     0.0041034\n",
      "At iterate     9  f =       132.42  |proj g|=    0.00069057\n",
      "At iterate    10  f =       132.42  |proj g|=    0.00012699\n",
      "At iterate    11  f =       132.42  |proj g|=    2.6014e-06\n",
      "At iterate    12  f =       132.42  |proj g|=    1.0907e-07\n",
      "\n",
      "iterations 12\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.09065e-07\n",
      "final function value 132.421\n",
      "\n",
      "F = 132.421\n",
      "final  value 132.421074 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2477 196.1002 \n",
      "  - best initial criterion value(s) :  -137.4575 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       137.46  |proj g|=      0.11501\n",
      "At iterate     1  f =       137.44  |proj g|=       0.11412\n",
      "At iterate     2  f =       136.83  |proj g|=      0.057192\n",
      "At iterate     3  f =       136.67  |proj g|=       0.01578\n",
      "At iterate     4  f =       136.64  |proj g|=       0.01856\n",
      "At iterate     5  f =       136.62  |proj g|=      0.016423\n",
      "At iterate     6  f =       136.59  |proj g|=     0.0031988\n",
      "At iterate     7  f =       136.59  |proj g|=    0.00062117\n",
      "At iterate     8  f =       136.59  |proj g|=    5.0692e-05\n",
      "At iterate     9  f =       136.59  |proj g|=    2.1648e-05\n",
      "At iterate    10  f =       136.59  |proj g|=    1.7424e-05\n",
      "\n",
      "iterations 10\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.74239e-05\n",
      "final function value 136.591\n",
      "\n",
      "F = 136.591\n",
      "final  value 136.591179 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3375 196.3354 \n",
      "  - best initial criterion value(s) :  -157.8538 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       157.85  |proj g|=      0.31177\n",
      "At iterate     1  f =       157.76  |proj g|=       0.23791\n",
      "At iterate     2  f =       157.62  |proj g|=      0.040622\n",
      "At iterate     3  f =       157.61  |proj g|=      0.038412\n",
      "At iterate     4  f =       157.58  |proj g|=      0.054063\n",
      "At iterate     5  f =       157.53  |proj g|=       0.11643\n",
      "At iterate     6  f =        157.4  |proj g|=       0.20491\n",
      "At iterate     7  f =        157.2  |proj g|=       0.28779\n",
      "At iterate     8  f =       157.01  |proj g|=       0.23717\n",
      "At iterate     9  f =       156.86  |proj g|=      0.059382\n",
      "At iterate    10  f =       156.85  |proj g|=     0.0097746\n",
      "At iterate    11  f =       156.85  |proj g|=     0.0016344\n",
      "At iterate    12  f =       156.85  |proj g|=    0.00043001\n",
      "At iterate    13  f =       156.85  |proj g|=    4.2105e-08\n",
      "At iterate    14  f =       156.85  |proj g|=    2.5609e-09\n",
      "\n",
      "iterations 14\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.56095e-09\n",
      "final function value 156.854\n",
      "\n",
      "F = 156.854\n",
      "final  value 156.853532 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1424 196.1952 \n",
      "  - best initial criterion value(s) :  -136.0877 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       136.09  |proj g|=      0.17694\n",
      "At iterate     1  f =       136.06  |proj g|=       0.16603\n",
      "At iterate     2  f =       135.78  |proj g|=      0.027407\n",
      "At iterate     3  f =       135.76  |proj g|=      0.019526\n",
      "At iterate     4  f =       135.74  |proj g|=      0.018109\n",
      "At iterate     5  f =        135.7  |proj g|=      0.039608\n",
      "At iterate     6  f =       135.61  |proj g|=      0.075022\n",
      "At iterate     7  f =        135.4  |proj g|=       0.12118\n",
      "At iterate     8  f =       135.18  |proj g|=       0.15364\n",
      "At iterate     9  f =       134.82  |proj g|=        0.1137\n",
      "At iterate    10  f =       134.63  |proj g|=      0.014433\n",
      "At iterate    11  f =       134.63  |proj g|=     0.0036811\n",
      "At iterate    12  f =       134.63  |proj g|=     0.0017676\n",
      "At iterate    13  f =       134.63  |proj g|=    6.9706e-06\n",
      "At iterate    14  f =       134.63  |proj g|=    6.9584e-06\n",
      "\n",
      "iterations 14\n",
      "function evaluations 32\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.9584e-06\n",
      "final function value 134.628\n",
      "\n",
      "F = 134.628\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 134.627545 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2364 196.2229 \n",
      "  - best initial criterion value(s) :  -146.9854 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       146.99  |proj g|=      0.21029\n",
      "At iterate     1  f =       146.94  |proj g|=       0.20302\n",
      "At iterate     2  f =       146.54  |proj g|=       0.06105\n",
      "At iterate     3  f =        146.5  |proj g|=      0.044559\n",
      "At iterate     4  f =       146.48  |proj g|=      0.029668\n",
      "At iterate     5  f =       146.44  |proj g|=      0.026215\n",
      "At iterate     6  f =       146.31  |proj g|=      0.089248\n",
      "At iterate     7  f =       146.12  |proj g|=       0.15709\n",
      "At iterate     8  f =       145.97  |proj g|=       0.15003\n",
      "At iterate     9  f =       145.84  |proj g|=     0.0042112\n",
      "At iterate    10  f =       145.84  |proj g|=     0.0019644\n",
      "At iterate    11  f =       145.84  |proj g|=    0.00030862\n",
      "At iterate    12  f =       145.84  |proj g|=    9.8901e-05\n",
      "At iterate    13  f =       145.84  |proj g|=    1.1771e-05\n",
      "\n",
      "iterations 13\n",
      "function evaluations 15\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.17707e-05\n",
      "final function value 145.836\n",
      "\n",
      "F = 145.836\n",
      "final  value 145.835822 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2177 196.2362 \n",
      "  - best initial criterion value(s) :  -167.3788 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       167.38  |proj g|=      0.49923\n",
      "At iterate     1  f =       167.14  |proj g|=       0.46892\n",
      "At iterate     2  f =        166.1  |proj g|=      0.066602\n",
      "At iterate     3  f =       166.04  |proj g|=      0.086183\n",
      "At iterate     4  f =       165.73  |proj g|=       0.13202\n",
      "At iterate     5  f =       165.41  |proj g|=       0.12423\n",
      "At iterate     6  f =       165.37  |proj g|=      0.017833\n",
      "At iterate     7  f =       165.36  |proj g|=      0.014914\n",
      "At iterate     8  f =       165.36  |proj g|=    0.00068181\n",
      "At iterate     9  f =       165.36  |proj g|=    8.6071e-06\n",
      "At iterate    10  f =       165.36  |proj g|=     6.139e-07\n",
      "\n",
      "iterations 10\n",
      "function evaluations 14\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.13904e-07\n",
      "final function value 165.364\n",
      "\n",
      "F = 165.364\n",
      "final  value 165.363542 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3147 196.2291 \n",
      "  - best initial criterion value(s) :  -139.4352 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       139.44  |proj g|=     0.030607\n",
      "At iterate     1  f =       139.43  |proj g|=      0.028372\n",
      "At iterate     2  f =       139.43  |proj g|=     0.0011073\n",
      "At iterate     3  f =       139.43  |proj g|=    0.00081581\n",
      "At iterate     4  f =       139.43  |proj g|=    0.00078763\n",
      "At iterate     5  f =       139.43  |proj g|=     0.0020857\n",
      "At iterate     6  f =       139.43  |proj g|=     0.0036722\n",
      "At iterate     7  f =       139.43  |proj g|=      0.004918\n",
      "At iterate     8  f =       139.43  |proj g|=     0.0039051\n",
      "At iterate     9  f =       139.43  |proj g|=    0.00043634\n",
      "At iterate    10  f =       139.43  |proj g|=    1.6452e-05\n",
      "At iterate    11  f =       139.43  |proj g|=    4.7194e-07\n",
      "\n",
      "iterations 11\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.71944e-07\n",
      "final function value 139.428\n",
      "\n",
      "F = 139.428\n",
      "final  value 139.427752 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1844 196.1623 \n",
      "  - best initial criterion value(s) :  -150.8149 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       150.81  |proj g|=     0.045182\n",
      "At iterate     1  f =       150.81  |proj g|=      0.045317\n",
      "At iterate     2  f =       148.28  |proj g|=      0.028154\n",
      "At iterate     3  f =       148.28  |proj g|=       0.02668\n",
      "At iterate     4  f =       148.25  |proj g|=      0.011614\n",
      "At iterate     5  f =       148.23  |proj g|=     0.0033346\n",
      "At iterate     6  f =       148.23  |proj g|=     0.0010179\n",
      "At iterate     7  f =       148.23  |proj g|=    7.5336e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     8  f =       148.23  |proj g|=    7.5523e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 40\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 7.55226e-06\n",
      "final function value 148.234\n",
      "\n",
      "F = 148.234\n",
      "final  value 148.233595 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1859 196.2947 \n",
      "  - best initial criterion value(s) :  -158.6905 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       158.69  |proj g|=      0.41886\n",
      "At iterate     1  f =       158.52  |proj g|=        0.4045\n",
      "At iterate     2  f =       157.32  |proj g|=       0.10899\n",
      "At iterate     3  f =       157.28  |proj g|=       0.12127\n",
      "At iterate     4  f =       157.24  |proj g|=       0.04142\n",
      "At iterate     5  f =       157.16  |proj g|=      0.041234\n",
      "At iterate     6  f =       156.67  |proj g|=       0.23385\n",
      "At iterate     7  f =       156.39  |proj g|=       0.37468\n",
      "At iterate     8  f =       156.05  |proj g|=       0.19778\n",
      "At iterate     9  f =       155.92  |proj g|=      0.095711\n",
      "At iterate    10  f =        155.9  |proj g|=      0.015039\n",
      "At iterate    11  f =        155.9  |proj g|=     0.0010575\n",
      "At iterate    12  f =        155.9  |proj g|=    0.00011468\n",
      "At iterate    13  f =        155.9  |proj g|=     8.646e-07\n",
      "\n",
      "iterations 13\n",
      "function evaluations 16\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 8.64604e-07\n",
      "final function value 155.897\n",
      "\n",
      "F = 155.897\n",
      "final  value 155.897305 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2817 196.2931 \n",
      "  - best initial criterion value(s) :  -142.465 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       142.47  |proj g|=     0.058657\n",
      "At iterate     1  f =       142.46  |proj g|=         0.054\n",
      "At iterate     2  f =       142.44  |proj g|=      0.010321\n",
      "At iterate     3  f =       142.44  |proj g|=      0.010299\n",
      "At iterate     4  f =       142.43  |proj g|=      0.022938\n",
      "At iterate     5  f =       142.41  |proj g|=      0.043717\n",
      "At iterate     6  f =       142.36  |proj g|=      0.072155\n",
      "At iterate     7  f =       142.27  |proj g|=      0.096408\n",
      "At iterate     8  f =       142.08  |proj g|=       0.10286\n",
      "At iterate     9  f =       141.93  |proj g|=     0.0067564\n",
      "At iterate    10  f =       141.83  |proj g|=     0.0011605\n",
      "At iterate    11  f =       141.83  |proj g|=    0.00020159\n",
      "At iterate    12  f =       141.83  |proj g|=    3.5013e-07\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    13  f =       141.83  |proj g|=    3.4918e-07\n",
      "\n",
      "iterations 13\n",
      "function evaluations 40\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 3.49178e-07\n",
      "final function value 141.835\n",
      "\n",
      "F = 141.835\n",
      "final  value 141.834855 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2318 196.4098 \n",
      "  - best initial criterion value(s) :  -148.316 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       148.32  |proj g|=      0.26045\n",
      "At iterate     1  f =       148.25  |proj g|=       0.26111\n",
      "ys=-1.686e-04  -gs= 6.828e-02, BFGS update SKIPPED\n",
      "At iterate     2  f =       144.78  |proj g|=       0.18648\n",
      "At iterate     3  f =       144.27  |proj g|=      0.048814\n",
      "At iterate     4  f =       144.24  |proj g|=      0.037125\n",
      "At iterate     5  f =       144.22  |proj g|=      0.019243\n",
      "At iterate     6  f =       144.19  |proj g|=      0.017058\n",
      "At iterate     7  f =       144.09  |proj g|=      0.064423\n",
      "At iterate     8  f =       143.97  |proj g|=       0.10512\n",
      "At iterate     9  f =       143.87  |proj g|=      0.092158\n",
      "At iterate    10  f =        143.8  |proj g|=     0.0022482\n",
      "At iterate    11  f =        143.8  |proj g|=    0.00066629\n",
      "At iterate    12  f =       143.79  |proj g|=    2.3189e-05\n",
      "At iterate    13  f =       143.79  |proj g|=    3.4219e-06\n",
      "\n",
      "iterations 13\n",
      "function evaluations 21\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.42192e-06\n",
      "final function value 143.795\n",
      "\n",
      "F = 143.795\n",
      "final  value 143.794878 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2791 196.2655 \n",
      "  - best initial criterion value(s) :  -167.6371 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       167.64  |proj g|=      0.50429\n",
      "At iterate     1  f =       167.38  |proj g|=       0.50307\n",
      "At iterate     2  f =       164.65  |proj g|=       0.12329\n",
      "At iterate     3  f =       164.55  |proj g|=      0.072564\n",
      "At iterate     4  f =       164.12  |proj g|=      0.085927\n",
      "At iterate     5  f =        163.8  |proj g|=      0.067291\n",
      "At iterate     6  f =       163.69  |proj g|=      0.049231\n",
      "At iterate     7  f =       163.68  |proj g|=     0.0040913\n",
      "At iterate     8  f =       163.68  |proj g|=    0.00027233\n",
      "At iterate     9  f =       163.68  |proj g|=    4.1234e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    10  f =       163.68  |proj g|=    4.1235e-05\n",
      "\n",
      "iterations 10\n",
      "function evaluations 53\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.12351e-05\n",
      "final function value 163.679\n",
      "\n",
      "F = 163.679\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 163.678676 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.241 196.1117 \n",
      "  - best initial criterion value(s) :  -146.1739 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       146.17  |proj g|=      0.65067\n",
      "At iterate     1  f =       145.78  |proj g|=       0.55496\n",
      "At iterate     2  f =       144.52  |proj g|=       0.14076\n",
      "At iterate     3  f =        144.4  |proj g|=      0.046936\n",
      "At iterate     4  f =       144.37  |proj g|=      0.020101\n",
      "At iterate     5  f =       144.36  |proj g|=      0.019157\n",
      "At iterate     6  f =       144.33  |proj g|=      0.037374\n",
      "At iterate     7  f =       144.27  |proj g|=      0.068608\n",
      "At iterate     8  f =       144.17  |proj g|=       0.09676\n",
      "At iterate     9  f =       144.09  |proj g|=      0.079218\n",
      "At iterate    10  f =       144.03  |proj g|=     0.0018622\n",
      "At iterate    11  f =       144.03  |proj g|=    0.00035552\n",
      "At iterate    12  f =       144.03  |proj g|=    6.0836e-05\n",
      "At iterate    13  f =       144.03  |proj g|=    1.3122e-05\n",
      "\n",
      "iterations 13\n",
      "function evaluations 14\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.31222e-05\n",
      "final function value 144.028\n",
      "\n",
      "F = 144.028\n",
      "final  value 144.027780 \n",
      "converged\n",
      "[1] 87.66738 12.33262\n",
      "[1] \"Adding point... \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For consistency with the rest of the package the inequality sign may be switched from >= to <= in a future nloptr version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2353 196.1368 \n",
      "  - best initial criterion value(s) :  -142.598 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        142.6  |proj g|=       0.1042\n",
      "At iterate     1  f =       142.59  |proj g|=       0.10404\n",
      "At iterate     2  f =       141.22  |proj g|=      0.040652\n",
      "At iterate     3  f =       141.17  |proj g|=     0.0061274\n",
      "At iterate     4  f =       141.17  |proj g|=     0.0036451\n",
      "At iterate     5  f =       141.17  |proj g|=    0.00057523\n",
      "At iterate     6  f =       141.17  |proj g|=     0.0001955\n",
      "At iterate     7  f =       141.17  |proj g|=    1.2352e-06\n",
      "At iterate     8  f =       141.17  |proj g|=    1.2358e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 26\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.23577e-06\n",
      "final function value 141.17\n",
      "\n",
      "F = 141.17\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 141.170378 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2253 196.0694 \n",
      "  - best initial criterion value(s) :  -159.5665 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       159.57  |proj g|=     0.064733\n",
      "At iterate     1  f =       159.56  |proj g|=      0.063127\n",
      "At iterate     2  f =       159.42  |proj g|=     0.0064633\n",
      "At iterate     3  f =       159.42  |proj g|=     0.0058294\n",
      "At iterate     4  f =       159.42  |proj g|=     0.0065921\n",
      "At iterate     5  f =       159.42  |proj g|=     0.0020981\n",
      "At iterate     6  f =       159.42  |proj g|=    0.00012262\n",
      "At iterate     7  f =       159.42  |proj g|=    5.6301e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 159.415404 \n",
      "stopped after 7 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2751 196.2297 \n",
      "  - best initial criterion value(s) :  -168.74 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       168.74  |proj g|=      0.83871\n",
      "At iterate     1  f =       168.04  |proj g|=       0.82841\n",
      "At iterate     2  f =       165.33  |proj g|=       0.22468\n",
      "At iterate     3  f =       165.27  |proj g|=       0.01085\n",
      "At iterate     4  f =       165.27  |proj g|=      0.001237\n",
      "At iterate     5  f =       165.27  |proj g|=    0.00073057\n",
      "At iterate     6  f =       165.27  |proj g|=    0.00073073\n",
      "At iterate     7  f =       165.27  |proj g|=     0.0021097\n",
      "At iterate     8  f =       165.27  |proj g|=      0.004231\n",
      "At iterate     9  f =       165.27  |proj g|=     0.0080072\n",
      "At iterate    10  f =       165.27  |proj g|=      0.013799\n",
      "At iterate    11  f =       165.27  |proj g|=      0.022937\n",
      "At iterate    12  f =       165.26  |proj g|=      0.036387\n",
      "At iterate    13  f =       165.26  |proj g|=      0.053653\n",
      "At iterate    14  f =       165.26  |proj g|=      0.068057\n",
      "At iterate    15  f =       165.25  |proj g|=      0.046693\n",
      "At iterate    16  f =       165.24  |proj g|=     0.0066367\n",
      "At iterate    17  f =       165.24  |proj g|=    0.00014014\n",
      "At iterate    18  f =       165.24  |proj g|=    4.1238e-07\n",
      "\n",
      "iterations 18\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 19\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 4.12378e-07\n",
      "final function value 165.244\n",
      "\n",
      "F = 165.244\n",
      "final  value 165.243976 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1765 196.3737 \n",
      "  - best initial criterion value(s) :  -145.2157 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       145.22  |proj g|=     0.041633\n",
      "At iterate     1  f =       145.21  |proj g|=      0.041546\n",
      "At iterate     2  f =       144.79  |proj g|=       0.05387\n",
      "At iterate     3  f =       144.38  |proj g|=       0.10185\n",
      "At iterate     4  f =        143.8  |proj g|=       0.13887\n",
      "At iterate     5  f =        143.2  |proj g|=      0.080237\n",
      "At iterate     6  f =       143.07  |proj g|=      0.014854\n",
      "At iterate     7  f =       143.06  |proj g|=    0.00062548\n",
      "At iterate     8  f =       143.06  |proj g|=    7.6234e-05\n",
      "At iterate     9  f =       143.06  |proj g|=    1.3465e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.34652e-06\n",
      "final function value 143.06\n",
      "\n",
      "F = 143.06\n",
      "final  value 143.059703 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2272 196.1137 \n",
      "  - best initial criterion value(s) :  -149.5342 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       149.53  |proj g|=      0.48779\n",
      "At iterate     1  f =       149.16  |proj g|=       0.44387\n",
      "At iterate     2  f =       146.88  |proj g|=       0.12365\n",
      "At iterate     3  f =       146.65  |proj g|=      0.059191\n",
      "At iterate     4  f =       146.58  |proj g|=      0.025251\n",
      "At iterate     5  f =       146.55  |proj g|=      0.011015\n",
      "At iterate     6  f =       146.54  |proj g|=     0.0096364\n",
      "At iterate     7  f =       146.54  |proj g|=    0.00070022\n",
      "At iterate     8  f =       146.54  |proj g|=    0.00021081\n",
      "At iterate     9  f =       146.54  |proj g|=    3.3775e-06\n",
      "At iterate    10  f =       146.54  |proj g|=    3.3673e-06\n",
      "\n",
      "iterations 10\n",
      "function evaluations 14\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.36727e-06\n",
      "final function value 146.538\n",
      "\n",
      "F = 146.538\n",
      "final  value 146.538123 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2922 196.2379 \n",
      "  - best initial criterion value(s) :  -199.2402 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       199.24  |proj g|=     0.098541\n",
      "At iterate     1  f =       199.22  |proj g|=      0.096114\n",
      "At iterate     2  f =       198.91  |proj g|=     0.0082203\n",
      "At iterate     3  f =        198.9  |proj g|=     0.0035429\n",
      "At iterate     4  f =        198.9  |proj g|=     0.0049671\n",
      "At iterate     5  f =        198.9  |proj g|=     0.0062378\n",
      "At iterate     6  f =        198.9  |proj g|=     0.0033026\n",
      "At iterate     7  f =        198.9  |proj g|=    0.00066889\n",
      "At iterate     8  f =        198.9  |proj g|=    8.3169e-05\n",
      "At iterate     9  f =        198.9  |proj g|=    2.4165e-06\n",
      "At iterate    10  f =        198.9  |proj g|=    2.2332e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate    11  f =        198.9  |proj g|=    2.0944e-06\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 198.896401 \n",
      "stopped after 11 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.0788 196.2461 \n",
      "  - best initial criterion value(s) :  -172.6894 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       172.69  |proj g|=      0.41274\n",
      "At iterate     1  f =       172.58  |proj g|=       0.10247\n",
      "At iterate     2  f =       172.57  |proj g|=      0.043543\n",
      "At iterate     3  f =       172.57  |proj g|=      0.043736\n",
      "At iterate     4  f =       172.55  |proj g|=      0.089505\n",
      "At iterate     5  f =       172.51  |proj g|=       0.17545\n",
      "At iterate     6  f =       169.95  |proj g|=       0.62668\n",
      "At iterate     7  f =       169.95  |proj g|=       0.62273\n",
      "At iterate     8  f =       169.13  |proj g|=       0.36499\n",
      "At iterate     9  f =       168.51  |proj g|=      0.090548\n",
      "At iterate    10  f =        168.4  |proj g|=      0.040501\n",
      "At iterate    11  f =       168.37  |proj g|=     0.0083504\n",
      "At iterate    12  f =       168.37  |proj g|=     0.0014882\n",
      "At iterate    13  f =       168.37  |proj g|=     0.0009029\n",
      "At iterate    14  f =       168.37  |proj g|=    5.6984e-05\n",
      "At iterate    15  f =       168.37  |proj g|=    4.6782e-07\n",
      "\n",
      "iterations 15\n",
      "function evaluations 25\n",
      "segments explored during Cauchy searches 15\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.67821e-07\n",
      "final function value 168.373\n",
      "\n",
      "F = 168.373\n",
      "final  value 168.372519 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1946 196.1622 \n",
      "  - best initial criterion value(s) :  -143.4381 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       143.44  |proj g|=      0.24124\n",
      "At iterate     1  f =       143.38  |proj g|=        0.2282\n",
      "At iterate     2  f =       142.77  |proj g|=      0.038284\n",
      "At iterate     3  f =       142.74  |proj g|=      0.034187\n",
      "At iterate     4  f =       142.65  |proj g|=      0.050385\n",
      "At iterate     5  f =       142.53  |proj g|=      0.074994\n",
      "At iterate     6  f =       142.42  |proj g|=      0.052874\n",
      "At iterate     7  f =       142.39  |proj g|=      0.012514\n",
      "At iterate     8  f =       142.38  |proj g|=     0.0030756\n",
      "At iterate     9  f =       142.38  |proj g|=    0.00013027\n",
      "At iterate    10  f =       142.38  |proj g|=     3.757e-06\n",
      "\n",
      "iterations 10\n",
      "function evaluations 11\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.75703e-06\n",
      "final function value 142.382\n",
      "\n",
      "F = 142.382\n",
      "final  value 142.382483 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1634 196.2696 \n",
      "  - best initial criterion value(s) :  -157.9312 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       157.93  |proj g|=      0.14218\n",
      "At iterate     1  f =        157.9  |proj g|=       0.14049\n",
      "At iterate     2  f =        156.9  |proj g|=      0.050979\n",
      "At iterate     3  f =       156.78  |proj g|=      0.052906\n",
      "At iterate     4  f =       156.68  |proj g|=      0.018072\n",
      "At iterate     5  f =       156.67  |proj g|=     0.0071342\n",
      "At iterate     6  f =       156.66  |proj g|=    0.00068487\n",
      "At iterate     7  f =       156.66  |proj g|=    5.7105e-05\n",
      "At iterate     8  f =       156.66  |proj g|=    4.0849e-06\n",
      "\n",
      "iterations 8\n",
      "function evaluations 9\n",
      "segments explored during Cauchy searches 8\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 4.08488e-06\n",
      "final function value 156.664\n",
      "\n",
      "F = 156.664\n",
      "final  value 156.664483 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1209 196.3856 \n",
      "  - best initial criterion value(s) :  -204.276 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       204.28  |proj g|=       3.8652\n",
      "At iterate     1  f =       190.11  |proj g|=       0.61288\n",
      "At iterate     2  f =       190.07  |proj g|=     0.0047258\n",
      "At iterate     3  f =       190.07  |proj g|=    8.5103e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     4  f =       190.07  |proj g|=    1.5275e-05\n",
      "\n",
      "iterations 4\n",
      "function evaluations 27\n",
      "segments explored during Cauchy searches 5\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.5275e-05\n",
      "final function value 190.072\n",
      "\n",
      "F = 190.072\n",
      "final  value 190.071775 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3021 196.2999 \n",
      "  - best initial criterion value(s) :  -176.7593 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       176.76  |proj g|=      0.37756\n",
      "At iterate     1  f =       176.57  |proj g|=       0.38992\n",
      "ys=-3.311e-03  -gs= 1.918e-01, BFGS update SKIPPED\n",
      "At iterate     2  f =       170.03  |proj g|=       0.25995\n",
      "At iterate     3  f =       169.89  |proj g|=       0.11216\n",
      "At iterate     4  f =       169.85  |proj g|=       0.09853\n",
      "At iterate     5  f =        169.7  |proj g|=      0.059595\n",
      "At iterate     6  f =       169.68  |proj g|=      0.011531\n",
      "At iterate     7  f =       169.68  |proj g|=    0.00071162\n",
      "At iterate     8  f =       169.68  |proj g|=    3.1535e-05\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     9  f =       169.68  |proj g|=    3.1531e-05\n",
      "\n",
      "iterations 9\n",
      "function evaluations 39\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.15307e-05\n",
      "final function value 169.682\n",
      "\n",
      "F = 169.682\n",
      "final  value 169.681991 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3567 196.2073 \n",
      "  - best initial criterion value(s) :  -172.3219 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       172.32  |proj g|=      0.54144\n",
      "At iterate     1  f =       172.04  |proj g|=       0.51613\n",
      "At iterate     2  f =       170.76  |proj g|=       0.17338\n",
      "At iterate     3  f =       170.66  |proj g|=      0.049788\n",
      "At iterate     4  f =       170.64  |proj g|=      0.051284\n",
      "At iterate     5  f =        170.5  |proj g|=       0.17903\n",
      "At iterate     6  f =       170.18  |proj g|=         0.414\n",
      "At iterate     7  f =       169.16  |proj g|=         1.188\n",
      "At iterate     8  f =        168.4  |proj g|=        1.5942\n",
      "At iterate     9  f =       167.36  |proj g|=        1.4561\n",
      "At iterate    10  f =       165.85  |proj g|=       0.12899\n",
      "At iterate    11  f =       165.83  |proj g|=      0.017611\n",
      "At iterate    12  f =       165.82  |proj g|=     0.0065505\n",
      "At iterate    13  f =       165.82  |proj g|=    0.00011968\n",
      "At iterate    14  f =       165.82  |proj g|=    2.2783e-06\n",
      "At iterate    15  f =       165.82  |proj g|=    2.1649e-06\n",
      "\n",
      "iterations 15\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 15\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.16491e-06\n",
      "final function value 165.816\n",
      "\n",
      "F = 165.816\n",
      "final  value 165.816084 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2007 196.1624 \n",
      "  - best initial criterion value(s) :  -154.6055 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       154.61  |proj g|=      0.14064\n",
      "At iterate     1  f =       154.57  |proj g|=        0.1378\n",
      "At iterate     2  f =       152.58  |proj g|=      0.076459\n",
      "At iterate     3  f =        147.6  |proj g|=      0.086841\n",
      "At iterate     4  f =       147.21  |proj g|=       0.05087\n",
      "At iterate     5  f =       147.04  |proj g|=      0.025037\n",
      "Nonpositive definiteness in Cholesky factorization in formk;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "At iterate     6  f =       147.03  |proj g|=      0.018645\n",
      "At iterate     7  f =       147.01  |proj g|=     0.0027606\n",
      "At iterate     8  f =       147.01  |proj g|=     0.0011593\n",
      "At iterate     9  f =       147.01  |proj g|=    1.8551e-05\n",
      "At iterate    10  f =       147.01  |proj g|=    1.8479e-06\n",
      "\n",
      "iterations 10\n",
      "function evaluations 20\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.84789e-06\n",
      "final function value 147.014\n",
      "\n",
      "F = 147.014\n",
      "final  value 147.014105 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.26 196.2762 \n",
      "  - best initial criterion value(s) :  -154.0239 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       154.02  |proj g|=      0.79751\n",
      "At iterate     1  f =       153.43  |proj g|=       0.68057\n",
      "At iterate     2  f =       151.47  |proj g|=       0.22145\n",
      "At iterate     3  f =       151.08  |proj g|=       0.13153\n",
      "At iterate     4  f =       149.99  |proj g|=      0.046295\n",
      "At iterate     5  f =       149.87  |proj g|=      0.025821\n",
      "At iterate     6  f =       149.87  |proj g|=     0.0066778\n",
      "At iterate     7  f =       149.86  |proj g|=     0.0011877\n",
      "At iterate     8  f =       149.86  |proj g|=    3.0943e-05\n",
      "At iterate     9  f =       149.86  |proj g|=     1.888e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.88796e-06\n",
      "final function value 149.864\n",
      "\n",
      "F = 149.864\n",
      "final  value 149.863970 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1855 196.3214 \n",
      "  - best initial criterion value(s) :  -162.8231 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       162.82  |proj g|=      0.14476\n",
      "At iterate     1  f =       162.79  |proj g|=       0.10992\n",
      "At iterate     2  f =       162.68  |proj g|=      0.086971\n",
      "At iterate     3  f =        162.6  |proj g|=       0.11716\n",
      "At iterate     4  f =       162.34  |proj g|=       0.21666\n",
      "At iterate     5  f =       161.61  |proj g|=       0.14837\n",
      "At iterate     6  f =       161.11  |proj g|=       0.37328\n",
      "At iterate     7  f =       160.92  |proj g|=       0.22199\n",
      "At iterate     8  f =       160.48  |proj g|=      0.018947\n",
      "At iterate     9  f =       160.25  |proj g|=      0.065642\n",
      "At iterate    10  f =       160.08  |proj g|=      0.028806\n",
      "At iterate    11  f =       160.08  |proj g|=     0.0055948\n",
      "At iterate    12  f =       160.08  |proj g|=    6.7537e-05\n",
      "At iterate    13  f =       160.08  |proj g|=    6.7546e-05\n",
      "\n",
      "iterations 13\n",
      "function evaluations 28\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 6.75458e-05\n",
      "final function value 160.08\n",
      "\n",
      "F = 160.08\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 160.080350 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2322 196.1081 \n",
      "  - best initial criterion value(s) :  -160.7639 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       160.76  |proj g|=      0.10599\n",
      "At iterate     1  f =       160.75  |proj g|=       0.10613\n",
      "ys=-1.398e-05  -gs= 1.206e-02, BFGS update SKIPPED\n",
      "At iterate     2  f =       156.56  |proj g|=       0.15002\n",
      "At iterate     3  f =       155.94  |proj g|=       0.16592\n",
      "At iterate     4  f =       155.57  |proj g|=      0.036824\n",
      "At iterate     5  f =       155.55  |proj g|=       0.01459\n",
      "At iterate     6  f =       155.54  |proj g|=    0.00092979\n",
      "At iterate     7  f =       155.54  |proj g|=    0.00012417\n",
      "At iterate     8  f =       155.54  |proj g|=    3.7989e-06\n",
      "At iterate     9  f =       155.54  |proj g|=    3.7885e-06\n",
      "\n",
      "iterations 9\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.78848e-06\n",
      "final function value 155.541\n",
      "\n",
      "F = 155.541\n",
      "final  value 155.541050 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.3204 196.1337 \n",
      "  - best initial criterion value(s) :  -172.6636 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       172.66  |proj g|=       1.1399\n",
      "At iterate     1  f =       171.34  |proj g|=        1.1779\n",
      "ys=-4.329e-02  -gs= 1.299e+00, BFGS update SKIPPED\n",
      "At iterate     2  f =       166.62  |proj g|=       0.37357\n",
      "At iterate     3  f =       166.53  |proj g|=     0.0057059\n",
      "At iterate     4  f =       166.53  |proj g|=      0.015365\n",
      "At iterate     5  f =       166.48  |proj g|=       0.14044\n",
      "At iterate     6  f =       166.43  |proj g|=       0.21652\n",
      "At iterate     7  f =       166.33  |proj g|=       0.20564\n",
      "At iterate     8  f =       166.31  |proj g|=      0.090118\n",
      "At iterate     9  f =       166.31  |proj g|=     0.0042411\n",
      "At iterate    10  f =       166.31  |proj g|=      9.68e-05\n",
      "At iterate    11  f =       166.31  |proj g|=    1.0841e-07\n",
      "\n",
      "iterations 11\n",
      "function evaluations 17\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 1.08407e-07\n",
      "final function value 166.305\n",
      "\n",
      "F = 166.305\n",
      "final  value 166.305014 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1368 196.177 \n",
      "  - best initial criterion value(s) :  -186.1843 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       186.18  |proj g|=      0.74004\n",
      "At iterate     1  f =       185.63  |proj g|=       0.75326\n",
      "ys=-9.730e-03  -gs= 5.481e-01, BFGS update SKIPPED\n",
      "At iterate     2  f =       179.97  |proj g|=       0.31726\n",
      "At iterate     3  f =       179.73  |proj g|=      0.078136\n",
      "At iterate     4  f =       179.68  |proj g|=      0.085604\n",
      "At iterate     5  f =       179.57  |proj g|=       0.16496\n",
      "At iterate     6  f =       179.12  |proj g|=       0.52968\n",
      "At iterate     7  f =       177.95  |proj g|=        1.3809\n",
      "At iterate     8  f =       177.12  |proj g|=        2.2959\n",
      "At iterate     9  f =       174.82  |proj g|=        1.0203\n",
      "At iterate    10  f =       174.36  |proj g|=        0.5829\n",
      "At iterate    11  f =       174.14  |proj g|=      0.094282\n",
      "At iterate    12  f =       174.11  |proj g|=      0.018893\n",
      "At iterate    13  f =       174.11  |proj g|=    0.00087423\n",
      "At iterate    14  f =       174.11  |proj g|=    1.0088e-05\n",
      "At iterate    15  f =       174.11  |proj g|=    3.0974e-06\n",
      "\n",
      "iterations 15\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 15\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 3.09738e-06\n",
      "final function value 174.114\n",
      "\n",
      "F = 174.114\n",
      "final  value 174.113708 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.0904 196.2649 \n",
      "  - best initial criterion value(s) :  -162.419 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       162.42  |proj g|=      0.56977\n",
      "At iterate     1  f =       162.11  |proj g|=       0.49389\n",
      "At iterate     2  f =       161.57  |proj g|=       0.15779\n",
      "At iterate     3  f =       161.53  |proj g|=      0.082513\n",
      "At iterate     4  f =       161.52  |proj g|=      0.029996\n",
      "At iterate     5  f =        161.5  |proj g|=      0.029674\n",
      "At iterate     6  f =       161.44  |proj g|=      0.096079\n",
      "At iterate     7  f =       161.42  |proj g|=      0.070147\n",
      "At iterate     8  f =       161.41  |proj g|=      0.012163\n",
      "At iterate     9  f =       161.41  |proj g|=     0.0005043\n",
      "At iterate    10  f =       161.41  |proj g|=     6.949e-06\n",
      "At iterate    11  f =       161.41  |proj g|=    1.2025e-06\n",
      "\n",
      "iterations 11\n",
      "function evaluations 14\n",
      "segments explored during Cauchy searches 11\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.20247e-06\n",
      "final function value 161.41\n",
      "\n",
      "F = 161.41\n",
      "final  value 161.409856 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1389 196.224 \n",
      "  - best initial criterion value(s) :  -178.4151 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       178.42  |proj g|=      0.82155\n",
      "At iterate     1  f =       177.73  |proj g|=       0.84372\n",
      "ys=-1.818e-02  -gs= 6.753e-01, BFGS update SKIPPED\n",
      "At iterate     2  f =       172.49  |proj g|=       0.61655\n",
      "At iterate     3  f =       172.23  |proj g|=       0.53575\n",
      "At iterate     4  f =       171.66  |proj g|=      0.099875\n",
      "At iterate     5  f =       171.62  |proj g|=      0.082545\n",
      "At iterate     6  f =       169.58  |proj g|=       0.46121\n",
      "At iterate     7  f =       169.43  |proj g|=       0.14007\n",
      "At iterate     8  f =       169.41  |proj g|=      0.024322\n",
      "At iterate     9  f =       169.41  |proj g|=    0.00070328\n",
      "At iterate    10  f =       169.41  |proj g|=    3.4952e-05\n",
      "At iterate    11  f =       169.41  |proj g|=    2.5146e-06\n",
      "\n",
      "iterations 11\n",
      "function evaluations 22\n",
      "segments explored during Cauchy searches 12\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 2.51456e-06\n",
      "final function value 169.408\n",
      "\n",
      "F = 169.408\n",
      "final  value 169.407688 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2067 196.2445 \n",
      "  - best initial criterion value(s) :  -159.5648 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       159.56  |proj g|=       0.6352\n",
      "At iterate     1  f =       159.16  |proj g|=       0.62637\n",
      "At iterate     2  f =       156.63  |proj g|=       0.18329\n",
      "At iterate     3  f =       156.55  |proj g|=       0.01058\n",
      "At iterate     4  f =       156.54  |proj g|=      0.010778\n",
      "At iterate     5  f =       156.54  |proj g|=      0.017122\n",
      "At iterate     6  f =       156.54  |proj g|=      0.044592\n",
      "At iterate     7  f =       156.52  |proj g|=       0.08315\n",
      "At iterate     8  f =       156.49  |proj g|=       0.13222\n",
      "At iterate     9  f =       156.44  |proj g|=        0.1535\n",
      "At iterate    10  f =       156.39  |proj g|=      0.041883\n",
      "At iterate    11  f =       156.38  |proj g|=         0.002\n",
      "At iterate    12  f =       156.38  |proj g|=    8.4163e-05\n",
      "At iterate    13  f =       156.38  |proj g|=    1.0153e-06\n",
      "\n",
      "iterations 13\n",
      "function evaluations 18\n",
      "segments explored during Cauchy searches 14\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.01534e-06\n",
      "final function value 156.383\n",
      "\n",
      "F = 156.383\n",
      "final  value 156.382839 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2195 196.2616 \n",
      "  - best initial criterion value(s) :  -183.0235 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       183.02  |proj g|=      0.48117\n",
      "At iterate     1  f =       182.79  |proj g|=       0.46797\n",
      "At iterate     2  f =       181.28  |proj g|=      0.073881\n",
      "At iterate     3  f =       181.27  |proj g|=        0.1044\n",
      "At iterate     4  f =       181.24  |proj g|=      0.043758\n",
      "At iterate     5  f =       181.21  |proj g|=      0.042272\n",
      "At iterate     6  f =       181.01  |proj g|=       0.14674\n",
      "At iterate     7  f =       180.61  |proj g|=       0.32477\n",
      "At iterate     8  f =       179.51  |proj g|=       0.67325\n",
      "At iterate     9  f =       176.21  |proj g|=       0.46993\n",
      "ys=-4.100e+01  -gs= 2.563e+00, BFGS update SKIPPED\n",
      "At iterate    10  f =       175.91  |proj g|=       0.19626\n",
      "At iterate    11  f =       175.87  |proj g|=      0.046587\n",
      "At iterate    12  f =       175.87  |proj g|=      0.053243\n",
      "At iterate    13  f =       175.85  |proj g|=       0.13519\n",
      "At iterate    14  f =       175.81  |proj g|=       0.33729\n",
      "At iterate    15  f =       175.74  |proj g|=       0.41967\n",
      "At iterate    16  f =       175.29  |proj g|=       0.75324\n",
      "At iterate    17  f =       174.83  |proj g|=       0.30042\n",
      "At iterate    18  f =       174.48  |proj g|=      0.015432\n",
      "At iterate    19  f =       174.28  |proj g|=      0.055914\n",
      "At iterate    20  f =       174.18  |proj g|=       0.11326\n",
      "At iterate    21  f =       174.16  |proj g|=      0.011442\n",
      "At iterate    22  f =       174.15  |proj g|=     0.0010219\n",
      "At iterate    23  f =       174.15  |proj g|=     0.0012366\n",
      "At iterate    24  f =       174.15  |proj g|=    4.3196e-07\n",
      "Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "Line search cannot locate an adequate point after 20 function\n",
      "and gradient evaluations\n",
      "final  value 174.153969 \n",
      "stopped after 24 iterations\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.078 196.307 \n",
      "  - best initial criterion value(s) :  -207.7127 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       207.71  |proj g|=       1.3783\n",
      "At iterate     1  f =       205.71  |proj g|=        1.5332\n",
      "ys=-2.135e-01  -gs= 1.900e+00, BFGS update SKIPPED\n",
      "At iterate     2  f =       184.89  |proj g|=       0.76966\n",
      "At iterate     3  f =        184.8  |proj g|=      0.080306\n",
      "At iterate     4  f =        184.8  |proj g|=     0.0038536\n",
      "At iterate     5  f =        184.8  |proj g|=    7.4951e-05\n",
      "At iterate     6  f =        184.8  |proj g|=    8.5587e-05\n",
      "\n",
      "iterations 6\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 6\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 8.55867e-05\n",
      "final function value 184.802\n",
      "\n",
      "F = 184.802\n",
      "final  value 184.802257 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2185 196.3282 \n",
      "  - best initial criterion value(s) :  -155.2208 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       155.22  |proj g|=     0.067119\n",
      "At iterate     1  f =       155.21  |proj g|=      0.067089\n",
      "ys=-9.700e-06  -gs= 8.072e-03, BFGS update SKIPPED\n",
      "At iterate     2  f =       151.74  |proj g|=      0.055248\n",
      "At iterate     3  f =       151.67  |proj g|=      0.060173\n",
      "At iterate     4  f =       151.32  |proj g|=       0.34362\n",
      "At iterate     5  f =       151.08  |proj g|=       0.17139\n",
      "At iterate     6  f =       150.89  |proj g|=      0.065831\n",
      "At iterate     7  f =       150.86  |proj g|=      0.029172\n",
      "At iterate     8  f =       150.86  |proj g|=     0.0024913\n",
      "At iterate     9  f =       150.86  |proj g|=     0.0033986\n",
      "At iterate    10  f =       150.85  |proj g|=     0.0025421\n",
      "At iterate    11  f =       150.85  |proj g|=    0.00027896\n",
      "At iterate    12  f =       150.85  |proj g|=    1.8713e-05\n",
      "At iterate    13  f =       150.85  |proj g|=    1.8262e-05\n",
      "\n",
      "iterations 13\n",
      "function evaluations 25\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.82619e-05\n",
      "final function value 150.854\n",
      "\n",
      "F = 150.854\n",
      "final  value 150.854025 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.226 196.212 \n",
      "  - best initial criterion value(s) :  -150.4734 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       150.47  |proj g|=      0.21894\n",
      "At iterate     1  f =       150.43  |proj g|=       0.19554\n",
      "At iterate     2  f =       150.21  |proj g|=      0.026617\n",
      "At iterate     3  f =        150.2  |proj g|=       0.02472\n",
      "At iterate     4  f =       150.18  |proj g|=      0.025866\n",
      "At iterate     5  f =       150.14  |proj g|=      0.062616\n",
      "At iterate     6  f =       150.03  |proj g|=       0.11803\n",
      "At iterate     7  f =       149.81  |proj g|=        0.1984\n",
      "At iterate     8  f =       149.53  |proj g|=       0.27107\n",
      "At iterate     9  f =       149.13  |proj g|=       0.20493\n",
      "At iterate    10  f =       148.87  |proj g|=      0.014524\n",
      "At iterate    11  f =       148.86  |proj g|=     0.0015573\n",
      "At iterate    12  f =       148.86  |proj g|=    0.00018007\n",
      "At iterate    13  f =       148.86  |proj g|=    1.2736e-05\n",
      "\n",
      "iterations 13\n",
      "function evaluations 16\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.27363e-05\n",
      "final function value 148.863\n",
      "\n",
      "F = 148.863\n",
      "final  value 148.863445 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2921 196.4094 \n",
      "  - best initial criterion value(s) :  -149.1059 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       149.11  |proj g|=      0.84872\n",
      "At iterate     1  f =       148.48  |proj g|=       0.63861\n",
      "At iterate     2  f =       147.51  |proj g|=       0.14528\n",
      "At iterate     3  f =       147.44  |proj g|=        0.0403\n",
      "At iterate     4  f =       147.43  |proj g|=     0.0091555\n",
      "At iterate     5  f =       147.43  |proj g|=      0.008996\n",
      "At iterate     6  f =       147.43  |proj g|=      0.015756\n",
      "At iterate     7  f =       147.42  |proj g|=      0.033755\n",
      "At iterate     8  f =        147.4  |proj g|=       0.06193\n",
      "At iterate     9  f =       147.37  |proj g|=      0.098891\n",
      "At iterate    10  f =       147.29  |proj g|=       0.13303\n",
      "At iterate    11  f =       147.21  |proj g|=       0.11568\n",
      "At iterate    12  f =       147.17  |proj g|=      0.082564\n",
      "At iterate    13  f =       147.15  |proj g|=      0.009183\n",
      "At iterate    14  f =       147.15  |proj g|=    0.00067807\n",
      "At iterate    15  f =       147.15  |proj g|=    6.3098e-05\n",
      "At iterate    16  f =       147.15  |proj g|=    7.8259e-06\n",
      "\n",
      "iterations 16\n",
      "function evaluations 17\n",
      "segments explored during Cauchy searches 16\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 7.82587e-06\n",
      "final function value 147.148\n",
      "\n",
      "F = 147.148\n",
      "final  value 147.148371 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2476 196.278 \n",
      "  - best initial criterion value(s) :  -176.5018 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        176.5  |proj g|=      0.95142\n",
      "At iterate     1  f =       176.02  |proj g|=      0.016248\n",
      "At iterate     2  f =       176.02  |proj g|=     0.0075154\n",
      "At iterate     3  f =       176.01  |proj g|=      0.027925\n",
      "At iterate     4  f =       175.98  |proj g|=     0.0081661\n",
      "At iterate     5  f =       175.98  |proj g|=     0.0012812\n",
      "At iterate     6  f =       175.98  |proj g|=    0.00014173\n",
      "At iterate     7  f =       175.98  |proj g|=    5.9726e-06\n",
      "\n",
      "iterations 7\n",
      "function evaluations 12\n",
      "segments explored during Cauchy searches 7\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.97261e-06\n",
      "final function value 175.98\n",
      "\n",
      "F = 175.98\n",
      "final  value 175.979998 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2337 196.3231 \n",
      "  - best initial criterion value(s) :  -172.961 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       172.96  |proj g|=      0.46341\n",
      "At iterate     1  f =       172.81  |proj g|=       0.18401\n",
      "At iterate     2  f =       172.78  |proj g|=        0.0303\n",
      "At iterate     3  f =       172.78  |proj g|=      0.022673\n",
      "At iterate     4  f =       172.78  |proj g|=      0.022472\n",
      "At iterate     5  f =       172.77  |proj g|=      0.065592\n",
      "At iterate     6  f =       172.76  |proj g|=       0.13197\n",
      "At iterate     7  f =       172.72  |proj g|=       0.24177\n",
      "At iterate     8  f =       172.63  |proj g|=       0.39927\n",
      "At iterate     9  f =       172.41  |proj g|=       0.60356\n",
      "At iterate    10  f =       172.05  |proj g|=       0.74797\n",
      "At iterate    11  f =       171.67  |proj g|=        0.3515\n",
      "At iterate    12  f =       171.58  |proj g|=       0.18893\n",
      "At iterate    13  f =       171.55  |proj g|=      0.018412\n",
      "At iterate    14  f =       171.55  |proj g|=     0.0013298\n",
      "At iterate    15  f =       171.55  |proj g|=    2.4004e-05\n",
      "At iterate    16  f =       171.55  |proj g|=    6.0723e-08\n",
      "\n",
      "iterations 16\n",
      "function evaluations 17\n",
      "segments explored during Cauchy searches 16\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.0723e-08\n",
      "final function value 171.549\n",
      "\n",
      "F = 171.549\n",
      "final  value 171.548869 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1329 196.2265 \n",
      "  - best initial criterion value(s) :  -170.3236 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       170.32  |proj g|=     0.096647\n",
      "At iterate     1  f =       170.31  |proj g|=      0.085065\n",
      "At iterate     2  f =       170.27  |proj g|=       0.03313\n",
      "At iterate     3  f =       164.89  |proj g|=       0.99037\n",
      "At iterate     4  f =       164.29  |proj g|=       0.70716\n",
      "At iterate     5  f =       163.94  |proj g|=       0.18555\n",
      "At iterate     6  f =        163.8  |proj g|=      0.019583\n",
      "At iterate     7  f =        163.8  |proj g|=     0.0025837\n",
      "At iterate     8  f =        163.8  |proj g|=     0.0001547\n",
      "At iterate     9  f =        163.8  |proj g|=    6.2983e-07\n",
      "\n",
      "iterations 9\n",
      "function evaluations 24\n",
      "segments explored during Cauchy searches 9\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 6.29834e-07\n",
      "final function value 163.801\n",
      "\n",
      "F = 163.801\n",
      "final  value 163.800667 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1737 196.2507 \n",
      "  - best initial criterion value(s) :  -191.6998 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=        191.7  |proj g|=       5.0153\n",
      "At iterate     1  f =       189.64  |proj g|=       0.65292\n",
      "At iterate     2  f =       189.61  |proj g|=     0.0031071\n",
      "At iterate     3  f =       189.61  |proj g|=    5.8028e-05\n",
      "At iterate     4  f =       189.61  |proj g|=    5.8143e-05\n",
      "\n",
      "iterations 4\n",
      "function evaluations 24\n",
      "segments explored during Cauchy searches 4\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 5.81434e-05\n",
      "final function value 189.608\n",
      "\n",
      "F = 189.608\n",
      "Warning:  more than 10 function and gradient evaluations\n",
      "   in the last line search\n",
      "final  value 189.608379 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.242 196.082 \n",
      "  - best initial criterion value(s) :  -194.969 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       194.97  |proj g|=       2.7533\n",
      "At iterate     1  f =       186.85  |proj g|=        2.7488\n",
      "At iterate     2  f =       185.68  |proj g|=        2.3131\n",
      "At iterate     3  f =        184.2  |proj g|=       0.21308\n",
      "At iterate     4  f =        184.2  |proj g|=      0.089936\n",
      "At iterate     5  f =       184.19  |proj g|=     0.0015306\n",
      "At iterate     6  f =       184.19  |proj g|=    0.00028788\n",
      "At iterate     7  f =       184.19  |proj g|=     0.0010695\n",
      "At iterate     8  f =       184.19  |proj g|=     0.0022382\n",
      "At iterate     9  f =       184.19  |proj g|=     0.0045279\n",
      "At iterate    10  f =       184.19  |proj g|=     0.0079807\n",
      "At iterate    11  f =       184.19  |proj g|=      0.013697\n",
      "At iterate    12  f =       184.19  |proj g|=      0.022734\n",
      "At iterate    13  f =       184.19  |proj g|=      0.037223\n",
      "At iterate    14  f =       184.19  |proj g|=      0.059139\n",
      "At iterate    15  f =       184.19  |proj g|=      0.087946\n",
      "At iterate    16  f =       184.19  |proj g|=       0.11256\n",
      "At iterate    17  f =       184.19  |proj g|=        0.0771\n",
      "At iterate    18  f =       184.19  |proj g|=      0.014906\n",
      "At iterate    19  f =       184.19  |proj g|=    8.5307e-05\n",
      "At iterate    20  f =       184.19  |proj g|=    9.7605e-08\n",
      "\n",
      "iterations 20\n",
      "function evaluations 23\n",
      "segments explored during Cauchy searches 21\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 1\n",
      "norm of the final projected gradient 9.76055e-08\n",
      "final function value 184.186\n",
      "\n",
      "F = 184.186\n",
      "final  value 184.185524 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.1724 196.327 \n",
      "  - best initial criterion value(s) :  -175.2764 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       175.28  |proj g|=      0.22598\n",
      "At iterate     1  f =       175.22  |proj g|=       0.18825\n",
      "At iterate     2  f =       174.29  |proj g|=        0.9362\n",
      "At iterate     3  f =       173.22  |proj g|=       0.97427\n",
      "At iterate     4  f =       172.58  |proj g|=         0.859\n",
      "At iterate     5  f =       172.18  |proj g|=        0.1692\n",
      "At iterate     6  f =       172.09  |proj g|=      0.057847\n",
      "At iterate     7  f =       172.06  |proj g|=      0.019159\n",
      "At iterate     8  f =       172.06  |proj g|=     0.0009655\n",
      "At iterate     9  f =       172.06  |proj g|=    6.6343e-05\n",
      "At iterate    10  f =       172.06  |proj g|=    1.3343e-05\n",
      "\n",
      "iterations 10\n",
      "function evaluations 13\n",
      "segments explored during Cauchy searches 10\n",
      "BFGS updates skipped 0\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.33431e-05\n",
      "final function value 172.058\n",
      "\n",
      "F = 172.058\n",
      "final  value 172.058366 \n",
      "converged\n",
      "\n",
      "optimisation start\n",
      "------------------\n",
      "* estimation method   : MLE \n",
      "* optimisation method : BFGS \n",
      "* analytical gradient : used\n",
      "* trend model : ~1\n",
      "* covariance model : \n",
      "  - type :  matern5_2 \n",
      "  - nugget : NO\n",
      "  - parameters lower bounds :  1e-10 1e-10 \n",
      "  - parameters upper bounds :  196.2394 196.1205 \n",
      "  - best initial criterion value(s) :  -160.5572 \n",
      "\n",
      "N = 2, M = 5 machine precision = 2.22045e-16\n",
      "At X0, 0 variables are exactly at the bounds\n",
      "At iterate     0  f=       160.56  |proj g|=      0.31086\n",
      "At iterate     1  f =       160.46  |proj g|=       0.31418\n",
      "ys=-1.038e-03  -gs= 9.699e-02, BFGS update SKIPPED\n",
      "At iterate     2  f =       154.86  |proj g|=       0.22193\n",
      "At iterate     3  f =       154.55  |proj g|=      0.056203\n",
      "At iterate     4  f =       154.53  |proj g|=      0.027622\n",
      "At iterate     5  f =       154.52  |proj g|=       0.01837\n",
      "At iterate     6  f =       154.49  |proj g|=      0.030054\n",
      "At iterate     7  f =       154.43  |proj g|=      0.074989\n",
      "At iterate     8  f =       154.37  |proj g|=      0.090063\n",
      "At iterate     9  f =       154.34  |proj g|=      0.038778\n",
      "At iterate    10  f =       154.33  |proj g|=     0.0064411\n",
      "At iterate    11  f =       154.33  |proj g|=    0.00017342\n",
      "At iterate    12  f =       154.33  |proj g|=    1.8955e-07\n",
      "\n",
      "iterations 12\n",
      "function evaluations 20\n",
      "segments explored during Cauchy searches 13\n",
      "BFGS updates skipped 1\n",
      "active bounds at final generalized Cauchy point 0\n",
      "norm of the final projected gradient 1.89553e-07\n",
      "final function value 154.331\n",
      "\n",
      "F = 154.331\n",
      "final  value 154.330699 \n",
      "converged\n",
      "[1] 86.22809 13.77191\n"
     ]
    }
   ],
   "source": [
    "# OPTIMISATION TMSE PROCESS USING COBYLA\n",
    "\n",
    "# Some parameters\n",
    "d = 2  # data dimension\n",
    "n_init = d*10   # initial number of data points\n",
    "n_points = nrow(mat.donne) # total number of data points\n",
    "n_adds = 5 # number of additional data points\n",
    "\n",
    "# Initialize randomly data by index\n",
    "index = sample(1:nrow(mat.donne),n_init)\n",
    "data_updated =mat.donne[index, ]\n",
    "X = data_updated[,c(-1)]\n",
    "\n",
    "points_test = matrix(nrow = n_adds, ncol =2)\n",
    "\n",
    "print(\"Starting...\")\n",
    "# Loop over additional data points\n",
    "for (i in 1:n_adds){\n",
    "\n",
    "    print(\"Adding point... \")\n",
    "    data_recherche = mat.donne[setdiff(1:nrow(mat.donne),index),]\n",
    "    x_new = cobyla(x0 = as.numeric(mat.donne[1,c(-1)]), fn = new_tmse, hin = contraintes, control = list(xtol_rel = 1e-3))$par\n",
    "    print(x_new)\n",
    "    points_test[i,] = x_new\n",
    "    newpoint = pointProche(x_new,data_recherche)\n",
    "    data_updated[nrow(data_updated) + 1, ] = newpoint\n",
    "    #data_updated = rbind(data_updated,newpoint)\n",
    "    X = data_updated[,c(-1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "736f7cc7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 5 × 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td> 48.68034</td><td> 5.131966e+01</td></tr>\n",
       "\t<tr><td>100.00000</td><td>-5.357195e-17</td></tr>\n",
       "\t<tr><td> 97.74836</td><td> 2.251638e+00</td></tr>\n",
       "\t<tr><td> 87.66738</td><td> 1.233262e+01</td></tr>\n",
       "\t<tr><td> 86.22809</td><td> 1.377191e+01</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 5 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t  48.68034 &  5.131966e+01\\\\\n",
       "\t 100.00000 & -5.357195e-17\\\\\n",
       "\t  97.74836 &  2.251638e+00\\\\\n",
       "\t  87.66738 &  1.233262e+01\\\\\n",
       "\t  86.22809 &  1.377191e+01\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 5 × 2 of type dbl\n",
       "\n",
       "|  48.68034 |  5.131966e+01 |\n",
       "| 100.00000 | -5.357195e-17 |\n",
       "|  97.74836 |  2.251638e+00 |\n",
       "|  87.66738 |  1.233262e+01 |\n",
       "|  86.22809 |  1.377191e+01 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]         \n",
       "[1,]  48.68034  5.131966e+01\n",
       "[2,] 100.00000 -5.357195e-17\n",
       "[3,]  97.74836  2.251638e+00\n",
       "[4,]  87.66738  1.233262e+01\n",
       "[5,]  86.22809  1.377191e+01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90ed1ef2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- seq(0,100,length.out=100)\n",
    "y <- sort(100-x)\n",
    "z <- outer((x-50)^2,(y-50)^2,`+`)\n",
    "\n",
    "contour(x,y,z,xlim = range(x, finite = TRUE),\n",
    "        ylim = range(y, finite = TRUE),\n",
    "        zlim = range(z, finite = TRUE))\n",
    "lines(x, 100-x, pch=18, col=\"blue\", type=\"b\", lty=2)\n",
    "points(points_test[,1],points_test[,2], pch=19, col=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9fbe75b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 25 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>resp</th><th scope=col>x</th><th scope=col>y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>40</th><td>4973.8003536</td><td> 0.1311703</td><td>99.868830</td></tr>\n",
       "\t<tr><th scope=row>35</th><td>2044.7191652</td><td>18.0256418</td><td>81.974358</td></tr>\n",
       "\t<tr><th scope=row>97</th><td>2742.4263992</td><td>87.0298960</td><td>12.970104</td></tr>\n",
       "\t<tr><th scope=row>58</th><td>3872.3856134</td><td> 5.9978091</td><td>94.002191</td></tr>\n",
       "\t<tr><th scope=row>48</th><td>4009.0023491</td><td> 5.2283441</td><td>94.771656</td></tr>\n",
       "\t<tr><th scope=row>95</th><td>4231.9038222</td><td> 4.0005227</td><td>95.999477</td></tr>\n",
       "\t<tr><th scope=row>73</th><td> 920.7120708</td><td>71.4559091</td><td>28.544091</td></tr>\n",
       "\t<tr><th scope=row>34</th><td>3187.4783130</td><td>89.9216627</td><td>10.078337</td></tr>\n",
       "\t<tr><th scope=row>100</th><td>   0.4662798</td><td>49.5171544</td><td>50.482846</td></tr>\n",
       "\t<tr><th scope=row>77</th><td>1718.1930436</td><td>79.3103484</td><td>20.689652</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>3081.3829637</td><td>89.2516430</td><td>10.748357</td></tr>\n",
       "\t<tr><th scope=row>62</th><td>2778.7835193</td><td>87.2745457</td><td>12.725454</td></tr>\n",
       "\t<tr><th scope=row>54</th><td>2056.2132363</td><td>82.0641017</td><td>17.935898</td></tr>\n",
       "\t<tr><th scope=row>76</th><td>   0.9333910</td><td>50.6831511</td><td>49.316849</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>1332.6301162</td><td>75.8130792</td><td>24.186921</td></tr>\n",
       "\t<tr><th scope=row>59</th><td>1418.4094027</td><td>23.3691025</td><td>76.630897</td></tr>\n",
       "\t<tr><th scope=row>15</th><td> 319.7021297</td><td>37.3567779</td><td>62.643222</td></tr>\n",
       "\t<tr><th scope=row>89</th><td> 107.0929054</td><td>42.6824558</td><td>57.317544</td></tr>\n",
       "\t<tr><th scope=row>67</th><td>1030.8288381</td><td>72.7027403</td><td>27.297260</td></tr>\n",
       "\t<tr><th scope=row>22</th><td> 417.1385438</td><td>64.4419276</td><td>35.558072</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>   1.3066524</td><td>49.1917140</td><td>50.808286</td></tr>\n",
       "\t<tr><th scope=row>52</th><td>4655.4584955</td><td>98.2465465</td><td> 1.753454</td></tr>\n",
       "\t<tr><th scope=row>38</th><td>4623.0480179</td><td>98.0783112</td><td> 1.921689</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>2678.3853679</td><td>86.5949817</td><td>13.405018</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>2678.3853679</td><td>86.5949817</td><td>13.405018</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 25 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & resp & x & y\\\\\n",
       "  & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t40 & 4973.8003536 &  0.1311703 & 99.868830\\\\\n",
       "\t35 & 2044.7191652 & 18.0256418 & 81.974358\\\\\n",
       "\t97 & 2742.4263992 & 87.0298960 & 12.970104\\\\\n",
       "\t58 & 3872.3856134 &  5.9978091 & 94.002191\\\\\n",
       "\t48 & 4009.0023491 &  5.2283441 & 94.771656\\\\\n",
       "\t95 & 4231.9038222 &  4.0005227 & 95.999477\\\\\n",
       "\t73 &  920.7120708 & 71.4559091 & 28.544091\\\\\n",
       "\t34 & 3187.4783130 & 89.9216627 & 10.078337\\\\\n",
       "\t100 &    0.4662798 & 49.5171544 & 50.482846\\\\\n",
       "\t77 & 1718.1930436 & 79.3103484 & 20.689652\\\\\n",
       "\t51 & 3081.3829637 & 89.2516430 & 10.748357\\\\\n",
       "\t62 & 2778.7835193 & 87.2745457 & 12.725454\\\\\n",
       "\t54 & 2056.2132363 & 82.0641017 & 17.935898\\\\\n",
       "\t76 &    0.9333910 & 50.6831511 & 49.316849\\\\\n",
       "\t19 & 1332.6301162 & 75.8130792 & 24.186921\\\\\n",
       "\t59 & 1418.4094027 & 23.3691025 & 76.630897\\\\\n",
       "\t15 &  319.7021297 & 37.3567779 & 62.643222\\\\\n",
       "\t89 &  107.0929054 & 42.6824558 & 57.317544\\\\\n",
       "\t67 & 1030.8288381 & 72.7027403 & 27.297260\\\\\n",
       "\t22 &  417.1385438 & 64.4419276 & 35.558072\\\\\n",
       "\t13 &    1.3066524 & 49.1917140 & 50.808286\\\\\n",
       "\t52 & 4655.4584955 & 98.2465465 &  1.753454\\\\\n",
       "\t38 & 4623.0480179 & 98.0783112 &  1.921689\\\\\n",
       "\t28 & 2678.3853679 & 86.5949817 & 13.405018\\\\\n",
       "\t25 & 2678.3853679 & 86.5949817 & 13.405018\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 25 × 3\n",
       "\n",
       "| <!--/--> | resp &lt;dbl&gt; | x &lt;dbl&gt; | y &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 40 | 4973.8003536 |  0.1311703 | 99.868830 |\n",
       "| 35 | 2044.7191652 | 18.0256418 | 81.974358 |\n",
       "| 97 | 2742.4263992 | 87.0298960 | 12.970104 |\n",
       "| 58 | 3872.3856134 |  5.9978091 | 94.002191 |\n",
       "| 48 | 4009.0023491 |  5.2283441 | 94.771656 |\n",
       "| 95 | 4231.9038222 |  4.0005227 | 95.999477 |\n",
       "| 73 |  920.7120708 | 71.4559091 | 28.544091 |\n",
       "| 34 | 3187.4783130 | 89.9216627 | 10.078337 |\n",
       "| 100 |    0.4662798 | 49.5171544 | 50.482846 |\n",
       "| 77 | 1718.1930436 | 79.3103484 | 20.689652 |\n",
       "| 51 | 3081.3829637 | 89.2516430 | 10.748357 |\n",
       "| 62 | 2778.7835193 | 87.2745457 | 12.725454 |\n",
       "| 54 | 2056.2132363 | 82.0641017 | 17.935898 |\n",
       "| 76 |    0.9333910 | 50.6831511 | 49.316849 |\n",
       "| 19 | 1332.6301162 | 75.8130792 | 24.186921 |\n",
       "| 59 | 1418.4094027 | 23.3691025 | 76.630897 |\n",
       "| 15 |  319.7021297 | 37.3567779 | 62.643222 |\n",
       "| 89 |  107.0929054 | 42.6824558 | 57.317544 |\n",
       "| 67 | 1030.8288381 | 72.7027403 | 27.297260 |\n",
       "| 22 |  417.1385438 | 64.4419276 | 35.558072 |\n",
       "| 13 |    1.3066524 | 49.1917140 | 50.808286 |\n",
       "| 52 | 4655.4584955 | 98.2465465 |  1.753454 |\n",
       "| 38 | 4623.0480179 | 98.0783112 |  1.921689 |\n",
       "| 28 | 2678.3853679 | 86.5949817 | 13.405018 |\n",
       "| 25 | 2678.3853679 | 86.5949817 | 13.405018 |\n",
       "\n"
      ],
      "text/plain": [
       "    resp         x          y        \n",
       "40  4973.8003536  0.1311703 99.868830\n",
       "35  2044.7191652 18.0256418 81.974358\n",
       "97  2742.4263992 87.0298960 12.970104\n",
       "58  3872.3856134  5.9978091 94.002191\n",
       "48  4009.0023491  5.2283441 94.771656\n",
       "95  4231.9038222  4.0005227 95.999477\n",
       "73   920.7120708 71.4559091 28.544091\n",
       "34  3187.4783130 89.9216627 10.078337\n",
       "100    0.4662798 49.5171544 50.482846\n",
       "77  1718.1930436 79.3103484 20.689652\n",
       "51  3081.3829637 89.2516430 10.748357\n",
       "62  2778.7835193 87.2745457 12.725454\n",
       "54  2056.2132363 82.0641017 17.935898\n",
       "76     0.9333910 50.6831511 49.316849\n",
       "19  1332.6301162 75.8130792 24.186921\n",
       "59  1418.4094027 23.3691025 76.630897\n",
       "15   319.7021297 37.3567779 62.643222\n",
       "89   107.0929054 42.6824558 57.317544\n",
       "67  1030.8288381 72.7027403 27.297260\n",
       "22   417.1385438 64.4419276 35.558072\n",
       "13     1.3066524 49.1917140 50.808286\n",
       "52  4655.4584955 98.2465465  1.753454\n",
       "38  4623.0480179 98.0783112  1.921689\n",
       "28  2678.3853679 86.5949817 13.405018\n",
       "25  2678.3853679 86.5949817 13.405018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be17d5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "9749.6501"
      ],
      "text/latex": [
       "9749.6501"
      ],
      "text/markdown": [
       "9749.6501"
      ],
      "text/plain": [
       "[1] 9749.65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fjouet(0.75,99.24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
